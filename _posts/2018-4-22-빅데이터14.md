---
post : layout
title : 빅데이터14
---
## 빅데이터14
빅데이터14

## 시작전
큰데이터를 넣었을때 하둡을 돌리면 문제가 생긴다. 그때 어떻게 할껀지 알아보자! 힌트를 하면 구글링 하면 나온다.
구글링 하면 쉽게 나올것이다.
다음주 중간고사, 그 시간은 피해 그 다음주로 측정했다.

주관식으로 대부분 나갈것이다.
시험문제 자체가 많이나가지 않을것이다.
1번 o,x 10문제 나간다.

데이터 set이 있을때 얘네들 유사도를 가지고서 데이터를 묶는게 클러스터링이다. 그륩핑이다. 클러스터링이 쉽지 않은 이유는 굉장히 디멘션이 크니까 2차원은 간단한데 3차원 이상부터 차수가 복잡해짐 그래서 통상적으로 높다. 그래서 쉽지가 않다. 클러스터링을 한다. 
눈에 보이는대로 그륩핑 하면 얼마나 좋겠냐만은 2차원의 유클리드한 스페이스 에서만 가능하다.
에제일 뿐이다. 
갤럭시 갔다가 .. 
같은 비슷한 종류를 갔다가 클러스터링을 한다던지
이런것들이 있다. 

다큐먼트를 예를 들어서, 클러스터링 할때 뭔가를 기준이 있어야 한다. 어떻게 표현을 하느냐 데이터, 데이터 패스 유클리드 공간에서 한 점을 잡고 공간을 생각하는데 그렇지 않다. 
데이터는 그렇지 않다. 부분적인것이다. 그런 데이터가 예를들어서 벡터형식으로 표현이 된다. 그렇게 했을때 cosin 디스턴스를 쓰게 된다.
이 디스턴스 개념은 한마디로 클러스터링 하게 될때 쉽게 말하면 디스턴스가 가까운 놈들끼리 묶는것이다. 이것은 2차원 유클리한 좌표에서 거리라고 생각해도 좋다. 2차원의 좌표가 있을때 그것을 그륩핑해라 하면 멍멍이 그림처럼 그냥봐도 디스턴스가 가까운 애들끼리 묶으면 되는것이다 근데 이 디스턴스라는 개념이 유클리한 공간에서만 적용되는것이 아니다. 이 디스턴스란 개념을 이용해서 디스턴스가 가까운 놈들끼리 클러스터링을 하는것이다. 그럼 디스턴스가 뭔데?? 디스턴스 맞지만 좌표상에서 디스턴스(유클리드 디스턴스)

2차원에서나 그렇지 벡터에서 디스턴스를 어떻게 측정할것이냐? set이 있으면 디스턴스를 어떻게 측정할것이냐 바꿔 말하면  디스턴스의 정의가 뭔지 나와야 한다.

한마디로 디스턴스가 가까운 애들끼리 묶는게 클러스터링인데 그러면 디스턴스가 뭐냐?? 라는게 그다음부터 나온다.

set으로 데이터가 표현이 된다. 그러면 무슨 distance를 쓰는지 여기서는 자카드 디스턴스를 쓴다.


포인터로 나오면 유클리드 디스턴스를 쓰면된다.
## Distance Measures (Jaccard distance)

디스턴스가 뭐냐 정의를 갔다가 해야하는데
첫번째 자카드 디스턴스가 나온다.
자카드 디스턴스는 자카도 similarity라는게 있다. 유사도를 가져다 먼저 정의를 해야 한다. 1에서 자카도 유사도를 주는게 자카도 인스턴스다.

자카도 similarity는 set이다. 자카도 distance는 set일때 그 distance를 쓰는것이다. 데이터 포인트가 1일때도 set의 형태로 나타날때는 자카도 디스턴스를 쓰는데 

유사도를 어떻게 측정하냐면 어떤 c1과 c2가 있을때 걔네들의 유사도를 어떻게 측정하냐면 그 교집합, intersection을 가져다 
교집합을 갔다가 합집합으로 나눈다.

보면 예제에서 보면 전체 합집합의 개수가 8개인데 그중에서 교집합이 3개이므로 3/8이 jaccard similarity다.

거기서 1에서 그값을 뺸것이 distance이다.

간단하다. 여기서 디스턴스는 1에서 자카도 유사도를 뺸것이다.
자카도 유사도는 셋에서 교집합을 합집합의 값으로 나눠준것이 유사도다.

## Distance Measures(Cosine distance)
이것역시도 선형대수 나온다.
데이터 셋이 벡터로 표현되는경우이다.
선형대수가 벡터를 다루기 때문에 두개의 벡터가 있을때 두개의 벡터가 이루는 각이다.
그 각을 어떤식으로 유도하냐면 cos 값으로 유도한다.
내적을 이용해서 dot product를 이용해서

내적값을 이용해서 그 공식을 유도한다.
물론 cos 쎼타가 x와 y의 놈값 내적값을 나눠준게 된다.
실질적으로 내적 을 구하는 공식 자체가 그 두개의 벡터가 있을때 놈값, (놈: 크기나 길이를 말한다 벡터에) 그 놈값을 가져다 두개를 곱하고 거기다 cos쎄타를 곱한것이 내적값이다. cos쎼타 값은 내적값을 놈값으로 나눠주면된다.
궁극적으로 원하는것은 각도다. cos 값을 알고있기때문에 구지 얘기하면 값을 알고있으니까 각도를 알려면 cos 쓰면된다.

x,y는 벡터이고 두개의 벡터의 차수는 같아야 한다.내적값은 각각 포지션 요소 곱에서 다 더한다. 
놈값은 자기 원소값의 제곱의 합에 루트다.
x,y의 놈값을 각각 구할수있다.
각도를 알고싶으면 아크코사인 취해주면된다.

우리가 금방 알 수 있다. 놈값을 구해보면 루트 6이다. 각각 스퀘어 값.

cos이 1/2 나오는값은 60도다.
계산하는방식 구하기.

## Distance Measures(Euclidean distance)
잘알고있다. 제일 쉬운 디스턴스다.
말그대로 
만약에 n차원 유클리드 스페이스가 있다.
두 개의 유클리드한 디스턴스는 두개의 좌표가 있다 가정하고
걔네들의 유클리드 디스턴스는 x1-y1빼고 제곱하고 더하기 x2-y2빼고 제곱하고 그것을 다 해서 루트 씌어준게 유클리드 디스턴스다.

두개의 점 사이 구하기 할때 이런식으로 한다. n차원으로 늘려놓은것일 뿐이다.
예제풀어보기
## Distance Measures(Edit distance)
이제는 Edit distancee라는게 나오는데
경험해보지 않고 못들어봤을텐데
데이터가 string으로 들어올때 표현될때
그 string끼리 distance 구해야 하는데
string에 디스턴스가 사실상 없다.

string 끼리 데이터 distance 개념으로 우리가 다시 정립을 해야 하는데 그걸위해 만든게 edit distance

edit distance : 만약에 두개의 string이 있는데 x...xn 표현이되고 y..ym까지 string으로 표현된다고 가정하면 edit distance라는건 x string을 y string 으로 바꾸고 싶다. 바꿀때 몇번 지우고 몇번 써야하느냐 말그대로 editing을 한다. 키보드 타이핑 한다고 생각하면된다.

그거에 물론 smallest 넘버다.
그래야지 하나의 값이 나온다. smallest 값은 x를 y로 바꿀때 몇번지우고 몇번 넣어야 되는지 그것에 최소값이 두개의 string의 edit distance이다.

abcde, acfdeg 이것의 edit distance 뭐냐 따졌을때 바꿔말하면 이 스트링을 요 스트링으로 키보드 타이핑하는데 바꾼다고 생각해보자. 그대로이다.

b를 제일 먼저 지울것이고 f를 넣고 그다음에 g를 넣으면되겠지 3번을 갔다가 editing을 한다. 지우고 쓰고 합했을때 3번을 갔다가 이순서를 따르면 x string을 y라는 string으로 바꿀 수 있다. 이것이 edit distance이다.

++ 사실은 코딩을 해서 뭔가 알고리즘으로 구현하기 어렵다. 그래서 나온것이 x string의 사이즈, y string 사이즈 (string의 사이즈를 더하기) 2lcs를 뺀다.

Longest Common Subsequence (LCS)
알고리즘 수업들으면 DP 으로 구성되는 자주 등장하는 주제다. 이용해서 값을 찾을 수 있다.

왼쪽에서 오른쪽으로 훑어 가면서 2개의 STREAM을 비교해서 COMMON 부분을 찾는다 반드시 연결될 필요는없다. 순서만 맞으면된다. 그렇게 나오는 Common sequence, 가장긴 string이다.

왼쪽에서 오른쪽으로 무조건 순서만 맞으면된다.
b가 없으니까 스킾한다. f 무시하고 d가 나온다.
e가 나온다 g는 무시한다.
acde가 LCS이다. LCS 길이를 두번 곱해서 값을 구해주면 값이나온다.
각각 length가 5,6이고 11+8 = 19다.

## Distance Measures(Hamming distance)
쉽다. 어떤 벡터가 있을때 벡터가 통상적으로 
벡터의 길이를 구하는거지만 벡터는 구지 해밍 디스턴스가 아니더라도 표현할 수 있는게 많다.
그래서 통상적으로 해밍 디스턴스는 0010101010 binary distance를 측정할때 주로 쓴다.

벡터 사이이긴 하지만 통상적으로 값이 boolean인 값들이다. binary stream이라고 생각하면된다.

string은 아니고 binary로 이루어진 그런 데이터다.

서로 다른 컴포넌트들의 개수다. 굉장히 간단하다.
두개 벡터가 있는데 하나 벡터가 10101 이고 나머지 11110인데 해밍 디스턴스는 3인데 첫번째 1같고 2번째 다르고 1같고 각각 자기 포지션에서 3개가 다른게 이게 해밍 디스턴스다.

## Overview: Methods of Clustering
이제는 본론으로 와서 디스턴스를 알고있으니까
클러스터링 이라는건 디스턴스 가까운것을 묶는것이다.
클러스터링을 하게 되는 방법을 생각해보면 크게 Hierarchical한 계층적으로 하는방법 
클러스터링을 하는 방법이있고, 

Point assignment 점할당 방식이 있다.

크게 두개로 나눠진다. 클러스터링은 굉장히 전형적이다.
계층적은 쉽게 말하서 
밑에서 bottom up해서 올라가는 그런 클러스터링 방식이 있고 아니면 반대로 클러스터링이 이미 되어있다 라고 가정을 하고 위에서부터 잘게잘게 쪼개가는 방식이 있다. 그게 Divisive 방식으로 top-down 방식이다.
통상적으로 계층적으로 할때는 bottom up 방식을 쓴다.
top-down 방식은 잘 안쓴다.

제일 밑에있는 각각의 하나 점이 주어진 데이터라고 생각하고 걔네들끼리 유사한 놈들끼리 묶는다. 1차원적으로 묶고 나서 그다음에 레이어에서 또 묶고 그다음 레이어 에서 또 묶고 를 한다. 결과적으로 우리가 원하는 덩어리에 도달하게 된다. 이게 bottom 방식, 계층적 방식이다.

point assignment는 다음에 나올 
가장 대표적이고 흔한 방식이다. 
이것은 점들이 쫙있다. 눈에 보이니까 그런데 컴퓨터에서는 눈에 보이는게 아니라, 데이터 컨트롤 밖에 없다.
그럼 컴퓨터 입장에서 각각의 점들이 데이터들이 순서들을 찍어서 가장 가깝다라고 생각하는 그놈한테 할당한다. 그 다음 점을 가지고 와서 distance를 계산해 그러고 나서 너는 요기 클러스터에 같구나 저기로가. 너는 저기 클러스터에 가깝구나 저기로 가 점을 가지고 하나씩 어사인해나가는 방식이 포인터 어사인먼트 방식이다.


## Hierarchical Clustering
가장 가까이 있는 클러스터 끼리 계속해서 묶는것이다.
코딩에서 recursive한 방식이라고 생각해도 좋다.
기본적으로 얘는 여러분한테 많은 데이터포인터가 주어지면 데이터 하나하나가 자기자신이 클러스터라고 생각한다. 초기화단계는 그렇게 생각한다.

클러스터끼리 거리를 계산해서 제일 가까운 클러스터 끼리 묶어버린다. 그게 Hierarchical Clustering 알고리즘 방식이다.

어떤 문제가 생기냐면, 클러스터링 좋은데
굉장히 많은 데이터가 있다고 가정했을때 각각 데이터는 지가 자신을 어떻게 표현하는지에 방식이 있을것이다. 예를들어 좌표라고 생각하고 우리에게 1000개의 점을 던져주면 클러스터링을 하기전에 1000개의 데이터를 표현하는 방식은 굉장히 간단하다. 좌표가 스스로 데이터를 표현하니까

근데 그데이터들을 클러스터링 했다고 생각하자. 그 데이터를 어떻게 표현할것이냐
++데이터가 두개점이 주어졌는데 각각점은 지 자체에 좌표를 표현하고있지만 2개 데이터를 클러스터로 묶었다 생각해보면 이클러스터를 어떻게 표현할것인가??
++

3개의 질문.
말은 쉽지만 해결하기 위해서는 또다른 정의가 필요하다.
1000개의 점을 하나의 클러스터로 묶었는데 어떻게 표현할것이냐? 클러스터 들끼리 묶어야 한다. 클러스터 들끼리 디스턴스 계산해야 한다. 클러스터 들끼리 디스턴스를 계산하기 위해서는 뭔가 표현이 있어야 디스턴스를 계산할 수 있을 것이다. 그거다. 첫번째 질문이 그것이다.

두번째 질문은 가까운놈들끼리 묶는다. 가깝다 정의는 뭐가 어떻게해야 가까운것이다. 

세번째 언제 멈출것이냐? 클러스터링은 끝까지 가버리면 하나가 되버린다. 언제 멈출것이냐

클러스터링에서 생각해봐야할 문제다. Hierarchical 뿐만아니라 Point assignment도 똑같이 적용된다.

## Hierarchical Clustering
하나의 점이 클러스터링이라고 인식을하고 클러스터 끼리 가까운 디스턴스 놈들끼리 묶어서 올라간다. 그런식이다.

그러면 그런 클러스터 가져다 어떻게 표현할까? 
대표적인것이 centroid 이다. 클러스터로 묶었는데 그것을 표현할 수 있는 그런 대표적인 값, 표현방식을 centroid 라고 한다.

centroid라는것은 그 값들을 유클리드 디스턴스로 표현될때만 쓸수있는 방식이다.
그게 centroid 이다. centroid는 굉장히 직관적이다. 클러스터들이 많은 점들이 있는데 걔네들의 average 값이다.
두개의 데이터가 있을때 중간값을 우리는 두개의 데이터 클러스터에 대표값이라고 하자. centroid다.

average값들을 좌표에) 좌표에 average 값을 cluster를 대표하는 그런값으로 하자. 이게 centroid 이다.

어떻게 가까운지,디스턴스로 묘사한다. 
## Example: Hierarchical clustering
그래서 클러스터를 가져다 centroid로 표현을 하고 그 centroid 끼리의 distance를 계산하면된다. 글면 그 두개의 클러스터가 아니면 클러스터들 끼리 얼마만큼 멀고 가까운지 값이 나온다. 그러면 걔들중에 가까운 클러스터끼리 묶으면 된다. 그리고 나서 centorid를 다시 계산한다.

왜냐하면 점이 묶여서 새로운 단위의 클러스터가 만들어졌으니까 굉장히 직관적이다. 

데이터 코드가 있다. 제일 먼저보면 두개를 묶는다 가정하면 묶고 나서 초기떄는 각각이 클러스터이다. 그러고 나서 묶었다. 묶는순간에 centroid를 계산해야되, 그러면 이 두개의 좌표 클러스터 데이터 값은 얘네가 된다. 그리고 나서 초록 값을 다시 묶는다. 클러스터가 됬기 때문에 얘도 centroid 값을 다시 계산해야 한다. 계속 .. 반복
3개포인터를 다시계산해야 한다. 값을 계산해서 저 클러스터로 집어넣고 

dendrogram 본인스스로가 클러스터라고 가정하고 클러스터끼리 묶고 클러스터 끼리 묶고 .. 이런식으로 나가는것이다.


## Efficiency(here, need to edit)
hierarchical 하게 묶어간다. 직관적이다. n^3이다 큐빅이다. 왜냐하면, 각각 하나의 점들당 지들끼리 distance를 다 구해야 한다. 다 구해야지 어떤놈이 제일 가까운 놈인지 나올것이다. 그얘기인말은 그거 계산한 순간 n 스퀘어다.
각각 n에 대해서 거리를 다 구하니까 
그걸로 끝나는게 아니라 제일 가까운 놈을 두개 묶었고 그러면 centroid가 만들어질것이고 그러면 distance를 또 계산해야된다. n-1의 스퀘어가 될것이다. 하나가 줄었다. 두개를 묶었으니까 그런식으로 묶어가는것이다 나중에 하나로 가게된다.
이러니까 다 더한것을 계산하면 큐빅으로 나오게 된다.

hierarchical하게 묶어가는것은 굉장히 비싸다.(오버헤드크다.) 
priority queue를 써서 heap을 쓴다. n의 3제곱 이었던것이 n의 제곱의 logn까지 줄어든다. heap에다 데이터를 쓰고 지우는것 자체가 logn이기 떄문이다. 그래서 
여전히 비싸다. 원래 hierarchical 하게 가는것은 비싸다.
이런식으로 데이터 set이 커지면 오버헤드도 굉장히 커진다.
memory에 맞지 않는다. 따라서 critical한 방법은 되지 않는다. 나중에 개량하는 방법이 나온다.

