---
post : layout
title : 시스템프로그래밍13
---
## Linux File System Types
리눅스 파일 시스템이 지원하는 파일 시스템들은 파일 시스템은 계속 개량된다. 용도에 따라서 큰 파일 작은파일이냐 디스크 깨지는것에 대해서 백업을 자동으로 만들꺼냐 안만들꺼냐 계속 추가가 되 오면서 파일 시스템도 변천을 거친다.

여러 가지 파일 시스템이 있다.
윈도우, 리눅스에서 사용하는 파일 시스템이 다르다.
nandflash를 이용한 ssd를 쓴다라든가 아니면 cdrom 이용한 파일시스템이라든가 여러가지가 있다.

그런것들을 대체적으로 리눅스는 서포트한다. virtual filesystem이라고 하는데 인터페이스 다 똑같이 open/read/write 지만 밑에 있는 내용은 달라질 수 있다. 

디스크에서는 ex2/3/4 까지 있었고, fat는 윈도우즈 에서 쓰는것이고 리눅스 서버에서 제일 많이 쓰는것은 xfs를 제일 많이쓴다. 구조가 조금씩 다르다.

flash 메모리에서는 f2fs 라는게 있는데 삼성에서 만든것이다. 
network file system은 전통적으로 nfs 같은것이 있는데 다른기계에 있는 파일들을 내기계에 하위 디렉토리로 만들어서 네트워크를 통하지 않고 change directory하면 단 기계 파일을 엑세스 할 수 있는것이 network file system이다. 서포트한다. 종류가 여러개 있다.

디스크가 없을 경우, 임베디드 시스템같은 경우는 메인 메로리에다가도 파일 시스템을 똑같이 만들 수 있다. 그것을 ramfs 이라고 한다. 이런것도 서포트 하고

수도파일시스템 proc sysfs 
proc이라는 디렉토리가 있는데 그 데릭토리 속에는 커널이 하면서 프로세스가 뭐가 생성이 되고 커널의 정보를 파일로 담아두는 디렉토리가 있다. 그것을 proc 파일 시스템이라고 한다. 

enterprise Cryptographic File system은 cryptographic은 암호화 한다는것이다. 암호화를 하는 파일 시스템이 eCryptfs 라는것이 있다.

ExOFS
굉장히 많이 서포트한다. 

isofs는 음악들을때 CDROM 를 위한 파일시스템이다. 

60가지 파일 시스템을 서포트한다.
리눅스를 올려놓고 리눅스의 오리지널 파일 시스템을 쓸 수 있지만 윈도우에서 만든것을 가져다가 쓸 수 도 있다.
파일시스템이 밑에가 구조가 달라도 위에서는 다 똑같이 쓸 수 있기때문에 이것을 Virtual file system이라고 한다.
++
60개를 자유자재로 쓰고, 일반적으로 디스크의 xfs가 제일 많이 사용하는 파일 시스템이다.++

## Linux File System
세미나 하면서 나왔지만 리눅스 파일 시스템에 서포트하는 파일의 타입은 Regular file이 있다고 했다. edit 통해서 만들거나 아니면 프로그램에서 copy를 해서 만든다든지 유저들이 일반적인 파일을 말하는것이다. 

그다음에 폴더라고 하는거, 리눅스에서 디렉토리라고 하는것도 파일을 담아두는 영역이 아니라 이것도 하나의 파일에 불과하다. 전화번호부와 같은것이다.

++
그래서, 어떤 디렉토리에 소속이 되어있는 파일의 리스트를 가지고 있는 또 하나의 파일 그게 디렉토리 파일이다.
전화 번호부를 가지고 있는게 디렉토리 파일이다. ++

파이프를 만들면 fifo 파일이 생긴다. 여러가지 input output 디바이스를 갖다가 편하게 쓰기 위해서 통일된 인터페이스를 쓰기 위해서 다 파일로 맵핑하라 하는데 root 밑에 디바이스라는 디렉토리 에 있으니까 스페셜 파일 이라고 한다.

예를들어 스페셜파일중에 sd0라는 파일이 있는데 이것은 디스크 통째로 하나의 파일로 본다. 우리들이 만든 파일에 그 디스크 속에 있는 쪼그만한 파일이 된다. 그래서 ++ 디바이스를 파일로 맵핑할때를 스페셜 파일이라고 하고, 링크파일은 세미나에서도 했다싶이 바로가기 같은것을 만드는 심볼릭 링크라고 한다.++

++이중에서 알아야 하는것은 디렉토리, 디렉토리도 하나의 파일에 불과하다.++ inode가 있고 #는 번호를 의미한다.
프로세스가 있으면 프로세스를 커널이 관리하기 위해서 프로세스 컨트롤 블락이 있는데 프로세스 마다.
이와 유사하게 파일을 하나 만들면 a.c 라는것을 예로 하나 만들면 edit를 통해서 디스크에 만들어 놨다 그러면 여러분이 만든 파일의 본체에 내용이고 그 파일에 관한 다른정보가 있는데 누가 만들었고, owner는 누구고, access permission (read, write, execute 할 수 있느냐)
언제 만들고, 수정헀는가? 파일의 크기는 뭐냐? 그것을 ++메타정보++라고 한다. 메타 정보를 가지고 있는 정보블락이 필요한데 그것을 리눅스에서는 inode라고 한다.

내가 쓰는 시스템에 파일이 만개가 있으면 inode도 만개가 있다. 디스크에 만든 파일 만개는 여기저기 흩어져 있다. inode는 디스크 속에 array 형태로 있다. 파일 만개에 대해서 array형태로 있기 때문에 array로 있다는것은 array access할때는 index access하는데 0번 inode 1번 inode 2번 inode 쭉 갈것아니냐, inode index, 혹은 inode 번호라고 한다. 따라서, 파일을 access할때 파일을 open 할려고 하면 파일의 이름을 알아야 한다. 어느 디렉토리에 어디에 있는 무슨 파일의 이름을 알아야 하는데 그거 가지고 open을 하면 그 파일에 관한 정보를 알아야 하니까 그것을 inode의 번호로 바꿔야 한다. inode를 들여다 봐야 파일을 access 할 수 있으니까

커널이 생각하는 파일은 inode 번호로 맵핑이 된다.
++
우리는 파일이름으로 어느 디렉토리 밑에 무슨 파일인지를 찾지만, 결국 inode의 번호로 번역이 되어야 한다.++

그게 그 파일의 unique한 identify 역할을 한다.

## (2)
++그래서 디렉토리파일이라는것은!++
예를들어 길동이라는 디렉토리 파일이 있다. 이 디렉토리 밑에 파일이 a,b,c가 있다고 하자. 그러면 길동은 디렉토리인데 하나의 파일에 불과하다. a,b,c라는 파일의 이름을 가지고 있다. 길동은 그 앞에 숫자를 가지고 있는데 이 숫자가 inode의 번호다 이것이다. 

inode가 몇번 파일이고 b는 inode가 몇번이고 c는 inode가 몇번이고 그래야 그 파일을 access하기 위한 다루기 위한 정보를 inode에서 찾아낸다.

그래서 idone 번호를 가지고 있는것이고.
. 이라는것은 자기 디렉토리, 자기 자신을 의미
디렉토리가 파일이니까 역시 디렉토리도 inode가 있어야 한다. 
++
..은 자기의 parent directory 그 디렉토리도 파일이니까 inode 번호가 있다. 모든 파일은 디렉토리 파일이건 스페셜 파일이건 링크파일이건 inode가 있다. ++

커널이 access할때는 그 파일의 이름을 inode의 번호로 바꾼다. 그러한 정보를 가지고 있는게 쌍의 리스트를 가지고 있는것을 디렉토리라고 한다.

## Linux File Types
세미나시간에 말한것이다.
키보드 같은것이 맵핑된 파일이고 
디스크에서 맵핑된 파일도 있고 
파이프 파일이 있고 
바로가기 심볼릭 링크 파일이 있다.
그러나 inode 번호는 있어야 한다.
inode는 지워지면 안되니까 컴퓨터를 껐을때 지워지면 안되니까 inode는 디스크에 있다.
array 형태로 있다. inode 번호를 가지면 그 inode를 찾아낼 수 있다.

## Linux File System: VFS
리눅스 파일 시스템은 Virtual File System 이다.
Virtual 이라고 하는 이유는 유저한테 다 똑같은 struct 다. 이게 윈도우 파일이건 리눅스의 xfs 파일 시스템이건 다 안에 들어가면 내용은 다르지만, 유저는 open read write close할 수 있는데 그렇지만 밑으로 내려와서 파일을 갔다가 open하는데 윈도우스에서 만든 파일을 읽어올때하고 리눅스에서 전용으로 쓰는 만든 파일을 읽어올때하고 read 루틴은 다르다. 파일의 형태가 intenal이다르니까 그래서 파일 시스템 dependent 한것과 independent 한것을 계층으로 나눠서 만들었다.

파일오픈하면 우리는 open을 쓰지만 window 파일이면 open이라는 디렉토리가 되는것이고 리눅스용 파일 open이면 리눅스를 위한 open루틴이 따로 존재해서 따로 콜하게 되는데 그런 계층 구조를 가지고 있다.

파일 시스템에 dependent한 레이어는 무엇이냐?
function point table을 가지고 있는데

## Logical Architecture of the VFS
open, read, write 엘스엘틱 파일 컨트롤(파일에다가 레코드에다 lock걸때 배웠다.) 그 파일에 관련된 시스템콜들이 다 파일시스템마다 따로따로 존재한다.
우리한테는 하나로 보이지만

그래서, 이런것을 리눅스의 Virtual File system이라고 한다.

그래서 dos, minix, ext2, ext3, nfs(네트워크파일시스템)을 위한 
만일에 read 루틴이다. 만일에 디스크 파일 시스템이면 디스크에서 읽어와야한다. 만일에 네트워크 파일 시스템이면 네트워크를 통해서 다른 기기에서 읽어와야 한다. 
++read 루틴이 달라진다.++

그러나 유저는 단 한가지로 볼 수 있다.

## (@)
버츄얼 파일시스템이 있고
버츄얼 파일 시스템은 유저한테 유니크한 인터페이스를 제고아지만 밑으로 내려오면 유닉스 파일 시스템일수도 있고 파일시스템을 다른것으로 쓸 수 도 있다.
그러나 우리가 학기초에 page cache라는것을 공부했는데 디스크에서 읽어올때는 메모리에다 자주쓰이는것들은 미리 일어다 놓는다 했는데 그거랑 똑같다.
그런데 페이지 캐시라는것은 디스크 I/O 줄이기 위해서 존재하는데 나중에 나오겟지만 파일을 OPEN 하는것은 하는일은 파일을 왜 OPEN 하냐? 우선 파일 이 있는지 없는지 파일 이 있으면 이 프로세스가 WRITE 모드로 OPEN했는데 WRITE를 할수있는 프로세스인지 아닌지 ACCESS PERMISSION도 체크해야 한다. 그런것들을 다 체크하고 이 파일을 ACCESS 할려하면 메타정보가 필요하다. 메타정보는 Inode 속에있다. indoe는 디스크속에 있다. indoe는 디스크에 갔다 놓고 그파일을 access할 때 마다 디스크 I/O를 찾아갈려하면 시간이 오래걸린다. 파일을 OPEN한단 말은 ++ 이 파일을 계속 ACCESS할꺼니까 INODE를 당연히 메모리에 가져다 놔야 한다. 그것이 OPEN 하는 주된 작업이다++
파일의 Inode를 메모리로 파일을 access하기 위해서 

그 파일을 open해서 read/write 하는 동안에 inode를 빨리 access하려고 디스크 I/O를 줄일려고 메모리에 가져다 놓는데 그 파일을 CLOSE하고 이 프로세스가 끝나면

++
그러면 Inode 메모리에 있는것을 디스크로 내보내야 하나?
그렇게 할 필요가 없다. 다른사람이 또 쓸수도 있으니까 유명한 파일같은경우는 그래서 inode자체를 메모리에다 캐싱을 한다. 그런것을 inode 캐시라고 한다.++

좌우간 디스크에서 가지고 오는것을 캐싱을 한다. 
디렉토리 파일을 찾아갈려고 하면 아까 어떤 파일을 찾아갈려고 하면 그 파일의 inode index를 알아야하는데 inode의 번호는 디렉토리에 있다. 디렉토리 파일속에 있다.
++
그러니까 디렉토리를 들여다 봐야 이 파일의 inode 번호를 찾을 수 있으니까 그 파일이 거쳐가는 디렉토리도 메모리에 캐싱하는게 좋겠다.++

## File I/O
했던 말이다.
Linux regular 파일은 byte의 stream으로 된다.
byte들이 나열되어있는 
access mthod는
sequential aceess는 읽을때마다 한 바이트씩 가져오자. 앞으로 
randomaccess는 lseek, fseek을 배웠는데 포인터로 왔다갔다하면서 아무대나 random하게 읽을 수 있다.
keyed access는 데이터베이스에서 나온다. 길동의 레코드를 가지고와 하면, 길동의 레코드가 어딨는지를 찾아야되는 전화번호부가 있어야 한다. 그것을 index tree라고 한다.
keyed access는 db 시스템에서 제공하는것이고 os는 1번 sequential access와 2번 random access를 제공한다.

## File Copy Example
n=read(fd1, &buf1, 10) 
10바이트씩 읽으면 읽은 바이트 가 10바이트 이상이면 10바이트씩 다 maximum 이니까 10을 return 할 것이다.
55byte면 마지막에는  5byte가 나오니까 5가 return이 되고 또 읽을려고 하면 0이 return이되고 그것이 eof 이다.

## Linux File System
파일 시스템의 모든 파일은 유일한 메타데이터를 가지고 있는 inode를 가지고 있다. inode는 파일의 헤더 또는 메타데이터인데 모든 파일에 관한 정보를 가지고 있다.
c struct 처럼 생각을 하면 된다.

그래서 뭐가 들어가 있냐면 파일의 이름이 있고 파일 타입여러가지가 있을것이고(레귤러, 디렉토리, 링크파일인지)
이 파일의 만든사람 id가 있어야 한다. access permission(rwxr-xr-x) owner group others에 대한것도 있어야 하고 
언제 생성했는지 언제 access, 수정을 했는지 시간에 관한 정보도 가지고 있어야 한다.
파일의 크기도 가지고 있어야한다.(ls -s 하면 파일의 몇바이트인지 알으켜 준다. 파일의크기)
ls하면 디렉토리에 있는 파일을 보여준다. 그건 디렉토리가 파일이라고 했는데, 그파일을 open해서 거기있는것을 찍어준것이다. ls 라는것은

++file data block addr table++(중요)

## Data Block Addr. Table in an inode(ext2)
이 파일이 디스크에 있으면 디스크에 흩어져있을것이다. 디스크는 무슨 단위로 구성되냐면, 하나의 physical block으로 구성이되고 그것이 4kbyte 라는것이다. 내 파일이 만일에 40kbyte면 10개의 블락으로 구성이 되어있는데 그게 디스크의 한 군데에 붙어있으면 빨리 access할 수 있지만 파일을 지우고 만들고 지우고 만들다하다보면 빵꾸가 많이 나서 결국은 10개의 블락이 디스크에 흩어져 있게된다. 
한군데로 모으는것이 디스크 조각모음 같은것이다.
빨리하기위해서

일반적으로, 우리가 만든 파일은 여러개의 블락으로 구성된다. 디스크에 흩어져있다. 나는 파일이 붙어있다고 생각하면서 무엇을 가지고 access하냐면 r/w offset을 가지고 쭉 access하는것이다. 커널은 r/w offset을 가지고 흩어져있는데를 찾아가야 한다. 흩어져있는 block들을 찾아갈려고 하면 ++주소 테이블이 필요하다.++ 
이파일에 데이터블락들이 10개가 있는데 이 10개가 도대체 디스크에 어디에 흩어져 있는지 그 주소를 아는 주소를 기록한 테이블이 있어야 찾아갈 수 있다. 데이터블락이 몇개로 구성되어있는지 간에 데이터블락들이 디스크 어디에 있는지 ++정보를 가지고 있는 데이터블락 어드레스 테이블이 inode속에 있다.++

이게 제일 중요하다.
이거가 데이터블락, 파일의 데이터블락 어드레스 테이블이다. inode 속에 있는 여기보면, ext2적혀있다.
ext2는 여러가지 파일 시스템중에서 한가지다.
제일 많이 썻던 파일시스템중 한가지인데
ext2에 예를든것이고 요즘 제일많이 쓰는게 xfs인데 그것도 다르다. ext2를 보면, 테이블이 하나가 있고 테이블이  inode속에 있고 15개의 entry가 있다. 첫번째부터 12번째 블락까지 12번째 4kbyte 블락까지는 디스크의 주소를 가지고 있다. 주소가 1개가 잇는데 찾아가면된다. 12개는 흩어져있다. 붙어있을수도있다. 좌우지간 주소를 가지고 있다. 무슨주소? 하드디스크에서의 진짜주소

파일이 12개 블락보다 커지면 다음주소를 가지고 있으면 좋은데 그렇게 하면 inode는 array라고 했는데 array속에 이 데이터블락 addr 테이블이 있는데 크기가 일정한것이 좋다. 크기가 들쭉날쭉하면 array를 만들수가 없다. 하는수없이 indirect addr를 쓰기 시작했다. 포인터같은것들 13번째 블락은 포인터 블락이다. 뭘 포인트하냐면 다른 디스크 블락을 포인터한다. 디스크 블락 어디에 있는것을 포인트하는데, ++이놈은 데이터블락을 가지고 있는게 아니라 128개의 블락의 주소를 가지고 있는 블락이다.++
포인터 블락이다.

13번째 블락서부터는 일로 찾아와서 13번쨰블락이면 요게 제일 앞에 있는것이다. 데이터블락을 찾아가고 128 + 12 에 있는것은 제일 끝에 있는 블락이다. 128개의 블락은 두번 거쳐서 가야 된다. 이거 한번보고 이거한번 보고 찾아가야 한다.

파일이 이것보다 더 커지면 감당할수없으니까 double indirection을 쓴다. 디스크 주소가 뭘 포인트하냐면 128개의 블락을 포인트 하고 128개의 포인터가 128개의 포인터블락을 다시 포인터한다. 그 각각이데이터블락을 가리키니까토탈 데이터블락을 128^2 그게 데이터블락이다.

파일이 그것보다 더 커지면 triple indirection을 쓴다. 포인터 블락을 포인터하고 요것이 다시 128개의 포인터를 포인터하고 요놈이 128개의 포인터를 또 포인터해서 이놈이 데이터블락을 포인터하니까 이러면 토탈 128개의 3승개까지 데이터블락을 포인터할 수 있다. 

## Data Block Addr. Table in inode
리눅슨느 ext2를 예전에는 썻엇는데 위의 형식처럼 만들었었다.
++
inode속에는 15개가 들어가 있는것이다. 토탈 포인트 할수있는것은 12개 더하기 128개 더하기 128개의 좌승더하기 128의 3승개의 데이터블락을 포인터할수있다.++
이것은 장단점이 다있다. 리눅스나 전신이 유닉스같은것은 옛날에 주로 상업용으로 쓰이는게 아니라 대학교같은곳에서 연구용으로 쓰이는것이었다. 굉장히 큰 데이터를 취급할 필요가 없었다. 작은게 아름답다. 
파일이 작으면 빨리 찾아갈수 있다. 파일이 커지면 저 맨뒤에있는 홍길동의 데이터는 여러번 디스크 I/O를 해야 데이터블락을 찾아갈 수가있다.

파일이 커지면 느려진다. 맨뒤에 access할려면 느린데 사실은 그것도 sequential access를 하면 이것도 디스크에 다 있는거다. 포인터블락도 캐싱이 되니까 sequential하게 하면 좀 나은데, 왔다리 갔다리 하면 random access하거나 db로 access하게 되면 캐시에 다 들어갈수가 없으니까 할때마다 이거 읽고 이거 읽고 읽고 되니까 디스크 하나access하는데 길동의 레코드처럼 맨앞에있는거는 빨리나오는데 홍길동처럼 뒤에있는 레코드는 무지하게 시간이 오래걸리는 단점이 있다. 큰 데이터베이스 같은경우 큰 파일을 만들때 이런구조는 좋지 않다.

숙제로 간단한 파일을 만들때는 빠르다.

이러한 인덱스 구조를 보면, 이렇게 되어있다.   
트리구조면 한쪽으로만 나무가 자라는쪽 맨앞에 access는 빠른데 뒤에있는것을 access하면 무지하게 느리다.
단점을 가지고 있다.

밸런스가 안맞는 트리다.

밸런스드 트리는 이렇게 되는것이다. 인덱스 구조를 이렇게 만들면 맨앞에 길동을 access하거나 뒤에있는 홍길동 access하거나 걸리는 시간이 depth가 똑같으니까 같다.
이런것을 밸런스드 트리

밸런스드 트리에는 b트리가 있고 b+ 트리가 있는데 큰데이터베이스에서는 b+ 써야 한다. 이런식으로 만든것이 ext2 파일시스템 나온다. xfs 에서는 b+트리 구조를 쓴다.
++
데이터버퍼 address 블락이 ext2와 같은것은 굉장히 큰 데이터베이스에서 쓰기 곤란한다. 그래서 most db system에서는 b+ 트리 스트럭쳐를 쓴다.++

파일시스템이 발전을 해 나가는데 ext2 다음에 나오는것이 ext3 이다. ext3는, ext2는 똑같은데 여기에다 journaling을 한것이다. journaling을 서포트하는건데 저널링은 파일을 하나 쓸때 쉽게 말할때 단데다 백업쓴다. 어디다 뭘 썻는지 기록해준다. 로그같은것을 남겨서 만일에 파일시스템이 깨져도 복구할 수 있는 수단이있는것을 저널 링 파일시스템이라고 한다. 파일을 어디로 어떻게 썻는지 로그를 전부다 남긴다. 그것을 저널이라고 한다.

로그같은것을 남기면 저널이라고 했는데 깨져도 이것을 보고 다시 파일시스템을 복구할수가 있다.

ext4는 : ext3+ btee를쓰는것이다. 요즘 많이 쓰는것은 모든 기능에다가 인덱스들을 비플러스 트리를 쓴것이 xfs 파일 시스템이다. 이것은 디스크가 깨져도 복구가 가능하다.(저널링 파일 시스템이라고 한다. 디스크가 깨져도 복구가능한것이)

## Linux File System
실제로 ext2 파일시스템 inode를 한번 뽑아본것이다. inode에 뭐가 들어있는지

## In-core inode
그래서, 파일을 오픈하면 파일을 오픈하면 파일의 이름을 가져다 pass name을 inode를 번호로 변환한다 inode를 메모리로 가져다 놔야한다. 체크같은것을 하고 메모리로 들어오는 inode를 in-core inode라고 한다. 원래는 디스크가 있었는데 파일을 오픈하면 inode를 왜냐하면 inode를 봐야지 파일을 access 하든지 아까 주소 테이블 같은것이 있으니까 indoe가 반드시 있어야 하는데 매번 access할때마다 inode를 거쳐야 하기때문에 메모리에 가져다 놓는데 그것을 in-core inode이고 이것을 inode-cache에 소속이 된다.

파일을 오픈할때는 파일의 이름이 inode 번호로 변해야 하고 inode 번호를 가지고 inode를 메모리에 inode cache에 가져다 놓고 나서 파일을 access하기 시작한다.

## Disk File System
디스크 파일 시스템을 보면 하드디스크 하나해도 윈도우 같은거보면 cde를 파티셔닝을 하는데 디스크는 하난데 여러개의 디스크 인것처럼 쓰져.
그 파티셔닝 이라는것은 트랙을 나눠둔것이다.
하드 디스크가 이렇게 있으면 여기서 부터 여기까지 c
여기서부터 여기까지는 b 이런식으로 쓴다. 파티션이라고 한다.
파티션은 맨처음에 시스템을 만들때 고정을 시켜버리고 크기가 변화할수가 없다. 여기서 얘기하는 파일시스템은 하나의 파티션을 말한다. 

윈도우스에서 파티션을 가져다 디스크 포맷팅한다고 물어볼때 부팅을 할수있게 할까요 물어보는데일반적으로 파티션의맨앞은 Boostrap Loader가 들어간다. 제일 앞에
Boostrap Loader가 먼저 메모리로 올라가서 커널을 메모리로 읽어 들이는 loader을 의미한다. 
그래서, 이게있으면 부팅이 가능하다.

그다음에 밑에서부터 보면 data area가 있는데 우리가 얘기하는 4kbyte 블락짜리가 쭉있는것이다. 디스크에 

그위에는 indoe area 에는 inode가 들어가는 array가 있다. array가 inode가 만약에 만개짜리 array면, 이 디스크에는 파일을 만개 이상으로 만들수가없다. 왜냐하면 모든 파일을 inode를 하나씩 가지고 있기 때문에 inode의 array

그러면 파일을 새로만들려고 하면 안쓰는 inode를 하나 찾아야한다. 그다음에 파일에다가 파일에 데이터를 디스크 에 쓸려고 하면 요 데이터 블락 중에서 쓰인게 있고 안쓰는게 있을것인데 안쓰는것을 찾아야 하는데 
파일을 지우면 그안에 node를 찾아가서 free하다고 만들어 놔야 한다. 

그러니까 os는 반드시 inode array중에서 어느 부분이 쓰는것이고 안쓰는것인지 알아야하고 데이터 블락에서도 어떤게 사용중이고 어떤게 사용중이지 않은건지(free한지) 알아야한다. 그런정보가 super block에 있다.

super block은 inode중에서 inode area 중에서 쓰는 inode는 어디에 있고 안쓰는 inode가 어디에 있는지 지도를 가지고 있다.

그담에 데이터 area 중에서 쓰는게 뭔지 안쓰는게 뭔지 사용할 수 있는 데이터블락의 뭔지를 map을 가지고 있다.

포맷팅을 할때 long 포맷이 있고 짧은 포맷이 있는데 롱 포맷팅이 뭐냐면 포맷팅 한다는것은 디스크를 싹 전부다 free한걸로 만드는데 free한것으로 만들때 free라고 표현하는게 아니라 거기다가 쓰고나서 읽어보고 error가 없는지 체크한다. 그게 16번 을 반복한다. 그래서 error 가 없으면 그블락은 앞으로 사용하는것이고 error있으면 bad block이라고 한다. bad block은 건너뛴다. 디스크는 못쓰니까 고장나니까 bad block 정보도 super block에있다.

그런데 super block에 bad block이 생기면 감당이 안된다. 디스크를 버려야 한다. (약간 관리자 느낌이네..?)

질문있다. 
inode는 파일시스템마다 조회가능
c에서 부팅, d에서부팅 가능하다. bootstrap 을 만드냐 안만드냥 따라서

shell에다 display를 요구했다. 루트 밑에 sp 밑에 디렉토리 밑에 sp.cpp 디스플레이했다. open 했다. 프로그램속에서 해당파일에 inode 번호를 알아서 inode 가지고 와야 한다. inode 번호를 아는과정을 그림으로 나타냈다.
## Hierarchical Directory Support
루트니까 루트는 디렉토리잖아
디렉토리가 file이라고했으니까 루트 디렉토리 inode가 있다. 루트 라는 파일에 디렉토리 파일 inode는 통상 2번이다. 왜 2번이냐 0번이 아니라 만들때서부터 0,1 또다른걸 생길지도 모르니까 2번으로 주었다.

inode array 디스크에 있으면 2번을 찾아간다. root 봐야 하니까  여기가면ㄴ
이 파일은 디렉토리 파일입니다. 이런 정보가 있고 inode속에는 루트라는 디렉토리파일이 디스크 어디에 있는지 나타내는 테이블이있다고 했는데(그게 b+트리일수도록, 인밸런스드 트리일수도있고) 그정보를 가지고 디스크에 실제로 데이터블락속에 있는 루트 라는 디렉토리 파일을 찾아갈것이다. 주소가 있으니까 찾아가면 루트라는 디렉토리 파일에는 . 나자신을 2번 inode 번호이고
..은 루트위에 자기랑 똑같은거니까 2번이고 sp라는 파일이 하나 있는데 이거에 inode는 10번이다 있다는것이다. 이것만 봐서는 디렉토리인지 아닌지 알수없다. 여기서 10번이구나 sp니까 찾아가지고 10번을 찾아가면 이것은 디렉토리다. 이 디렉토리 파일은 어디있다 라는 주소가 있을테니까 이것을 가지고 또 찾아가면 . 자기자신은 10이고 ..은 2번이고 sp.cpp 파일이 하나 있는데 inode가 105번이다. 105번을 찾아간다. 여기에는 regular file이고 이렇게 되서 파일을 쫓아갈수가 있다.

그런데 이것을 뭐라고 하냐면 루트밑에 쭉 찾아오잖아 찾아와야하니까 이것도 디스크에 있고 이것도 디스크에 있으니까 디스크I/O를 굉장히 많이 해야한다. ++좌우간 디렉토리 트래벌스 라고한다.++ 디렉토리를 뒤진다.

디렉토리 트래벌스는 이런식으로 하면 디스크 I/O가 많이 일어나서 그래서 디렉토리 캐시가 있다. 자주 쓰이는 디렉토리에 대한 정보를 메모리에 가지고 있어서 이게 만약에 current directory가 있잖아 들어가면 현재 디렉토리 했잖아 현재 디렉토리 내용은 캐싱이 되어있어서 빨리 찾아갈수가있고 디렉토리 캐시는 네임캐시 라고도 하는데 이것은 현재까지 자주 쓰이는 파일을 이름을 가지고 inode 번호를 찾을 수 있는 해시 리스트를 만들어 놓는다 파일이름하고 자주 쓰였던 파일에 inode 번호를 갖다가 캐싱을 해놓는데 그것을 디렉토리 캐시라고 한다. 다른 말로 네임 캐시다.

일단 이렇게 하면 루트 밑에 sp 밑에 sp.cpp 이렇게 하기전에 디렉토리 캐시를 뒤진다. 그래서 이파일을 예전에 누가 썻으면 거기에 inode 번호가 105로 남아있다. 디스크 i/o를 할필요가 없으니까 
그런데 없다라고 하면 없으면 이걸 해야함. 찾아 내려가서 105번을 찾아 내야한다.

그담에 105번을 찾아냈으면 이 파일을 access할꺼니까 105번에 해당하는 inode를 메모리로 가지고 와야 한다. 가지고 오기전에 또 이 파일을 누가 썻을지 모르니까 inode를 캐시에서 찾아봐서 있으면 쓰고 없으면 디스크에서 가지고 온다.

전부다 캐싱 시스템을 이용해서 디스크i/o를 줄이기 위해서 애쓰고 있다.

우리한테 제공되는것은 hierarchical 한 파일 시스템이다. 우리가 보기에는 파일시스템이 루트밑에 뭐가 있고 .. 계층구조 디렉토리를 쭉 찾아서 내려가는 파일시스템이 제공되는데 보는데 실제로 커널 이 볼때는 ++flat file system 이다.++
flat이라는건 평평하다. 왜 평평? 그냥 inode array이니까 inode가 10000까지 있으면 0번 부터 10000까지 array에 담기는거니까 그냥 flat하다.

계층구조가 아니다. 우리한테는 계층구조 파일 시스템을 제공하지만 커널이 실제로 inode를 볼떄는 파일 시스템 array 본다.


## Incore data structure to access a disk file
세미나를 하거나 shell 한것을 하면서 pcb속에는 open file table 이 있다고 했다. 정확히는 open file 디스크립터 테이블. 
리눅스에서는 pcb를 task struct라고 하는데 이 array를 읽는건지 pointer를 읽는건지 찾아봐야 함
0번은 stdin
1번은 stdout
2번은 stderror
이렇게 되어있다.

이 프로세스가 x라는 파일을 두번 오픈했다.
그러면 3번에도 x가 오픈되어있을것이고 4번에도 x가 오픈되어있을것이다. 3과 4에 x가 들어있다.

core process라는 말이 나와있다.
pcb속에있으니까 프로세스 입장에서 본것이다.
x를 이놈만 오픈하겠냐 ? 다른 프로세스도 오픈할 것이다.
이프로세스가 fork를 해서 자식프로세스를 만들면 그놈도 open해서 그대로 쓴다고 했으니까 걔는 이것을 카피해가는것이다. 이것은 프로세스별 입장에서 본것이고 

커널의 입장에서는 프로세스가 100개가 있으면 100개의 프로세드들이 오픈한 파일들에 관한 정보를 몽땅 다 가지고 있어야 할 것이다. files sturct 라고 한다.

링크드 리스트인지 테이블인지 구현하기 나름이고, system wide 커널 전체를 다 가지고 있다는 의미다. 모든 프로세스가 모든 오픈한 파일들에 대해 정보를 테이블이 다 가지고 있다. 시스템 전체에 대한것을

여기서 x를 오픈했으니까 여기도 있겠다. (sys - wide) 그런데 여기서 한번 더 오픈했다. 여기서도 다른 자리를 차지 한다. x를 두번오픈하면 그건 나중에 알게되겠지만 file offset이라는 것은 read/write offset 이다. read write offset이 syste wide에 있다. 

파일을 오픈할때마다 하나씩 read/write offset이 하나씩 생긴다고 했는데 3번으로 access할때와 4번으로 access할때 포인터가 r/w offset이 서로 다르다.

그러니까 system wide에서도 따로 생기는것이다.

포인터로 가지고 있다.

offset까지는 유저가 보는 논리적인 뷰인데 실제 디스크 주소가 아니라 유저가 보는것을 실제 디스크 주소로 번역해야한다. 번역을 하기위해서는 address table이필요하다. 이걸 찾아갈려고 하면 inode를 들여다 봐야 한다. inode 캐ㅣ속에 inode가 들어와있다.  x라는 파일에 

inode라는것은 여러개가 있을 필요가 없다. 여러명이 x를 오픈했다 치더라도 x라는 파일에 inode는 하나만 메모리에 들어와있으니까 

그래서 이것은 incore inode다 .
inode에 디스크 블락 어디레스 테이블이 있고 요것은 각각 
inode를 가리키고 있다.

파일을 open하면 x가 생기는데 read를 하면 x가 이걸 쫓아가서 여기서 read/write offset을 얻고 이것을 가지고 inode를 찾아가서 실제 디스크 주소를 찾아내는 메커니즘이 이렇게 구성된다.

여기에는 항상 count라는것이 있는데 reference count다. 나를 포인터하는놈이 몇개 인가를 나타낸다. 나를 하나만 포인터한다. 
inode는 count가 2다. 나를 포인터하는놈이 2개니까 
내가 3번 채널을 close했으면 없어질것이고 3번해당하는 file offset도 없어질것이고 (reference count를 빼기 -1을 한다. 0이 되면 아무도 안쓰는거니까 없어진다)이것을 inode로 쫓아가서 reference count를 1을 빼면 아직도 1이니까 쓰는놈이 남아있다. 내버려두고 
4번도 close하면 inode위치의 count도 0이될것이다.

그러면 얘는 쫓아낼수도 있는거지만 ++메모리가 허용하는한은 캐시니까 남겨둔다.++

## 같은 그림
같은그림인데 프로세스 A가 파이프 숙제했던것처럼 파이프를 OPEN하면 파일이 2개가 오픈된다. 3번에 fd[0] 하고 4번에 fd[1]이 오픈된다. 파이프는 read write offset을 따로쓴다고 했으니까 그러면 files에 각각 다른 offset을 가지고 있다. 따로 생긴다. 이것은 inode를 가리킨다.

프로세스 A가 포크를했다. 자식프로세스가 생기는데 child가 생기는데 항상 배울때 fork한 child 프로세스는 parent가 오픈한 파일을 몽땅다 물려받는다. execv해도 물려받는다. fork를 해도 물려받는다.

물려받는다라는것은 물려받는다 라는것은 child의 pcb속에도 open file table이있다는것이다. 프로세스니까 이것을 가져다 일로 복사한다. 물려받는의미가 이것이다.

stdin, stdout, stderr도 같이쓴다. fd[0]도 같이 쓰고 fd[1]도 같이쓰는데 포인터도 복사했으니까 얘가 어디로 포인터 하냐면 동일한 r/w offset을 가리킨다. 

이러면 이 reference count가 2가 된다. 저게 2가 되는경우는 바로 parent가 open 해두고 fork해서 child가 또 사용할 경우에 누차 말하지만 parent와 child는 r/w offset을 공유한다고 한 이유는 같은곳을 포인터하기 때문에 r/w offset을 공유하는것이다.

왜냐하면 r/w offset이 중간에 있으니까(중간 system wide)

parent가서 이놈이 쓴놈이면 close를 하는데 얘만 지워지지 다른애는 지워지지 않는다.  그러니까 fd[0]을 지워도 child에 fd[0]는 지워지지 않는다. reference count가 1감소될뿐이지. 

fork 하기전에 close를 해버리면 write놈을
fork를 해도 읽는애만있고 write하는 애가 없어져 버린다.

링크 리스트, 트리, 해시 같은거 쓰고..
## open() syscall
open system call에서는 무슨일ㅇ ㅣ일어나느냐
파일이름이 들어오고 inode의 번호를 얻어야 하는데
그것을 하기위해서 이름 하고 inode를 ㄴ매칭한것을 자주쓰이는것을 기록해두고 캐시에서 찾는데 디캐시(아까는 디렉토리 캐시) 라고 한다.
여기서 못찾으면 그림에서 나온것처럼 루트서부터 팔로우업을 해야한다. 할숭벗이 디렉토리 트래벌스라고하고 

inode 번호를 알면 그러면 역시또 inode 캐시를 찾고 없으면 또 inode를 디스크에서 가지고 와야 하는데 inode 캐시에서 inode 같은것을 찾을때는 자료구조 시간에 배웠던 헤시 알고리즘을 쓴다.

++
그렇게 해서 얻으면 pcb 구조를 만들어서 파일에다가 x에다가 write하면 쫓아가서 read/w offset을 얻고 이것을 가지고 inode를 찾아서 거기서 실제 pysical한 addr를 얻는다.++

pysical addr 얻으면 또 페이지 캐시에서 또 찾아본다. 
없으면 디스크에서 또 찾아와야 한다.!



## close() syscall
close할때는 파일 디스크립터에서 하나 지우고 파일 테이블 엔트리에서 reference count를 하나 줄이고 그래서 0이면 없애고 inode table에서도 reference count를 하나 줄이고 제거가 됬다고 하더라도 가능하면 나중에 사용하기 위해서 inode cache에다가 keep을 한다

## Kernel Actions to Reduce Disk I/O
아까 네임 캐시라고 하는것은 dcache이다. 파일이름하고 inode 번호를 씌였던것을 기억한다. 캐시가 되겠고

페이지 캐시는 디스크 블락을 위한 캐시고 

inode는 inode를 위한 캐시다.


이거 외에도 디스크 I/O를 줄이기 위해서 메모리 management에서도 페이지 캐시를 쓰고 디스크에서는 디스크 스케쥴링 이라는것을 다음학기
## Others(covered in OS lecture)
요새 많이 쓰는게 ssd
또는 emmc 라는 flash storage가 있다.
그래서 이것을 쓰는데 이것에 관한 내용은 os시간에

nand flash memory로 만든게 ssd인데 노트북에서 쓰는게 디스크처럼 느리지 않다. 쓰는데 한계가 있다.
몇만번 쓰는데 한계가 있다.

더중요한 특징은,  디스크는 읽거나 쓰거나 느리는게 단점이지 시간은 같은데 nand flash memory는 읽어오는건 1byte만 읽어와도 블락을 읽어와도 dynamic memory 처럼 빠르다. 1byte를 쓸려고하면 4kbyte를 다 지워야 한다. 지우고 새로 써야 한다. 그게 nand flash memory 의 write의 특성이다. 

read는 엄청 빠른데 write는 거기에 비해 느리다. 그래도 디스크 보다 빠르다. 빠르지만, write 를 많이 하게 되면 nand flash 입장에서 골치아프다.

그러니까 중간에 1byte쓰는것을 모았다가 버퍼링을 했다가 한번에쓰는 게 훨씬 낫다.
일반적으로 os는 하드디스크는 지원하니까 하드디스크 코드가 들어있다. 거기에 붙일려고 하니까 flash memory에
그러면 os를 뜯어고쳐야 한다. 그게 골치아프니까 write할때 버퍼링하는것을 하드웨어로 만들어벼렸다. flash memory 속에다가 ssd 속에다 만들었는데 flash translation layer라고 한다.

