---
post : layout
title : 빅데이터3
---

## Refinement: Combiners
맵 리듀스는 이론이다. 분산 프레임 워크이론이다.
프로그래밍 모델이다.
이론이다. keep in mind, 실제 이론을 어떻게 쓰이는지 대해서 보여주는게 하둡이다.

combiner 라는것은 맵이 어떤 인풋데이터를 받아서 key-value 뿌려줄때 key-value 아웃이 굉장히 많이 나옴.
같은 word가 계속 나온다 map입장에서는 같은 word 1 같은 word 1 외대 1 외대 1 계속 반복된다 따지면 비효율적이다.

네트워크를 낭비한다. 그런경우가 생겼을때 어떻게 효율적으로 처리할 수 있을까
combiner이다. 아웃풋을 컴바인한다.

key값에 대한 아웃풋 나오는 값이 원래는 word랑 word 1 나온게 
value 여러개 쭉 나오는것을 얘입장에서 얘를 1 처리 해버린다.
워드 카운트 입장이니까 얘를 , reducer는 우리가 짜기에 따라 다르다. 
combiner는 데이터 줄여버린다. word count일때 얘를 쭉 더해버린다. 
외대 1 외대 1 외대 100으로 줄여든다. 

하나로 줄어든다. 데이터를 네트워크를 통해서 리듀서에게 던져준다. 
엄밀히 말하면 실질적으로 작동하는 방식으로 따져보면 맵퍼가 리듀서에게 데이터를 던져주는것이 아니다.
맵퍼는 일이 다 끝나면 로컬에 적고 끝난다. 그러면 리듀서는 그 데이터를  가지고 네트워크를 통해서 와서 리보트하게 패치를 해서 가지고 가는것이다. 이게 shuffle이다. 

이런식으로 데이터를 줄여서 네트워크 사용량을 줄일수있다. 클러스트 상에서 네트워크 바틀렉이 큰 문제가 생긴다.
데이터가 네트워크를 congestion 시켜버리면 실제 프로세싱 타입이 굉장히 느려진다. 데이터 왔다갔다 하는짓때문에 빅데이터 프로세싱이 느려진다. 그거에 대한 해결할 수 있을지에 대한 아이디어가 계속 나온다.
한가지 방법이다.

++combiner는 reduce function이랑 같다고 나오는데++

왜냐하면 리듀서가 해야될 일을 pre-processing을 해주는것이다.
어떤면에서보면 세미 리듀서 라고도 얘기를 한다.
a.k.a semi - reducer

워드 카운트 예를 보면
같은 단어가 나오는데
foo 1
car 1
컴바인을 하면 합쳐버린다. 합쳐버리고 나면 리듀서가 shuffle 과정을 통해서 패치해서 자기가 가지고 가버린다. ++맵퍼가 리듀서로 데이터를 던져주는것이 절대 아니다. ++ 
++리듀서는 자기가 하고 끝이다.++
그리고 나서 main 노드에게 알려준다. reduce는 프로세싱이 끝났다. 아웃풋 데이터가 어디에 있어 그러면 mapper하는일은 끝이다. 
++
분산환경에서는 그런 일들이 명확하게 각각 노드가 해야할일이 나눠져 있다. 그러고서 끝이다.
reducer가 main에게 mapper일 다 끝났니 하고 물어본다.
다 끝났어 하면 output 값이 어디에 있니
어디 패스 에 있다고 알려주면 reducer는 내가 그값을 가지고 올게 이렇게 작동된다.++

빅데이터 , 병렬 프로세싱이 돌아간다.

shuffle단계에서 네트워크 congestion을 굉장히 줄일 수 있다.
## Refinement: Partitioner
또다른 방식이다. 파티셔너이다. 파티션이다. 
말그대로 나눈다 라는 의미다.
맵퍼가 일을 끝을 냈는데 리듀서 입장에서는 아무 데이터나 지가 가지고 오면 더 힘들것이다. 복잡해진다.
리듀서 입장에서는 기왕이면 같은 key를 갖고있는 놈을 본인한테 가지고 오는게 나중에 최종 데이터를 내뱉을때도 솔팅이나 할때 유리하다.

그렇기 때문에 맵퍼입장에서 결과적으로 아웃풋 을 만들어가지고 로컬 데이터에다 쓰고 말지만 리듀서가 데이터를 fetch해 갈때 얘한테 알려줘야 한다. 리듀서 입장에서는 자기의 로컬도 어딘가 있을 수 있지만 다른 네트워크에 있는데 다른 노드의 있을 확률이 더 높다. 그 애한테 알려줘야 한다. 너를 요 데이터를 갖고가 , 이런 아웃풋이 나았을때 아웃풋에서 파티션을 나눠서 너는 요 파티션의 데이터만 너가 갖고가 라고 알려줘야 한다. 파티셔널 한것은 옵션이다. 
컴바이너는 필수요건이 아니다. 옵션이다. 성능을 높히기 위한 옵션이다. 파티션도 마찬가지다. 

맵퍼가 key-value 중간값을 내뱉고 나면 얘를 갔다가 어떤 key를 갔다가 어떤 리듀서 에게 줄지를 결정을한다. 파티셔너가 
데이터가 파일인데 그 파일을 갖다가 쪼개서 요 부분만 니가 가지고가 라고 알려주는 파티셔너인데 

파티셔너에 관한 함수가 있는데 해쉬를 쓴다. 해쉬를 써야한다.
같은 키를 갔다가 같은 리듀서로 던져주도록 코딩을 해봐 하면 해쉬를 한다.

해쉬는 같은키에 대해서 같은값을 낼것이기 때문이다.
끝에 mod가 있다. R만큼 나눠죠 왜 reducer 개수가 R개 니까 R은 리듀서의 개수이다.
파티션을 나누긴 나누는데 리듀스 개수만큼 나눠야 한다. 
리듀스가 예를 들어서 10개인데 파티셔너를 넣고 20개로 나눠봐야 의미가 없다.
그래서 키를 가져다 해쉬를 해주고 그러면 같은 key끼리 모일것이다. 같은 key끼리 모아두면 누구한테 얼마만큼
당연히 reducer 개수만큼 나눠줘야한다. 그래서 저렇게 붙는다.

이 해시를 하는것은 우리가 맘대로 만들수있다. 정해진건 아니다.
예를들면 빅데이터처리할때 웹 로그 같은게 있는데 이것을 프로세싱 하면 url을 다루게 될것이다. 어떤 웹페이지가 가장 인기있는 웹페이지냐 상식적으로 웹 로그 긁어와서 프로세스 했을때 어떤 특별한 그런 도메인을 갔다가 찾아냈을때 이  카운트가 가장 높은놈이 가장 인기있는 웹페이지일것이다.

그런 처리를 맵퍼로 한다했을때 url을 다뤄야한다. url을 키로 주고싶을때 키값을 url로 줘서 호스트 네임 -url을 줘서 해시를 할수도 있다. 

그래서 이 속의 key값을 어떻게 주는거는 우리들의 app에 따라 달려있다. 다만, ++ 맵퍼가 리듀서가 알아서 가지고 가도록금 기왕이면 같은 키를 갔다가 모아서 리듀서가 가지고 갈수있게끔 만들어주는게 파티셔너의 역할이다 ++

# Problems Suited for MapReduce

## Basic MapReduce patterns
빅데이터 처리할때 카운팅을 한다던지, sum 한다든지
로그분석하거나 데이터 쿼리를 다룰때
collating은 똑같이 마찬가지다. 똑같이 모은다라는건데 ETL이라는것은 데이터 베이스 시간에 배운다.
extract하고 데이터를 데이터베이스에서 extract하고 그 데이터를 우리가 원하는대로 transform을 해서 처리를해서 그리고 다시 데이터베이스에다 다시 쓰는 과정 load 이것을 etl 이라고 한다.

그런 app 같은데서 많이쓰고
filtering (grep, 어떤 데이터를 가져다 필터를 아웃할때도 많이 쓴다. 맵퍼에다가 필터의 기능을 구현을 하면된다.) 
그러고 분산환경을 분산 테스크를 execution할때 시뮬레이션하거나 
아니면 소팅, 기본적인 소팅함수가 내장되어 있다.
하둡코드를 보면 merge sort를 쓴다.

## Not-so-basic MR patterns
Iterative messaging passing - 반복적인 데이터 처리이다. 데이터가 맵핑되고 나와서 reducer로 들어가고 reducer가 처리되어 가지고 아웃풋을 내고 끝나는게 아니라 이 끝난것이 다시 맵퍼에 인풋으로 다시 들어가서 다시 처리를 하고 리듀서도 다시 처리한다. 이게 알파고에서 많이 쓴다. 머신러닝에서 많이 쓴다. 그런식으로 계속적으로 학습을 해야하기때문에 인풋데이터가 들어가면 학습된 결과가 나오고 결과를 다시 인풋으로 넣고 다시 처리를 하고 학습을 시키고 인풋이 다시 나오고 여러단계에 반복적인 일을 담당한다. 이게 머신러닝의 기본이다. 이게 맵 리듀스 프레임 워크에 잘맞지는 않다. 

잘맞는 프레임워크는 아니다. 하둡같은 그런 애플리케이션 라이브러리를 만들어서 올립니다. 기본적으로 아무리 그위에 새로운 프레임 워크를 올린다 치더라도 기본적으로 하둡은 반복적인 iterative한일은 잘 맞지 않다.

맞지 않다. 하지만 할수는 있다. breadth-first-search를 짤때는 recursive하게 짠다.
그런식으로 iterative 일을 할때는 맞지 않다.

Cross-correlation도 마찬가지다. 어떤 cross-product 같은 join이나 db에서는 얘기하는 cross product 같은 경우 할수는있는데 잔머리가 필요한 application이다.
Cross correlation detects the number of times two things occur together. For example, in the Amazon dataset, if two buyers have bought the same item, we say that they are cross correlated. Through cross correlation, we count the number of times two customers have bought a same item.

## Reading
우리가 지금까지 다룬 맵 리듀스, 맵리듀스는 저 페이퍼는 굉장히 it 쪽에서는 기념비 쪽은 페이퍼다.
놀라운 아이디어는 몇년에 한번이다. 저 페이지 로 인해서 하둡이 나온다.
이 페이퍼를 배운것이다.

이론만으로는 부족하다.

# Hadoop
맵 리듀스 페이퍼를 야후 사람이 만든다.
더그 클락팅??
데이터를 어떻게 저장하고 관리할 것인가? 에대한 storage
데이터를 저장을 했으면 그거를 읽어내서 처리를 할것인가
두가지 프레임워크를 합쳐놓은것이 하둡이다.
맵 리듀스 페이퍼를 보고 실제 프레임 워크이다.

하둡이 제일 유명함

병렬처리가 가능한 프로그래밍 api이다. 구글이 만들어놓은 맵리듀스라는 페이퍼이론을 가지고
gfs : 구글이 만든 파일시스템이다. 그런 파일 시스템과 
구글이 만든 빅테이블이다. 나온 프레임워크이고 구글에서 사용하고 있다.

구글에서 사용하고 있다. 페이퍼를 통해서 유추할 수 있다. 

빅테이블 데이터를 저장하기위한 storage api, mapreduce는 분산처리하기위한 프레임 워크 
데이터를 저장하고 읽고 써야한다. 그것을 파일시스템이 당연히 해야하고 storage 모델이 존재한다.
gfs와 bigtable이 있으면 빅데이터를 효율적으로 저장을 하고 access하고 manage 할지에 대한 그런것이 갖춰진다. 기본 프레임워크에 데이터를 뽑아내서 어떻게 처리할꺼냐 그것이 map reduce다.

더그킹이라는사람이 하둡이다.

## Why use hadoop?
scale out => 싼기계를 여러개 붙인다.(병렬처리) 이것이 하둡이다. 통상적으로 컴퓨터를 여러개 넣는게 성능이 linear하게 증가한다. 비싼 머신을 쓰는게 아니라 싼머신을 병렬처리 한다. 싸다. 그런 의미에서 cheaper 의미
당연히 빠르다. 분산처리 & 병렬처리하니까 성능 좋다.

scale up => cpu를 좋은거 써도 많이 올라가지 않는다.

빅데이터 처리에 잘맞는 프레임 워크다.
## Hadoop History
nutch, 웹 크롤링 을 만들고 있다. 데이터를 가지고 올때 어떻게 처리할까 막막
nutch에서 hadoop을 독립시킨다. 성능이 너무 좋아서
ny times 이미지 백업을 pdf 로 바꾸고 싶어하는데 4TB 양이다.
하둡이라는 프레임워크를 받아들인다.
EC2s 아마존에 클라우드 서비스, 아마존에 100개의 노드에다가 하둡깔고 분산 작업을 처리한다. 4TB 를 pdf로바꾸는데 36시간 걸린다. 3달치작업이었다.
아파치에서 야후로 Cutting을 데려간다. 
모든 데이터들은 그때 당시 sql 로 집어넣었다. sql을 다룰수있는 방법이 없어서 페이스북이 만든게 Hive이다.
1TB Sorting 하는것이다. benchmark가 있다. 빅데이터를 처리하는데 기준점이 있는게 Terasort라는것이 있다. 1TB 던져주고 누가 제일 먼저 srot 하는지 벤치마크가 있다. 경쟁력으로 많이했다. 910개 노드를 묶어서 3.5분 만에 처리 완료
읽고, 소트까지 해야하는걸 몇분만에 끝낸다.
1460개 노드를 묶어서 62초만에 끝낸다.
PB도 16시간만에 끝냈다.