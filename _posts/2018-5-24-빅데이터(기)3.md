---
post : layout
title : 빅데이터(기)3
---

## k-means 알고리즘

## bfr 알고리즘
k-means 알고리즘에 변형본임
k-means 알고리즘은 메모리에 다 올라가고 가정을 하고있어서 큰 사이즈 데이터를 다루기에는 클러스터상에는 적합하지 않음 굉장히 크다라는게 사이즈라기 보다는 메모리 로드 힘듬 양이 많음
통상적으로 큰 양의 데이터양은 storage 저장되기 마련
그 정도의 양을 클러스터 할 때 쓰는 k-means의 확장판임
addr 버전임 얘같은경우 strong assumption 임 가우션 분포를 따르고 있다고 가정을함
굉장히 틀린건 아니다. 왜냐하면 클러스터링 자체가 센트로이드가 있으면 값이 모여있으면 그것을 우리가 만듬
센트로이드 중심으로 값이 모여있는것을 우리가 만듬
센토로이드 입장에서 가우시안 분포가 틀리지 않음
가우시안 노말 디스트리비우션을 따른다.

그리고 mean이나 stadard devation은 각각 클러스터마다 다름
클러스터가 있을때 서머링 하게 되는 서머링 = 메타데이터 인폴메이션 클러스터를 가져다 서머링을 하게 되는 방법
굉장히 명확한 방법을 가지고 있다. bfr 알고리즘의 경우는
이거 같은 경우는 shape 자체가 타원이나 원형이나 그런 클러스터 모양을 가정을 한다. bfr 알고리즘, k-means 도 마찬가지로 센트로이드 를 기준으로 가깝냐 머냐 디스턴스를 따져서 그러 원형이나 타원밖에 나올 수 밖에 없다. 한점을 기준으로 거리를 매기기 때문에

얘네는 축자체가 타원형 자체가 어떤 유클리드 디스턴스 입장에서 봤을때 기울어진것 자체가 축 을 기준으로 길쭉하게 분포가 되어야함 사선으로 기울어진 축에서는 작동하지 않는다. 요런 형태는 케어할수있는 방법이 없는가? bfr 은 없다. 뒤에 맨마지막에 queue 알고리즘이 소개된다.

bfr 알고리즘은 한번씩 굉장히 큰 용량을 기준으로 하다보니까 기본적으로 메모리에 로드에 한번에 할 수 있는 양만큼 잘름 데이터 청크 . 메모리에 올려서 처리하고 그런방식으로 가게됨
한번 올릴때마다 스텝정보를 유지를함 (스텝정보는 말해줬고 다음 슬라이드에서 나온다, 스텝정보가 뭐지???)
제일 먼저 한번 첫번째 청크를 메모리에 로드함 로드를 하고 나서 걔로부터 랜덤으로 몇개의 포인터가 k개 포인터가 잡아냄 k개의 포인트 k개를 어떻게 잡아내는지에 대해서 k-means의 발전된 버전임

k-means 방법을 따르고 발전된 형태임
그래서 k개를 정하는 방법은 랜덤 할 수도있고 어느 한놈을 가져다 잡고나서 이놈과 제일 먼놈 을 잡고 얘랑 새로운 잡을때 이 두놈이랑 제일 먼놈잡고 이런식으로 k개를 잡을 수 있음
k개를 잡아서 initial clustering 을 하는데 얘네 같은경우 bfr 알고리즘 경우 클러스터당 서머라이즈 (서머링) 라고 하는데 서머리 자체가 클러스터당 유지하게 되는 메타데이터 정보다 라고 생각하면된다. state 정보를 유지함.(스텟 정보..?)
스텟 정보를 유지를 하는데 (스텟 정보가 머지???)
스텟 정보를 유지하기 위해서 어떤 클러스터당 어떤 클러스터 유지하게 되냐면 이 세가지다.
각각 청크를 읽어서 분류를 해야 하는데 분류를 하게 되는 3가지 기준 자체가 
1. discard set
그냥 떙큐한것이다. 실제로 기본적으로 이니셜 단계에서 k개로 가져다 클러스터 했을때 이 클러스터에 굉장히 잘맞는 제일 가까워서 잘맞는 이런 포인트를 가져다 discard set이라고함
2. compressed set
이 클러스터에 직접 가깝지 않지만, 뒀더니 지들끼리 맞아서 지들끼리 클러스터 형성되는 미니클러스터 의미
discard set이나 compressed set의 경우는 우리가 다음 슬라이드에 나올 그런 ???? 와 서머리를 가져다 그 스텟 인포메이션을 유지를 하고 나서 얘네들 데이터는 다 버려버린다.
클러스터링이 되는것들이기때문에 일단은 걔네의 정보를 유지하고 업데이트로 버려버린다.
별개로 이도 아니고 저도 아니고 지혼자 따로 노는 outier가 있음
어디에 집어넣냐면
3. retained set
여기다 집어넣는다.
클러스터에 속하지 않기떄문에 기존 클러스터의 정보를 에다가 스텟 인포메이션을 업데이트해서 얘네들을 집어넣을 수없음 
그래서 좋든 실든 메모리에 keep을 해야함
그래서 얘네들을 가져다 retained set이라고 말함

센트로이드가 있을때 그 클러스터에 제일 가까운 스케쥴 놈들을 가져다 ds라 하고
지들끼리 조그맣게 미니 클러스터 유지하는것을 여기에 속하지 않지만 가까이있지 않지만 지들끼리 클러스터를 유지를 하는 cs 라고 함
열심히 지혼자 따로 노는 rs라고 함

그리고 이제 어떤 정보를 유지하는지 써머리를 하고 클러스터당 그런 써머리 인포메이션을 얘들이 keep을 함 그 인포메이션이 3가지
keep을 해야 하는 정보가 3가지임 
ds나 cs는 클러스터가 형성 되기때문에 클러스터당 유지를 해야하는데 이런 정보를 가져다 각각 클러스터당 유지를 해야함
고 유지해야하는 써머리 정보가 뭐냐면 그 클러스터에 속하는 토탈 그 포인트 숫자 개수(n), sumvector(dimesion 이 있을때 기본적으로 유클리드 스페이스를 가정하기 떄문에 어떤 b라는 디메젼이있는 어떤 벡터를 가졍했을때 각각 자기 디멘젼당 각각 다 더한 포인트들을 다 더한 값 이렇게 세로로 각각 디멘전 끼리 더해서 다 써메이션 해놓은 그런 하나의 벡터를 가져다 sumvectort라고함 )length=d 임 
비슷하게 sum sqare vector 이 있음 기존에 섬벡터의 경우는 각각 자기 포지션에 자기 디멘전에 해당하는 데이터를 가져다 다 단순하게 더한것이고
sum sqare vector는 지관적으로 그냥 받은게 아니라 각각 루트해서 다 더한다.
다 더해놓은 d 디메젼의 벡터를 가져다 썸 스퀘어 벡터라고 한다.
요3가지 인포메이션은 각각 클러스터당 유지를 함
왜? 왜냐면 우리가 원래 필요로 하는 정보는 그게 아니지만 이런 식으로 정보를 유지하게 되면 이피션트 하다. 그래서 얘네들이 요런식으로 써머리를 유지한다.

실제 클러스터당 유지해야 하는 ????
카운트 value 임 클러스터당 포인트가 몇개있느냐?
n을 가져가 그대로 쓴다. 
두번쨰 필요한것이 뭐냐면 이게 유클리드 스페이스임 유클리드 스페이스 가정을 하고 그래서 센트로이드 개념을 쓰게 되는데 실질적으로 디스턴스 자체는 센트로이드 에서 그 포인터 그 포인터 센드로이드랑 거리가 얼마만큼 되느냐 로 일을 하게 되는데
실질적으로 유지해야하는 정보는 센트로이드 값임 원래 유지해야 하는건 센트로이드 개념임
그래서 우리가 센트로이드 정보를 가져다 썸벡터가 있으면 센트로이드 정보를 우리가 금방 유측 할 수 있음 각각 썸벡터를 n으로 나눠버리면 average가 되버림

그런식으로 센트로이드를 킾하고 
그리고 그리고 실질적으로 스탠달드 디베이션 정보를 가져다 왜 유지를 해야하는지?
사실은 감이 안옴
유지해야 하는 이유는 뒷부분에 
말러노 디스턴스를 구해야하는데 그 디스턴스를 구하기 위해서 이 정보가 필요함
스탠달드 디베이션을 유지해야하는데 어떻게 유지할 수 있냐면
섬벡터 스퀘어 벡터로부터 유추를 할 수있다고 설명했다 왜그랬는지 설명했다
실질적으로 이것을 통해서 얻어질 수 있는것은 분산값이지만 
분산값 ??? 스퀘를 씌우는게 표준편차잔아(이건 ppt 내용을 참고하고) 
표준 편차 값도 두개의 정보를 유지하고 3개의 정보르 유지하게 되면 
굉장히 쉽게 유추를 할 수 있다.
ㅇ;런식으로

왜? 이딴식으로하니??
이렇게 하면 훨씬더 계산량이 많아지기 떄문에 복잡해짐 이런식으로 하는것이다.
여기까지 지난시간에 우리가 배운것이다.
이제부터는 조금더 자세하게 

## BFR Algorithm
이제는 우리가 bfr 알고리즘을 배울 준비가 된것이다 각각 킾해야할 정보가 무엇인지
그리고 어떻게 그값을 찾아내는지 배웠다.
실제 우리가 bfr 알고리즘을 들어갈텐데 바라보면 기본적으로 말씀드렸다싶이 굉장히 큰 데이터를 가정하기 떄문에 같은 사이즈로 메모리 로더 가 사이즈를 청크를 한다고 했다.
데이터를 가져다

통상적으로 os가 그렇게 돌아간다.
그래서 데이터를 청크를 하여 메모리를 로딩을 한다.
각각 메모리에 로딩을 하면서 작업을 하게 되는데

각각 메모리 로드당 이짓을 한다. 한번 올라서 그작업을 이 알고리즘을 돌리고 한번 올리고 작업하고 올려서 작업하고 나서 discard set이나 compressed set은 그냥 버립니다.
그렇기 떄문에 메모리가 크게 부족하지 않다.
실제 keep해야 하는 정보는 retain set 밖에 없다.
그래서 한번 그렇게 메모리에 청크를 해서 한번 메모리에 로드를 하게 되면 어떤 포인트를 찾게 되는데 어떤 포인트냐면 각각 처음에 우리가 기본적으로 클러스터를 만들어놨음 
기본적으로 클러스터를 만들어놨다. 정확한 클러스터는 아님
k개를 포인트를 가져다 k-means 처럼 k개의 포인트를 가져다 우리가 어떤 방식에서든지 k개의 클러스터를 만들어놓음 
그리고 걔네들이 센트로이드가 됨
처음에 데이터를 끌여다 올려다가지고 각각 포인트당 계산 하게 되는데
각각 포인트를 읽어서 센트로이드당 거리계산을 하게됨
거리 계산을 해서 제일 가까운 놈(sufficiently close)라고 하는 그 클러스터라고 하는데
이거 자체가 굉장히 엔지니어 답지 않음
충분히 가깝다 기준이 불명확함
이런식으로 얘기를 하면 안됨
엔지니어에서는 

엔지니어는 숫자로 말한다.
나중에 대학원을 가든 연구를 하든 직장을 가든 이 도메인에서 있는 순간 
성능을 숫자로 말한다.

그런식으로 말하는게 아니라
산호세에 보고를 하든 페이퍼를 쓰든 숫자로 얘기해야 한다.
자 그런데 이런식으로 실컷말해서 이렇게 써놓으면 그래서 빨간색으로 해놓음
복잡해서 이렇게 해둠
가깝다 기준은 다시 말해준다.
이때 말라노 디스턴스를 쓰게 된다.
그 디스턴스를 썻을때 어느정도 쓰레시 홀 보다 가까우면은 여기서 얘기하는 충분히 가깝다 기준을 두게 된다.
그게 그 디스턴스를 구하는지는 뒷페이지 에 있음

우리가 각각 포인트당 걔네들 클러스터에서 디프런트를 ??? 를 각각 디스턴스를 가져다(유클리드 디스턴스임) 말라노 디스턴스를 계산을 해서 
그 디스턴스를 계산을 해서 제일 가까운 놈
어사인을 함
그 포인트들을 찾는다. 충분히 가깝다 에 쓰레시 홀에 들어가는 (이내에) 그런 포인터들을 찾아서 그것을 그 클러스터에 어사인함
그 클러스터가 ds, discard set임
그 말씀드렸던 클러스터에 충분히 가깝기 때문에 그 클러스터에 들어가야 되는 놈들
그런 놈들 부터 찾는다.
찾아서 그리고 클러스터에 집어 넣는다.
클러스터에 집어 넣어서 n값을 sum값 sum-sq vector 각각 정보를 업데이트해야함
새로운 포인터들어가면 그냥 sum 더해주면 그만이고 sum-sq 스퀘어 쓰고 더해주면 그만
이런식으로 기존에 우리가 만들어놨던 그런 클러스터에 충분히 가까운 놈들은 그런식으로 
일단은 버려버린다.
(왜버림???)

그다음에는 충분히 가깝지 않아. 충분히 이 클러스터에 가깝지 않은데 지네들끼리 충분히 가까운놈들이 있다. 얘네들 얘네들 같은 경우는 
센트로이드에 충분히 가깝지 않는데 얘네들 같은 경우는 남아있는 포인터들
이거보면 우리가 처음에 제일 가까운 놈들을 가져다 먼저 어사인 해버리고 난 다음에
떨거지들을 가지고서 지네들끼리 클러스터가 되는지 안되는지 찾는것이다.
그리고 그걸로 끝나는게 아니라 사실은 이 얘네들 데이터가 얘네들 끼리 
실제 클러스터가 되는지 찾는게 아니라 이게 이전에 retained set이 있다고 가정하면
retained set은 항상 존재하는데 그런 outlier들 기존에 있던 outlier 들이랑 그리고 처음에 이제 충분히 가깝지 않은 클러스터에 속하지 않은 그런 놈들
걔네들이랑 retained set에 있는 걔네들이랑 같이 묶어서 다시 가야함
직관적임
그런 놈들이랑 다시 묶어서 바라봐야함 얘네들끼리 클러스터 가능한가 안한가 
그래서 걔네들끼리 클러스터가 충분히 된다. 그러면 
걔네들끼리 묶어서 compressed set에다 집어넣고 3가지 정보를 각각 클러스터당 업데이트 하고 (n값을 sum값 sum-sq vector) 버려버린다.

그리고 나서도 남는다. 걔네들은 outlier들임 꼭
걔네들은 좋든 싫든 retained set에 집어넣는다. 써머링 하지 않음
이게 두번째 단계임

그런데 두번쨰 단계에서 우리가 이제 미니 클러스터가 만들어짐
첫번째 단계에서 실제 클러스터에 들어간 놈들을 다 골라냈고
두번쨰 단계에서 미니클러스터를 만들어지는 놈들이 우리가 만들어졌는데

이 미니클러스터가 지금만 ??? 
이게 각 라운드마다 돈다고 헀음 
그러니까 미니클러스터가 이 전 청크에서도 만들어졌을꺼임
그렇다. 왜냐하면 청크당 이짓을 하는거임
그러면 생각해보면 지금 청크에서 우리가 미니클러스터 몇개를 찾아냈어
그러면 그 이전에 우리가 청크들을 통해서 만들어진 미니클러스터 그런놈들도 있을것임
걔네들이랑 같이 같이보는것임

이 지금 현재의 미니클러스터랑 그 이전에 우리가 찾아놨던 청크들에 찾아놨던 미니 클러스터들이랑 같이봄 얘네들끼리 센트로이드 들끼리 더해저서 디스턴스 계산할 수 있겠다.

그래서 계산을 해서 걔네들끼리 충분히 가깝냐 아니면 지네들끼리 다시또묶는다.그러면
새로운 cs set이 다시 만들어짐
그럼 미니클러스터 다시 만들어짐
그게 이제 3번째 단계임

4번째는 
클러스터에 할당이 됬던지 아니면 미니 클러스터에 할당이 됬던지 이렇게 클러스터 에 할당되었던 포인터들 얘네들을 더이상 필요가없으 메모리에서 작업을 하고 있었을 꺼임
애들은 그냥 플러시 아웃 다시 해버림 메모리에서 빼머린다는 소리임
왜냐면 다시 필요없음
그러고 나서 이게 이제 요단계까지 계속 돈다.
각 청크마다 계속 이렇게 돌고 이제 만약에 다 끝났어 그리고 이제 마지막 청크야
마지막 청크가 왔을때는 최종 교통정리만 해주면됨
그 마지막 데까지 오면서 우리가 이제 클러스터는 계속 기존 클러스터 ds set에 들어간 클러스터 셋이 이미 다 만들어졌을껏이고 그러고 미니 클러스터도 지들끼리 계속해서 묶이고 묶이고 해가지고 미니 클러스터 지네들도 만들어졌을꺼임 

그리고 이제 retained set에 들어가는 그런 outlier도 모여있을것임
클러스터에 들어가있는 놈들을 일단은 제쳐두면됨 클러스터에 들어가는 놈들은 더이상 볼 필요가 없음
나머지 이제 미니클러스터에 남아있는 놈들 
그리고 retained set에 들어있는 그런 outlier 얘네들을 가져다 우리가 어떻게 처리를 해줘야 하는지임
1,2,3 같은 경우를 요걸 요렇게 다 해야 된다가 아니라 그놈들을 우리가 그럼 어떻게 처리할까에 대한 옵션임

첫번쨰를 보면 그냥 남은 놈들을 다 아이고 너네 다 필요없어 니들 다 그냥 outlier야 없어져 라고 얘기하고 retained set으로 해서 그냥 무시해버리는 일이 있음

두번째는 ratained set에 넣어놓은 놈을 가져다 좋든 싫든 이놈들을 그래도 제일 가까운 놈에 대해 할당해주마 
이렇게 해서 retained set에 있는 놈들을 가져다 억지로 라도 제일 가까이 있는 놈한테 이렇게 그냥 클러스터에 넣어주는 방식이 있음 그러나 애플리케이션마다 다름

세번째는 미니클러스터가 나옴 미니클러스터 역시도 이제 그냥 이제 좋으나 싫으나 제일 가까이있는 그런 놈들한테 그냥 억지로 떼 붙임 어사인 해버림 이런 방식이 있음

뭘 어떻게 택하고는 이렇게 해라가 아님 어쨋든 마지막 청크까지 1,2,3,4 까지 계속 돔 
계속 돌고 나서 이제 클러스터가 충분히 다 만들어지고 다 만들어지고 나서 남은 그런 애들에 대해서 어떤 일을 가져다 마지막 청크 알고리즘에서 한번 처리릃 해주면 bfr 알고리즘은 이런식으로 끝이남 

그런데 충분히 가깝다 뭐가 가깝니 ? 가깝다 라고 했는데
가깝다 라고 정의를 알려주지 않았음 말라노 디스턴스를 말하지 않았음
첫번째 질문이 그것임

## A Few Details
어떤 포인트가 왔을때 센트로이드를 가깝다 라고 얘기했는데 뭐가 가까운데 
두번째는 컴프레드 셋이 있는데 맨마지막 알고리즘 보면 컴프레스 셋끼리 지들끼리 묶는다. 여기도 보면 3번을 보면 컴프레드 셋, 지네들끼리 묶음 
묶어가지고 새로운 미니클러스터를 키워나감
비록 기존에 클러스터에 들어가지 않았다 치더라도 그럼 얘네들끼리 묶을때 무슨 기준으로 묶느냐?
그것에 대해서 아직 얘기를 하지 않았음
그냥 한다라고 말만 
말만 했음
거기에 대해서 알아보도록 하기로함
미리 말하면 두번째는 굉장히 심플함

## Q1. How Close is Close Enough?
어떤 포인트가 있을때 bfr 알고리즘에서 그 클러스터 그 클러스터랑 충분히 가깝다. 
라고 얘기를 했고 충분히 그렇게 가깝다 라고 정의가 됬을때 그것을 클러스터에 집어넣게되는데
그 정의를 보도록 함
여기 보면 이 실제 얘네 알고리즘에서는 두가지를 제안을 하는데
첫번째 같은 경우는 보면 	
High likelihood of the point belonging to currently nearest centroid
이게 사실은 별 처음에 우리가 이제 센트로이드 가져다 만들었고 클러스터가 만들어짐에 따라 센트로이드가 물론 바뀌긴 할 지라도 그 클러스터가 있고 걔네들의 센트로이드가 있는데 
이 첫번쨰 얘기는 뭐냐면 요 거 같은 경우는 사실 실질적으로 요 방법은 많이 쓰지 않음
요게 뭔 말이냐면 어떤 포인트가 있을때 (확률적인 말을함) 이 포인트가 거리를 따질때 무슨 distance 를 썻던간에 얘가 이 클러스터에 제일 가깝다 라고 얘기를 할 수 있게 하는 여러분들의 판단 하고 있는 그 순간에 그 순간에 이 포인트가 이 클러스터에 제일 가깝다 라고 주장을 할 수 있느냐? 실제로는 그렇지 않음 k-means에서
k-menas에서 우리들이 포인트가 계쏙 해서 어사인되면 클러스터가 바뀜 
클러스터가 바뀌면 센트로이드가 바뀜 
센트로이드가 바뀐다는 말은 여러분들이 어느 한순간 그 시점에서 이 포인트를 가지고 어떤 디스턴스를 구하는 그 순간은 내가 제일 가까울 지 모르겠지만, 따른 것들이 쭉 들어와버리는 순간에 얘는 걸과적으로 여기는 얘가 속하는 클러스터가 아닐 수도 있음
근데 이게 혼란 스럽지만, 이방법이 첫번째 방법은 확률 을 가지고 서 하는건데 이게 왜 현실적으로 맞지 않냐면 내가 지금 현재 이 포인트가 여기 제일 가깝다 라고 주장을 했을때는 어떤것을 가정하게 되냐면 내가 그 이후에 다 오게되는 데이터 포인트 들을 다 알 고 있다는 가정하에 있는것임
왜냐하면 그렇지 않고서는 가정이 없이는 지금 현재 내가 어사인한 이게 맞다고 주장을 할 수 없음
이것 역시도 그렇기 떄문에 확률이 기대값 같은 
확률이란 기대값 같은 그런 수학적인 표현을 써서 우리가 미리 끝까지 다 알고있고 우리가 미리 끝까지 알고있고 그 가정하에 얘네들의 확률과 그런 기대값 따져봐서 
내가 지금 이 포인터를 지금 여기다 넣는게 그렇게 틀린것이 아님 라는 수학적인 모델을 따름
통상적으로 이런 방법을 쓰지 않음

첫번쨰 얘기는 그얘기고 두번째는 말라노 디스턴스 얘기임

## Mahalanobis distance
클러스터링 에서 나오는 마지막 디스턴스 개념임
말라노 디스턴스임
상식적으로 
여러 가지 클러스터링은 디스턴스 개념을 쓸수밖에 없음
어떤 디스턴스를 쓰느냐는 그때그때 마다 다름
요 bfr 알고리즘에서는 그 디스턴스 개념을 자 요 새로나온 용어의 말라노 디스턴스 개념을 씀
이 개념을 써서 이 디스턴스가 어떤 ????? (쓰레시 레지스턴스 홀드 값이) 값이 있어요 무조건 가깝다 가 아니라 어떤 쓰레스 홀드 값을 둬가지고 그 값보다 적으면 거기다 넣음
그렇게 복잡하지 않음

말라노 디스턴스의 정의임
말라노 디스턴스는 결과적으로 보면 유클리드 디스턴스임
k-means의 확장 버전을 하고 있기때문에 결과적으로 유클리드 디스턴스를 쓰지 않을 수 없음
유클리드 디스턴스인데 조금은 변형된 형태의 유클리드의 디스턴스가 됨 

그래서 보면 normalized 유클리드 디스턴스라고 적혀있음
어떤 포인트가 있을때 그 포인터와 그리고 우리가 만들어 놓은 그런 각 클러스터에 센트로이드 가 있음 포인트와 센트로이드 상에 그 거리를 가지고 이제 계산을 하는데 이 계산이 k-menas에서는 단순히 유클리드 디스턴스였으면 여기서는 유클리드 디스턴스인데 이것을 가져다 노멀라이징 시킨 유클리드 디스턴스를 쓴다.

그렇게 노말레이징 시켜놓은 유클리드 디스턴스를 가져다 말라노 디스턴스라고 함
조금더 살펴보면 노멀라이징된 유클리드 디스턴스가 뭐냐? 디스턴스인데 어떤 포인터랑 센트로이드 상에 거리임
그것을 가져다 노멀라이징 한다. 노멀라이징을 뭐로 노멀라이즈하냐? 그때 뭘로 노멀라이즈 하냐면 스탠달드 디베이션으로 노멀라이즈시킴

각각 디멘젼당 각 디멘젼당 스탠달드 디베이션 값으로 노멀라이즈 시킴
이제 왜 우리가 스탠달드 디베이션을 keep을 해야하는지 이유를 이해했을것이다.
++우리가 클러스터당 뭐를 유지한다고 했냐면 3가지를 유지한다고 했는데 n값, sum vector, sum-sq vecotr 유지함 얘네들 sum-sq sum vecotr을 미분해서 스탠달드 디베이션을 가져다 계산을 할것임 스탠달드 디베이션 을 구해야 하는 이유가 말라노 디스턴스를 계산을 하기 위해서임++
그래서 실제 로 보면 각 포인트가 없음 어떤 포인트 x1, d 디멘젼이라고 가정을 함 
그 벡터를 가정을 하자 유클리드 디스턴스에서 어떤 점에서 센트로이드 까지 거리를 구하는데 그 각각에 대해서 보면 각각 디메젼 은 어떻게 되냐면 
유클리드 디스턴스를 구하면됨 일단은 디스턴스 니까 자기 데민젼 값을 뺀다 
그것을 가져다 스탠달드 디베이션 값 그 각각 자기 디멘젼에 해당되는 스탠달드 디베이션 값으로 나눕니다. 이 값이 yi라고 가정을 해보면 이렇게 가정을 하고 나서 그 값에 스퀘어 값들을 가져다 
스퀘로 해서 다 더하는것이다. 다 더함 이렇게 되면 사실은 유클리드 디스턴스와 별반 달라보이지 않음 유클리드 디스턴스는 제가 값을 빼가지고 스퀘어 해서 다 더해가지고 스퀘어 루트취하는것이 유클리드 디스턴스인데 
값을 빼서 노멀라이징 시켜서 그리고 제곱해서 다 더해 루트를 씌어줌
그게 각각 디멘젼당 
i가 1에서 d 까지 임 그래서 대입이 되서 각각 디멘젼에서 그짓을 쭉쭉함
그렇게 해서 스퀘어 벡터를 취해주는게 말라노 디스턴스가 되는것이다.

얘네들 갖다가 클러스터에 어사인을 해야함
포인트 p가 있을때 그러면 클러스터에다 어사인하는데 어떤식으로 어사인 하냐면 그 일단은 그 포인트 가 그 클러스터에 있는 센트로이드당 일일히 말라노 디스턴스를 다 계산을 함 
우리가 처음에 k개의 클러스터를 만들었기 때문에 당연히 k번째까지 할것임
k개의 디스턴스가 나오게 될텐데 
그중에서 이제 일단은 제일 당연히 제일 가까운 한놈을 찾고 두번쨰 보면 말라노 디스턴스 계산하고 그리고 그중에서 제일 작은 놈, 제일 가까운 놈을 가져다 
그렇다고 해서 얘를 무조건 어사인 하는게 아니라 말씀드렸다.
세번쨰를 보면 어떨때? 이 디스턴스가 어떤 트레시 홀드를 주게됨 그런 트레시 홀드를 주고 그 트레시 홀드에 들어갈때 만 어사인을 한다.
제일 가깝다고 무조건 어사인하는게 아님
그 렇기 떄문에 이게 보면 어떤 포인터들은 클러스터에 할당이 되고 어떤 포인터들은 아웃라이어 저 위를 주는 그륩이 되는 이유가 이래서 그럼
기존에 우리가 k-menas의 경우는 그런 아웃라인을 어사인을 하는데 걔네들 때문에 영향을 많이 받게 되는데 어쩃든 얘네들 역시도 물론 영향을 안받는건 아니지만 
맨 마지막에 나온 그런 retained set을 어떻게 어사인 하느냐에 따라서 사실 에러율이 달라지기는 하지만 어쨋든 기본적으로 걔네들이 말라노-디스턴스를 계산하고 제일 가까운 애를 택하고 그리고 이 놈노 그냥 어사인 하는게 아니라 어떤 트레시 홀드를 줘서 그 트레시 홀드에 들어갈때 만 그제서야 어사인을 하게 됨
통상적으로 보면 스탠다드 디베이션 값을 줘가지고 그 스탠다드 디베이션에 값 인데에 디스턴스가 들어올떄 그제서야 어사인을 하게됨 
통상적으로 보면 스탠다드 디베이션에 두배값이다. 그러면 
어떤 자 디비?? 값이 있다고 가정했을때(표를 보면댐) 거기서 스탠다드 디베이션 은 
한배했고 두배했고 세배했고 이런식으로 갈것임
노멀 디스트립션, 가우시안 디스트립션을 가져다 가정하게 되는 이유는 그 이유임
그래서 이게 쓰레시 홀드 벨리유 값을 몇 배에 쓰레드 홀드 값을 이런식으로 주는 이유가 
이게 그 가우시안 분포를 가정하기 때문임
가우시안 분포를 가정하기 때문에 이 어느정도 스탠달드 디베이션에서 어느정도 거리에 들어온다 싶으면 실제 거기에 속할 확률이 굉장히 높음
그래서 얘네들이 실질적으로 쓰는 어 쓰레시 홀드 개념을 가져다 스탠달드 디베이션에 몇배 두배 네배 이런식으로 주게됨
물론 이것자체가 스탠달드 디베이션 몇배 몇배 몇배 자체가 사실은 퍼센트나 ???가 나오게 되겠다. 그것을 여러분들 클러스터링 할때 애플리케이션마다 다름
그것은 정하기 나름이고 그런 쓰레시 홀드를 줘서 거기 내에 들어가면 그냥 어사인한다. 고 생각을 하면됨
간단함

두번째가 
## Should two CS clusters be combined?
미니클러스터, 얘네들끼리 두개, 다시 매 라운드 돌면서 지네들끼리 묶는다 그랬음
얘네들 가져다 묶을때 기준은 무엇이냐?
얘네들 끼리 묶을때는 만약에 두개가 있다고 가정하면 두개의 미니클러스터가 있다고 가정하고 애네들 combined 했다고 가정했을때 즉 2개의 sub 서브 트랜스.. ?? 을 가져다 두개를 컴바인한 걔네들의 분산값을 정함
쉽게 구할 수 있음
얘네들 각각도 왜냐하면 각각도 클러스터이기 떄문에 n값, sum, sum-sq 유지 하기 때문에 그 베리언스(분산값을) 쉽게 구할 수 있음
이 컴바인된 서브 클러스들의 분산값을 구하고 나서 그리고 뒤에 어느정도 쓰레시 홀드 벨리유 걔네역시도 정해서 쓰레시 홀드 벨리유 이내에 들어오면 걔네들 끼리 합하는것임
이것역시도 스탠달드 디베이션 몇번이고..? 분산 이었음
그런 ..???? 줘서 그런 쓰레시 홀드 값이 들어올때 그 두개들 혹은 걔네들의 미니클러스들을 합쳐서 다시 새로운 미니클러스를 만듬
그리고 보면 

Many alternatives: 이것을 가져다 디멘젼을 다르게 취할 수도있고 당연히 덴서티 같은경우도 고려해서 계산을 하고 그렇게 할 수도 있음 약간은 extra임 
이렇게 하게 되면 bfr 알고리즘을 배운것임
k-mneas알고리즘을 어드밴스 시켜서 실제 빅데이터에 쓸수있는 클러스터링에 쓸 수있는 알고리즘이 되는데 완벽한건 아니다.
얘네들 역시도 구멍이 있음 문제가 있음 그래서 나온게 클러스터링에서 마지막에서 다루게 될 큐알고리즘임
bfr 알고리즘을 할때 가정이 뭐냐면 그 shape이 원이나 타원형이나 그런식으로 클러스터를 가정을 함 이게 틀렸다 라기 보단 bfr 알고리즘에서 당연함 k-means 어드밴스 버전이고 k-means도 유클리드 디스턴스를 가져다 기본적으로 가정하기 때문에 센트로이드라는 개념이 존재하고 센트로이드라는 한점이 존재하기 떄문에 그점에서 얼마만큼 가깝냐 이기 때문에 굉장히 당연하게 shape 클러스터링의 shape이 원형이 나올수밖에 없음 당연한 얘기
클러스터링을 하는데 세상에 원만 있는것은 아님
그래서 그거에 remitaion을 넘어서기 위해서 그걸 가지고 해결하기 위해서 나온 알고리즘이 큐 알고리즘임
기존에 bfr, k-means 알고리즘을 보면 어떤 문제가 있냐면
노말 디스트립션을 가정한다고 했음 통상적으로 많이들 맞지만 세상에 100이어딧음 
노말 디스트립션을 , 가우시안 분포를 안따를수있음
그런걸 안따르는것 같은 경우는 얘네들 문제가 생김 스레시홀드 자체가 그 가우시안 분포를 가정을 하고 거기서 어떤 확률을 가지고 그만큼 잘라내는건데 

이게 만약에 분포가 가우시안 분포가 아니면 사실은 그 자체가 성립하지 않음
그래서 보면 노말 디스트리비우션을 따지기 때문에 이제 그런 가정이 문제가 될 수 가 있음
얘네들 같은 경우는 이게 구 형태가 아니면 구가 됬든 뭐가 됬든 원의 형태가 아니면 작동을 잘 안함
shape이 지멋대로 마구 마구 면 답하지 않음
그리고 outlier에 대해서 굉장히 민감함 k-means에서도 outlier에민감함 마찬가지로 
걔네들 outlier하나가 쑥 들어오면 centroid 값이 확변함
그 센트로이드 개념을 bfr 알고리즘에서도 씀
걔네들이 갖고 있는 리미테이션을 bfr 한들 그 리미테이션을 벗어 날 수 없음
이런 문제점이 있음
그래서 나온게 큐알고리즘인데

## The CURE Algorith
Clustering Using REpresentatives
알고리즘 인데 클러스터링을 함
클러스터링을 하는데 뭘 가지고 하냐면
지금까지는 그 대표값되는 센트로이드를 가지고 그 한놈을 가지고 클러스터링을 했는데 이제는
Clustering Using REpresentatives
이 얘기는 한점이 아니다. 
대표점들 
어떤 클러스터링을 표현을 할때 한 노드에 한 점이 중요한게 아니라 대표값이 여러개의 대표값을 가지고서 그 대표값들이 그 클러스터링을 표현을 함 그렇게 함으로 인해서 
우리가 기존에 가지고 있는 k-means나 그런 문제점을 극복가능
k-menas나 걔네들이 기본적으로 가지고 있는 shape 의 형태에 대해서 리미테이션 이 있을 수 밖에 없던 이유가 그 대표값이 센트로이드라는 한놈을 가지고서 열라게 주고 팬다??
그렇다 그래서 생기는 문제이기 떄문에 
얘네들은 그것을 해결하기 위해서 여러개의 대표값을 둬가지고 얘네들이 우리의 클러스터를 대표한다 라고 
그런 방식을 가지고서 접근을 함 
유클리드 디스턴스를 가정하고
shape은 상관없음
대표값을 여러개의 대표값을 쓰기 떄문에
어떤 shape이든지 문제없음
어떤 대표값 포인터들 여러개 를 가지고서 클러스터 표현하고 센트로이드 라는 한점을 가지고 표현하지는 않음
실질적으로 얘네들은 hybrid approach임 
센트로이드 방식 한점을 가지고 하는 그런 방식이 갖고있는 장점 단점 이 있을텐데 그 방식과 
어떤 클러스터 표현할때 모든 점 자체를 가지고 클러스터 표현할 수 도있음 
사실은 정확하기는 이게 정확함
점이 너무 많아 지면 이제 ..? 
실질적으로 센트로이드 개념 자체가 유클리드 개념을 가정을 하고 있는데 유클리드 아닌건 클러스터 로이드 개념도 있지만 통상적으로 가장 정확하게 표현할 수있는것은 모든점들을 가지고 표현햇을때 클러스터를 제일 정확하게 표현할 수있음
그런식으로 올 포인트 어프로치? 할떄 그런 어프로치와 그리고 지금까지 배웠던 센트로이드 방식의 그런 어프로치들 각각에 장단점이 있을때 그런 장단점을 뽑아서 hybrid 방식으로 만들어놓은게 큐 알고리즘임


