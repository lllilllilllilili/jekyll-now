---
post : layout
title : 빅데이터(기)마지막 	
---
## 마지막 빅데이터 수업

## Spark architecture anatomy
지난 시간에 요기까지 했다. 스파크 남은거는 요기까지 합니다.
장수는 조금 되 버려도 
내용자체는 많치 않다.
스파크 아키텍쳐 이거는 좀더 하드웨어 적인 의미에서 아키텍쳐 입니다.
코딩적인 측면에서 아키텍쳐 바라보면 이렇게 생겼다.
소프트 웨어입장에서 

## Spark components
스파크 컨텍스트 - 드라이버 프로그램 이 그 스파크 컨텍스트 포함하고있음 지금 이거 뭐 이페이지 안된다고 걱정할필요없다. 다름 팔로잉 설명 오버럴 한 아키텍쳐한

클러스터 매니저가 그사이에 있고 각각 노드 1,2,3 가 있어서 워커 노드가 있다 물론 얘네들은 워커 노드들을 그 얘네들도 워커노드라고 하긴하는데 그속에서 돌아가는 실질적으로 예전에 우리가 그 하둡 할때 실제 맵 태스크 있죠 아니면 맵퍼라든지 리듀스 라던지 각각 돌아가는 그런 태스크 실행하던 그 프로그램 자체를 얘네들은 엑스큐터라고 합니다. 엑스큐터가 각각의 태스크를 가지고서 그 프로그램을 실행해요 그래서 실제 예전에 그 하둡 맵 리듀스 같은경우는 맵 태스크가 있고 그리고 걔네들이 데이터 노드에서 어 그 데이터 노드 걔네들이 각각 그 태스크를 가지고서 맵퍼와 리듀서를 실행했잔아요 똑같은 이치다. 대신 얘네들은 이름을 엑스 큐터라고 바꿨을 뿐이다. 그리고 그 캐시 걔네들이랑 다르게 캐시라는 
강조 해서 나왔는데 얘네들이 그 중간까지 그런 데이터를 가져다 어 캐시를 해가지고 인메모리 프로세싱을 하기떄문에 고부분 강조하기 위해서 색깔을 바꿔놓은것 같다. 

각각의 컴포넌트들이 소프트웨어 컴포넌트들이 있는데 요거에 대해서 조금씩 얘끼해본다
자이제 스파크 컨텍스트라고 있었다.
이거는 여러분들이 하둡에서 나오든 그 하둡 컨텍스트 맵 리듀스 컨텍스트랑 전혀 다르잔아요 이게 여러분들 코딩 좀 많이 해보셨던 분 아실텐데 말그대로 컨텍스트이다.
이게 뭐냐면 이 스파크라는게 클라스터에 돌아가잔아요 그쵸 
클러스터에 돌아가다보면 실제 드라이버 프로그램 이 딱 실행시켰을떄 얘가 그러면은 아까 그 리소스매니저라든지 각각의 노드가 어디에 있고 그런것을 얘네들 전혀모른다 
그런 일련의 정보를 가져다 컨텍스트 라고합니다 그리고 예를들어서 지금 여러분들이 잡을 실행읋했다. 그러면 잡을 실행했을떄 잡에 이거 잡에 이름이 뭔지에서부터 시작해가지고 각각 그런 정보들을 가지고 컨텍스트라고 해요 

실질적으로 여러분들이 드라이버 프로그램을 짤때 그런정보를 가져다 넣어줘야 되거든요 예를들어서 hdfs 에서 쓴다라던지 파일에 어디에 있는지 아니면 리소스 매니저 가 어디에 있는지 아이피 주소 알려준다라던지 그런 정보를 이 스파크 컨텍스트에다가 그 파라미터를 넣어줍니다 실제 코드를 보면 그렇게 되어있다. 그래서 실질적으로 스파크가 시작하면서 메인 엔드리 포인트 역할을 합니다 포인터 역할을하고 
사실은 여러분들이 숙제를 하셨으면 경험을 하셨을거에요 
거기보시면은 sc. 어쩌구 저쩌구 이렇게 나오는데 그떄 sc라는게 사실은 스파크컨텍스트에 약자다 자 스파크 컨텍스트를 갖다가 우리가 스페스 파이 해줘야 하는데 걔네들이 그런 컨텍스트 정보 자체를 가져다 파라미터로 넘겨준다 
그리고 이 스파크 컨텍스트 라는건 이 드라이버 프로그램에 한 부분이다. 그 드라이버 프로그램을 짜시면 그 속에 여러분들 스파크 컨텍스트를 갖다가 스페스 파이 해줘야 한다.

그리고 사실은 이게 스파크 컨텍스트가 더많이 쓰이고 더 중요한 이유는 이 rdb라고 나오는데 지금 여러분들이 뭐 이해를 하실필요가 없다. rdb는 굉장히 중요한 부분이다. 

뒷부분에 나온다 어쩃든 rdd 라는건 말그대로 끝에 d는요 데이터다. 
실제 그 데이터를 가져다 이 스파크 컨텍스트 라는 이 객체를 통해가지고 거기서 그 rdd 를 만듭니다. 쉽게 얘기하면 그 데이터셋을 갖다가 만들어낸다
그떄 만들어낼떄 그 오브젝트 가 스파크 컨텍스트다

자 뭐 지금 이해안되든 상관없음

##### 드라이버 프로그램
예쩐에 우리가 하둡할떄 그 자바 코드 여러분들한테 보여드렸죠 그리고 run 이렇게 나온단 말이에요 그쵸, run하고 나서 실제 맵퍼와 리듀스 를 갖다가 다실행시키고 맨나중에 그 걔네들이 끝날떄까지 폴링 하면서 기다리잔아 
wait for completion 함수있었던거 기억나죠 

그 프로그램 처럼 얘네들도 똑같다 실질적으로 그 어떤 잡을 가져다 예를들어서 워드 카운트 다 그러면 그 워드 카운트를 수행해 라고 여러분들이 드라이버 프로그램을 런 해야된단 말이에요실질적으로 그게 수행하는거는 자 엑스큐터라고 여러분들이 따로 클러스터 용으로 그걸 짜셔야 되지만 하둡에서도 똑같았다 하둡에서도 똑같이 맵퍼와 리듀스는 여러분들 이 짜셔야 했다 하둡에서 여러분들이 짜셔야 할건 맵퍼하고 리듀서 걔네들이 사실은, 
맵퍼와 리듀서가있고 걔네들이 여기에서는 엑스큐터에 해당한다
두개가 

따로 얘네들은 그걸 가져다 맵퍼와 리듀스로 , 맵 리듀스 모델이 아니기떄문에 맵퍼와 리듀스를 나눠놓치는 않았지만 실질적으로 클러스터에서 돌아가면서 실질적으로 일을 하는놈이 엑스큐터다 얘네들이다.
이 엑스큐터 는 하둡의 리듀서 에서는 맵퍼와 리듀서일 뿐이다

아시겟죠 자 그리고 그 맵퍼와 리듀서 아니면 저 엑스큐터 를 가져다 실질적으로 태스크를 줘가지고 일을 수행하도록 만드는 말그대로 드라이브 한일 그 드라이브 런 프로그램이 드라이버 프로그램이다 아시다싶이 여기 보시면 알겠지만 이 드라이버 프로그램 자체가 스파크 컨텍스트를 포함하고있다.
실질적으로 런 프로그램 보면 시작 자체가 이 스파크 컨텍스트를 갖다가 스페스피 파이 하는 그코드 부터 시작을합니다. 자그리고 당연히 뭐그런 이 스파크 컨텍스트를 통해가지고 컴플리션 다하고요 왜냐하면 그 지금 노드라든지 지금 아이피라든지 아니면 그모든걸 다 알려줘야 한다 자 그리고 이 드라이버 프로그램 내에 액션이 갖다가 뭐 스파크 액션이 드라이버 내에서 수행된다. 이렇게 나온다 말이짜구 꼬이고 하는데 
지금 걱정 ㄴㄴ 지금 오버롤 하는걸 가져다 여러분들한테 훑어 드리는거기 떄문에 헷갈릴수있는데 구지 먼저 미리 조금 말씀드리면 이 액션이라는건 스파크는요 어 데이터를 갖다가 제일 먼저 rdd 일 , rdd라는 데이터를 가져다 데이터 셋을 갖다가 뽑아내고 그 데이터를 가지고서 처리를 한다 중간처리를 막한다. 중간 처리를 데이터를 갖다가 바꿔가는 과정을 트랜스포메이션이라고하는데 데이터를 갖다가 트랜스포메이션을 하고 맨 나중에 그 데이터 가 다 ?? 끝나면 자 결과값을 던져줘 아니면 결과값을 저장해 여러분들이 스파크 요번에 그 프로젝트 해보시면 맨마지막에 실제 그결과 자체를 하둡에 파일시스템을 이용해서 저장한다 
나오죠 save as 그부분도 마찬가지다 실질적으로 그 결과값을 갖다가 내가 갖고 오는 과정아니면은 그 최종 결과값을 저장하는 과정
그 최종 결과값을 가져오는 그런 행위를 얘네들은 액션이라고 합니다.
물론 걱정 ㄴㄴ
액션 수십가지 다 보여드리겠다. 이게 그게 액션이다. 맨마지막 에 수집하는 과정을 액션이다. 액션 자체도 드라이버 내에서 수행이 된다. 자 그리고 스파크에서 자 애플리케이션 짜봐 스파크에서 프로그래밍을 한다라고 얘기하면 여러분들이 짜셔야 되는건 두개다.
당연히 드라이버 프로그램을 짜야되고 하둡 마찬가지다 
드라이버 프로그램 짜야되고, 실제 맵퍼와 리듀스를 여러분이 짯듯이 얘네들도 그 엑스큐터를 갖다가 짜야된다. 실질적으로 그 클러스터에서 돌아가는거는 얘네 프로그램이다  이 두개 프로그램을 다 짜야되는데 자 저거를 가져다 그냥 스파크 프로그램에서 애플리케이션이다라고하면 이런식으로 결과프로그램과 엑스큐터 두개를 가져다 여러분들이 짜셔야 된다.

자 클러스터 매니저인데 , 클러스터 매니저 이렇게 가운데에 있었죠 
클러스터 매니저가 있었는데 클러스터 매니저는 한마디로 얘끼하면 리소스 매니저다 
클러스터가 있을때 어 여기서는 클러스터 매니저라고 통상적으로 얘기하는데 어 리소스 매니저라고 생각하시면됩니다. 클러스터에 리소스를 관리하는놈이다 왜냐하면 그 실제 그 클러스터가 여러분 하둡 에서요 하둡 맵 리듀스에서 네임노드 기억나시죠 

네임노드가 어 프라이메리고 네임노드가 있었고 그 밑에 데이터 노드들이 있어가지고 그데이터노드들이 일을 했단 말이에요 기억나시죠 그떄 이제 마스터 역할을 했던것이 네임 노드였다 얘네들이 이제는 클러스터 매니저 역할을합니다. 얘가 그런 모든 데이터 노드에 그런 리소스들이나 스케쥴링 이라든지 그런 모든것들을 다 감당을 합니다 아시겠쬬 그 역할을 하는게 클러스터 매니저다 클러스터 매니저가 있는데 여기서는 어 크게 3가지 
(standalone manager, YARN, Apache Mesos) 유명한건 이 두가지다 얀이라든지 아파치 리소스이다.
이 리소스는 제가 살짝 말씀드렸다 이것도 역시 버클리 amp 랩에서 나온건데 
리소스, 얀같은 경우가 그런역할을한다 실제 클러스터 위에서 따로 노드가 돌면서 노드가 프라이메리 역할을 하고 이 프라이 메리 역할 마스터 역할을 한다
그러면서 각각 이 노드 위치가 어딨는지 ,각각 노드가 죽었는지 살았는지 아니면 그런 핑같은것을 떄려가지고 그런 모든 역할을 얘가 다합니다
아시겟죠 클러스터 매니저 역할을 하는데 
이 클러스터 매니저 에 관점에서 이제 디플로이를 하는데 실제 클러스터를 아니면 그 여러분들이 드라이버 프로그램을 디플로이 할떄 크게 두가지로 나눠진다. 
첫번쨰 가 클라이언트 모드가 있고 두번째가 클러스터 모드가 있는데
그렇다고 클러스터 모드가 뭐그런 클라이언트 모드 가 무슨 클러스터 모드가 아니냐 그런 의미는 아니다 오해하시면 안된다. 이때이게 그 디플로이 모드는요 어떤 관점에서 이게 클라스터 클라이언트라는 어떤 관점에서 나눠지냐면 실제 아까 드라이버 프로그램이 있었잔아요 그 드라이버 프로그램이 어디서 실행 됬냐 이거임 결과적으로 그 드라이버 프로그램이 실행이 되어야 하는데 그 드라이버 프로그램이 자 여러분들이 만약에 클라이언트에요 예를들어서 클라이언트인데 이 워드 예를들어서 뭐 워드 카운트를 가져다 실행해줘 라고 여러분들이 다 짯다 가정해봐요 그런 여러분들 컴퓨터에서 저 하둡 이 아니고 스파크 클러스터에다 던질거라고 일을 가져다 그랬을때 그 드라이버 프로그램은요 여러분 컴퓨터에서 돌수도있고 아니면은 나한테 돌지마, 그게 아니라 클러스터 너네한테서 돌아 이렇게 할수도있어요 드라이버프로그램이 
그 드라이버프로그램이 여러분 짜신 그 드라이버 프로그램이 어디서 수행되냐 따라서 클라이언트 모듈일수도 있고 클러스터 모듈일수도 있습니다. 실제 만약에 여러분들 컴퓨터에서 노트북에서 그런식으로 나한테서 클라이언트에서 돌아가면은 이제 그게 클라이언트 모드 입니다 
드라이버 그 프로그램이 

그게 아니라 내가 클라이언트가 잡을 가져다 딱 던지고 나서 그다음에 나는 ?? 빠질거야 자 이 드라이버 프로그램이 야 클러스터 너네 노드내에서 돌아 이렇게 할수있는데 그런식으로 그 드라이버 프로그램이 그 클러스터 데이터 노드에서 돌아가면 그거는 클러스터 모드 입니다 그런데 이게 각각 일장 일단?? 있어요 일장 일단이 뭔가 
디폴트 는 클라이언트 모드인데 여러분들 제가 데모 보여드렸는데 기억나시죠 제가 일일히 쉘에서 타이필 가지고 인터렉티브하게 작업을 했단말이야 그게 클라이언트 모드입니다.
그게 왜 중요하냐면 모든 일을 가져다 스파크가 다 처리 하고 다 처리하고 나서 최종 데이터가 나오는데 그 최종 데이터 값을 가져다 던져줘 그러면 그 데이터가 어디로 가냐면요 당연히 드라이버 프로그램으로 간다 
그 드라이버한테 리턴이 되요 그렇기 떄문에 그 드라이버, 최종 데이터를 여러분들이 만약에 내클라이언트 나한테서 내 노트북 쓰면 받고 싶으면 아님 내 클라이언트 머신에서 받고싶으면 클라이언트 모드로 실행하는거고 통상적으로 디폴트가 저거에요 왜냐하면 내가 필요한 데이터 잔아요 아시겟죠 그게 아니라 그냥 그 클러스터 자체 저장할수도 있습니다. 클러스터 자체 에다가 그 드라이버를 실행시켜 가지고 최종결과값을 드라이버 한테 던저주고 그 드라이버가 로컬 파일 시스템이나 아니면 hdfs 로 클러스터 자체 에 저장할수있는데 그 모드가 클러스터 이다. 그러다 보니까 클러스터 모드로 만약에 여러분들이 노리게 될거같은데 그 리소스를 갖다가 어느정도 리절브를 해야된다. 아시겟죠 왜냐하면 내 로컬 컴퓨터가 아니잔아 그러면 그 클라이언트에 어느정도 미리 admin한테 사전 협의가 되든 모가 어떻게 되든지 간에 리소스 를 어느정도 할당은 해놔야 한다. 아시겟죠 메모리든 그게 로컬스토리지가 됫든 
어느정도 리소스 가 필요해요 
그런 반면에 클라이언트 같은 경우는 내머신이잔아요 
그렇기 떄문에 그런 클라이언트 에 그런 리소스를 갖다가 어 무시?? 하거나 아니면 그런거를 갖다가 리절브할 필요가없다.

그러고 클라이언트 모드 같은 경우는 어 자 미리 얘기
인터랙티브 모드로 여러분들이 작업을 하고싶다 스파크 를 이용해가지고 인터렉티브 모드로 작업을 하고싶을떄는 클라이언트 모드로 해야함 왜냐하면 드라이버 프로그램이 내 로컬에서 돌아야지 내가 도중에 인터렉티브 걸어서내가 중간결과 값을 받던지 아니면 무슨 쿼리를 해서 값을 던지든지 그런식으로 인터렉티브 하게 작동을 하지 드라이버를 갖다가 이미 만들어가지고 클러스터에 툭 던져놓고 나는 빠져버리면 사실 인터렉티브하게 작업을 할수없다 아시겟죠 

그래서 인터렉티브 모드 자체는 클라이언트다. 그래서 디폴트다 제가 그때 실행했을때 아무것도 건드리지 않은게 디폴트이다. 그래서 그떄 뭐했어요 그쵸 그떄 인터렉티브 모드, 스파크쉘에서 제가 인터렉티브 모드로 작업을 했었잔아요
데모를 보여드릴때 근데 그게 아니라 클러스터 모드 같은 경우는 얘네들 같은경우는 인터렉티브 모드 라기 보다는 배치 잡에 맞다 
왜냐하면 여러분들 이미다 만들어 놓고 그냥 클라이언트에 던져주고 끝나는거에요 나는 아무것도 안해 이런식이다. 그떄 작업을 항상 그런형태로 하게 된게 클러스터 모드 이다. 어떤게 좋다 나쁘다 그런 의미는 아니다.
아시게죠 

## spark components 
실질적으로 사실은 열심히 뺑이를 까면서 열심히 일을 하는 노드입니다. 실질적으로 그 데이터 노드 처럼 하둡 맵 리듀스에서 데이터 노드랑 똑같은 역할을 하는게 얘네들의 워커 노드이다 자 드라이버 프로그램이 있고 자 클라이언트 매니저 클러스터 매니저 리소스 매니저라고도 하고 얘네들이랑 이제 인터렉션을 거쳐가지고 뭐 데이터를 던져주던 태스크 를 던져주던 그런 역할을 하게 되죠 그랬을때 실질적으로 그 일을 하게되는 게 이 워크 노드인데 
이워크노드에 속에서 이제 엑스큐터가 돌아가게 되고 이 엑스큐터가 각각 태스크 하나당 컨커런트 하게 다 돌아간다 이떄에 이 태스크 라는거는 여러분들이 이미 맵 리듀스 시간에 배웠다 싶이 잡을 가져다 잘게 잘게 쪼개놓은 거다. 잘게 잘게 쪼개 놔가지고 여러개의 태스크가 모였을떄 하나의 잡을 이루게 되는거고 실제 그 일을 수행하개 되는 그 미니멈 유닛을 갖다가 태스크 라고 합니다. 그떄 맵 태스크 리듀스 태스크 이런식으로 있었잔아 
그쵸 그런식으로 잘게 쪼개놓은 그런 하나의 일의 단위를 갖다가 태스크 라고 하는데 이 엑스큐터가 이 각각의 태스크를 하나씩 받아가지고 컨커런트하게 작업을 수행을해서 결과값을 드라이버에 던져주게 됩니다

자 요거 보시면 역시나 우리는 컴싸 코드로 봐야지 정신을 차리지 

## Spark programming model
드라이버 프로그램인데 스파크 프로그래밍이 어떤식으로 구성되는지 살짝 보자
보면 이해가 수월하다
자 스파크 
이 처음에 보시면 스파크 컨택스트를 가져다 이런식으로 지정을해 물론이게 완벽한 코드는 아닙니다 자 스파크 컨택스트 이 클래스를 불러가지고 자 그 스파크 컨택스트 그 오브젝트를 하나만든다 물론 요기 뒤에 빠졌는데 요 뒤에 어 보면은 파라미터가 잔뜩 들어가요 아이피 주소라든지 그런 잡이름 이라든지 그런것들이 컨텍스트 그런 실제 이 잡을 수행하기 위해서 필요한 컨텍스트들이 파일로 쭉 다 들어간다 5~6가지가 
그리고 나서이제 그 sc 요 오브젝트 만들어지는데 그 다음 라인을 보시면은 자 rdd 라고 나오잔아요 그쵸 근데 이 rdd가 요 스파크 컨텍스트 오브젝트 에 있는 이 텍스트 파일이라는 요 매소드를 통해서 사실은 만들어집니다 이 텍스트 파일 요 함수를 갖다가 호출하면서 사실 rdd가 만들어지는데 요거는 물론 그데이터가 텍스트 데이터에 하다떄문입니다?? 여러분들ㅇ 실제 지금 스파크 숙제 하시게 되시면 코드 자체가 저 그대로다 거기서 보면 그 데이터 자체가 텍스트 파일이거든요 그 텍스트 파일에서 rdd를 만들어내는 그런 함수 자체가 그 이름이 텍스트 파일이다. rdd나 만일에 각각 그런 sql 이나 각각 따로있는데 그거는 그떄 해당되는 메소드를 부르면됩니다 어쩃든지간에 hdfs 에서 데이터를 읽어가지고 그 데이터를 가져다 처리를 해서 최종적으로 리턴해주는게 rdd라는건데 어 요거는 알아두셔야 합니다 지금 나오는 rdd 특징 이거는 지금을 이해하지는 말고 슬라이드 자세하게 나온다 그떄 배우고 나서 앞에서 돌아보시면 이해 갈것이다 지금 설명 안한다 rdd라고 나오는데 스파크 를 갖다가 예를들어서 어 특징 짓는 한 단어를 애기해라 그럼 rdd다.

rdd라고 대답을 해야한다 인메모리 라고 프로세싱이라고 얘기하는 사람도있는데 인메모리 기능있는거지 얘네들은 무조건 메모리에서 돌아간후 100% 돌아가는건 아니다. 착각 ㄴㄴ
메모리에 여러분들 스페스파이 해가지고 그만큼 충분한 메모리가 있을떄 그만큼 돌아가는거지 메모리가 부족한데 인메모리 프로세싱 절대 안된다. 
얘네들 도 실질적으로 ?? 프로세싱 많이합니다
어쩃거나 스파크에서 가장 핵심되는 단어는 rdd이다.
그정도로 rdd는 중요하다 
rdd는 자 
resilient냐 의미 자체가 알고있는 단어뜻 그대로다 근데 왜 데이터 셋 분산 이되어있는 데이터셋인것도 알겠어 
왜, 분산 시스템이잔아요 데이터를 청크를 나눠서 분산으로 쫙 뿌려가지고 클러스터에서 데이터를 처리할꺼거든요 그러니까 분산 데이터 셋이겟지 그런데 이게 RESILIENT 하다 라는얘끼는 나중에 여러분에 폴트 타이런스 부분에 제가 커버하면서 다시 설명을 드리겠지만 미리 조금 설명을 드리면 이 rdd 라는 데이터를 아까 제가 그런식으로 여러분들이 데이터를 만들고 나면요 이걸 가져다 분산 시스템에다가 데이터를 확 뿌릴꺼거든요 그쵸 근데 예를들어서 재수 없어서 노드 하나 죽어버리면 아니면 데이터 날아가버리면 자 그러면은 끝장나느냐 물론 레플리케이션 팩터를 주거나 hdfs 측면에서 처리할 수 있겠지만 그거는 그거고 얘네 자체 rdd 자체에서 얘네들이 폴트 타일런스 기능이 있다. 
그게왜 resilient 하느냐 그 데이터 셋 하나가 죽어버려도 노드가 죽어버려도 그 rdd가 사라지는게 아니라 rdd를 다시 만들어낼수있어요 
그걸 가져다 레플리케이션 한걸가져다 치사하게 끌어 오는게 아니라 막 rdd를 새로 만들수있다. 새로 만들게 할수있다, 그래서 얘네들이 resilient 하다 라고 말한다.
그게 왜그런지는 설명을 드린다
어떻게 이게 가능한지도 설명을 드릴꺼에요 

## RDD: Rwsilient Distributed Datasets
자 rdd입니다 금방 말씀드렸죠
resilient 하고 디스트리 비우트한 데이터 셋 
갖다가 
자 클러스터 노드에다가 분산 되어있는 오브젝트를 가져다 rdd라고 하는데 실제 이 데이터 그 프로세싱이라든지 스파크를 할떄 그런 모든 어 오퍼레이션 자체가 이 rdd를 기준으로 한다. 그리고 rdd가 일단 만들어지면은 3번쨰 보면 이뮤터블 하다고 나오는데 자 rdd는 일단 만들어지고 나면 그게 수정불가능하다 말그대로 이뮤터블 하다  rdd 자체를 바꾸거나 건드리게 할수없다. 자 아시겠쬬 
그리고 여기보시면 rdd는 뭐 메모리라든지 디스크리에이져 펄시스트 가 될수있다 이렇게 나오는데 다른 얘기가 아니라 메모리에 펄시스트 된다가 되니까 메모리에다가 캐시가 된다 라는 얘기임 캐시 될수있다 라는 얘기임 
그리고 폴트 타이런트 애기가 여기 살짝쿵 나오는데 어 rdd 는 폴트 타일런트 합니다 아까 말씀드렸죠 실제 그 rdd에 파티션이나 rdd 자체가 확 날아가도 다시 생성을 해낼수있어요 그렇기 떄문에 폴트 타일런트 합니다
어떻게 lineage 정보를 가지고 있거든요, 리니지 오락 아님
이떄 리니지 그 단어의 리니지 = 혈통
리니지 정보를 갖고있다 그래서 쉽게 얘기하면 내 족보정보를 갖고있다. 내가 이 내 rdd가 어느 족보를 통해서 만들어졌는지를 알수있다 그렇기떄문에 내가 설사 날아가도 그 족보 혈통 그 리니지정보를 갖고있어요 

그래서 내 쉽게얘기하면 내 족보 정보를 가지고 있어요 내가 내 rdd가 어느족보를 통해서 만들어졌는지를 알수있다 그렇기 떄문에 내가 설 사 날아가도 그 족보 형통이 있기떄문에 정보를 갖고있기때문에 다시 만들어질 수있다. 그런 방식으로 얘는 폶트 타일런시를 갖다가 제공을 한다.그러면 rdd는 어떻게 만들어지느냐 여러분들이 숙제를 하게 될때는 3번째 케이스이다 rdd는 hdfs 이든지 로컬파일 시스템이던지 간에 자 그런 거를 통해서 곧바로 텍스트파일이라든지 그런 함수를 통해서 곧바로 만들어질수도있고 아니면 rdd가요 rdd가 만들어지는데 여러분 rdd가 한번 만들어지면 끝이 아니야 
rdd는요 만들어지고 나서 프로세싱을 거치면 다른 rdd 가 만들어지고요 이 프로세싱을 하면 다른 rdd가 또만들어진다 아까 근데 보시면은 이뮤터블 하다고 그랬잔아요 이뮤터블 하다라는게 일단 만들어진 rdd를 바꿀수없다라는 얘기지 rdd가 바뀌지 않는다라는 얘기는 아닌거다 아시겟죠 그래서 아웃던 ?? rdd가 만들어지면 이 걸 바탕으로 여러분들이 뭐 필터링을 하던 뭔가를 리듀스 하던 맵핑작업을하던 뭔가를 통해서 새로운 rdd가 만들어지고 자식 rdd가 만들어지는거다. 그리고 이 자식 rdd를통해서 여러분들 프로세싱을 하면 또다른 자식 rdd 가 또만들어진다 이게 여기서 얘기하는 리니지 , 리니지 인포메이션이다
그래서 그러면 부모 내부모가 누군지 내 부모의 부모가 누군지 난 알고있어 그리고 무슨 프로세싱을 통해서 내가 만들어졌는지 다 킾핑을 하고 있어 그렇기 때문에 내가 설사 날아가도 그 프로세싱이 뭔지는 알고있고 그리고 나에 직속 부모가 누군지 알고있기떄문에 새로 만들면 되는겁니다 아시겟죠 
그렇게 그 관점에서 바라보면 이얘기가 그얘기다 rdd는 자 기존에 있던 여러분들 갖고있는 파일에서도 만들수있고 그리고 아니면 이미 만들어져있는 rdd에서 다른 rdd를 새로 또 만들수있고 
그리고 첫번째 이건 파이선이나 
리스트나 정보
파이선에서 패럴라이징 함수르 써가지고 만들수도있다. 그 이것까지는 자세하게 ㄴㄴ
파이썬 에서 컬렉션 , 리스트아님 그런 정보를 통해서 거기서 곧바로 만들어낼수도 있긴 합니다 아 그리고 보시면 이제 파티션, 당연히 남길수있죠 그 기본적으로 똑같다 
기본적으로 128 메가 단위로 쭉쭉 파티션 다 나누 그리고 그걸 가져다 더 잘게 얼마든지 나눌 수도 있다

아시겟죠 그리고 파티션 개수를 몇개까지 내가 할껀지 여러분들 그 콤파주고 옆에 파라미터를 다 줄수있다 아이덴티 만들때 
아시겟죠 아까 그 구지 말씀드리면 텍스트파일있잔아요 요 파일이름주고 , 뒤에 만약에 4 이렇게 주면 파티션이 4개가 된다.
우리는 코딩적인 측면이구요 
어쩃든지 간에 프로그래머 가 그렇게 파티션 개수를 정할수있다. rdd 개수를 
자 rdd가 자세히 모르겠지만 

rdd가 그렇게 생겨먹은 데이터셋인건 알겠어 그리고 스파크가 그 rdd 가지고 뭐 프로세싱을 한다는것도 알겠어

그러면 rdd를 가지고 무슨짓을 할수있을까? 
자 rdd에 가장 대표적인 
rdd를 가지고 이 3가지 일을 합니다.

## RDD operaions
1. 트랜스포메이션이다 
기존에 있던 데이터 아니면은 어 기존에 있던 rdd 만들어진 데이터로부터 무슨 operation을 합니다 예를들어서 필터링을 하고싶어 이 실제 데이터가 처음에 rdd가 만들어졌지만 거기서예를들어서 필요없는 데이터를 내가 만약에 필터링 해가지고 새로운 rdd를 만들고싶어. 그러면은 데이터가 트랜스폼이 되잔아요 그렇죠 그런식에 형태이다 데이터를 가져다 rdd에서 데이터를 자꾸 자꾸 새로운 형태로 만들어내는것이다 그게 트랜스포메이션이다.
그리고 재밌는게 이 트랜스포메이션은요 어 여러분들이 나중에 숙제, 이 트랜스포매이션에 해당되는 그런 그 operation들이 수십가지 있다 그리고 액션에 해당되는 operation 도 수십가지 있다 테이블에 보여줄것이다 자 이 트랜스포메이션은요 여러분 그 워드 카운트 하시게 되면은 제가 그 데모시간에 보여드렸던거 기억할지 모르겠는데 실제 데이터를 가져다 처음에 rdd 만들고 그러고 나서 제가 뭐 맵도 하고 제일 먼저 플랫맴하고 그다음에 맵 수행하고 그다음에 리듀스 바이 키 이런식으로 3개를 동시에 수행했다 
데이터를 가져다 가공해 나가는 과정이다 처음에 제일 먼저 rdd 만들어내고 플랫맵을 통해서 데이터 를 rdd를 다 트랜스포메이션을 하고 그리고 맵 과정을 쉽핑 시켜가지고 데이터를 다시 새로운 rdd를 만들고 그리고 그걸 가져다 리듀스 작업을 합니다. 
리듀 스 바이 키 , 키별로 리듀스를 하는 그런 작업을 딱 거쳐서 나오면 워드 카운트 최종결과값이 나옵니다
그런데 잘생각해보면 하둡에서는 요 이모든 작업을 하게되면 맵 해그?는 맵 리듀싱  리듀스핵? 리듀스 실행이되요 근데 이제 재밌는게 골떄리는게 그렇게 하라고 하면 안합니다 이게 그말이다 lazy operation이다 이게 트랜스포메이션 해 라고 해도 얘네들은 수행하지 않게 계속 그냥 스택에 쌓아놓고있다 내가 할일만 리스타업 해놓고 그냥 꼐속 기다린다 얘들은 그냥 몇개를 하던지 간에 여러분들 트랜스포메이션 몇개를 줘도 수행안해요 수행 안하고 자 액션이라는 그 해당되는 오퍼레이션들이 그 액션을 갖다가 취하는순간 이때까지 모아 뒀던 트랜스 포메이션 작업을 동시에 쫙 수행을 한다. 그러고 나서 액션을 딱 하고 끝나는거야 그래서 여러분들이 실질적으로 여러분들이 그 요번에 작업을 해보면 나중에 해보시길 바랍니다 여러분들이 아무리 맵이니 플랫맵이니 리듀서 줘도 아무일도 안한다. 아무일도 안하고 맨마지막 여러분 스트릭? 트에서 맨마지막 코드보면 setasdata  셋애즈파인 이렇게 되어있는데요 그게 액션이다. 그 액션을 갖다가 딱 치는순간 얘가 맵 이랑 리듀서 갖다가 막 작업을 해가지고 그제서야 작업을 다끝내고 그데이터를 하둡 파일 이나 로컬파일 시스템으로 저장을 한다 이게 그얘기다 
이 액션이 실제 명령이 떨어지기 전까지는 트랜스포메이션 여러분들이 아무리 오퍼레이션을 줘도 아무리 코드를 짜도 얘는 아무일 안한다. 
이런 트랜스포메이션에 해당하는 명령어 들이있어 맵이라든지 필터라든지뭐 플랫맵이라든지뒤에 종류가 나온다.
2. 액션
액션은 여러분들이 모든 트랜스폼 프로세스 다 거쳐가지고 최종 데이터를 클라이트 ?? 하는 과정이 액션이다 최종 결과값을 내라 이게 액션이다.
그래서 여기 보시면은 카운터 라든지 얘기하면 예를들어가지고 뭐 카운터 가 지금 몇개야 최종데이터가 몇개야 
카운트를 세는거고 그리고 리듀스는 여러분들 다 아시죠 
리듀스에요 실질적으로 
그리고 컬렉트는 최종 결과값을 다 끌어오는것이다.
그리고 테이크는 요사실 이 가운데에 이거 저속에 숫자를 정수를 주는데 테이크 5를 주면은 자 니가 뽑아낸 결과값중에서 탑 5 다섯개만 나한테 던져줘 이거임 
자 공통점이 얘네는 뭐냐면 결과값을 내놓으라는거임 그게 액션이다.
그리고 펄시스턴시는 
3. persistence
캐싱하는거에요 그냥 한마디로 얘기하면 엄밀히 얘기하면 펄시스턴시는 물론 그 디스크에도 에다가 저장을 할수있긴 합니다만은 통상적으로 얘네들 펄시스턴시는 캐시하는거임 메모리에다가 
그래서 보시면 뭐 디스크에도 옵션리 하게 아니면 램이든지  디스크 둘다 믹스해서 저장할수있다 
나오죠 실제 얘네들은 두개다. 펄시스트 뭐뭐 .펄시스터를 주거나 아니면 캐시 이렇게 주면 자 여러분들이 파티션해서 다 만들어져있는 여러개의 rdd가 있을거 아니에요 여러분들이 생각하시는 이 rdd는 어 이거 로컬에 저장하지 말고 앞으로 또 쓰이고 또 자주 쓰일것이기 때문에 이거는 중요한 데이터 이기 때문에 나는 이것을 가져다 메모리에다 넣놓고 속도를 내가 높이고 싶어 예를들어가지고 그럴떄 그런 rdd 에다가 지정해가지고 펄시스턴시 아니면 캐시 이렇게 주면 얘네는 메모리 에 올라가 있어요 
그럼 얘네들은 flush 되지 않습니다. 여러분들이 flush 하기 전까지는 flush 되지 않는다.
그런용도로 쓰는겁니다. 
이 함수 펄시스턴시 , 캐시란 함수는 
그래서 이거를 가져다 persistence 라고합니다
실질적으로 스파크는 요 3가지가 다다. 요 3가지 형태로 만들어져서 돌아갑니다 
이 operation을 가져다 한마디로 다이어그램을 그려보면은 요렇게 생겼다.

## RDD operations
rdd가 있어요 처음에 rdd는 
그 로우 데이터에서 만들어내든 만들어진 
만들어 내든지 간에 아니면 이미 만들어진 데이터 rdd 로부터 
트랜스포메이션 작업을 거쳐서 새로운 rdd를 만들어내든지 간에 자 rdd가 일단 이렇게 만들어집니다 
맵핑이라든지 필터라든지 이런 트랜스포메이션 과정을 거쳐서 rdd가 만들어진다 
그런데 여러분 보이시나요 살짝쿵 
point to parent = 자식이 내 직속 부모 가르치는 포인터를 가지고 있다 물론 그 프로세싱 자체 오퍼레이션 자체 도 가지고 있는 오퍼레이션자체는 코드에 있잔아요 그쵸 
그리고 내가 오퍼레이션을 알고 부모를 알고있기떄문에 내가 설사 rdd가 날아간다 하더라도 rdd를 새로 만들수있다고 말씀드렸다.
자 이런식으로 포인트를 얘네들은 만들떄마다 계속 해서 자기 부모 포인터를 가지고 있다 어쨋든 rdd가 이렇게 만들어지는 계쏙 트랜스포메이션 거치고 나중에 액션이라고 치면 
액션 치면 세이브 애즈 텍스트 파일 이라든지 리듀스라던지 이런식으로 액션 오퍼레이터 가 나오게 되면 그제서야 이때 모아놨던 그런 작업들을 가져다 다 거치면서 최종적으로 처리를 다하고 저장을 하던 여러분들한테 디스플레이 를 해주든 아니면 로컬파일로 저장을 하던 그런식으로 작업을 끝내게 된다. 이게 한눈에 잘보여주는 그림이다.

## 트랜스포메이션
일일 히 설명 안한다 
통상적으로 많이 쓰는게 맵이라 필터랑 플랫맵 많이쓰인다 
리듀스 바이키도 사실 많이쓰이는데 

액션 많다.
## 펄시스턴스
이미 말씀드렸다.
펄시스턴스는 사실 스파크에서 중요한 오퍼레이션중에 하나다 이 
기능이 없었으면 스파크가 그렇게 빨리 동작을 할수없다 스파크에서 굉장히 핵심이 되는 내용이다 그리고 기본적으로 rdd가 만들어지고 rdd가 트랜스포메이션 새로운 rdd만들어지고 계속해서 이렇게 만들어 나가는데 기본적으로 rdd는 그냥 계속 그런식으로 재생산한다. 있는 데이터에서 자꾸자꾸 만들어낸다 근데 그게 아니라 그걸 가져다 만약에 여러분들이 그 캐시나 그런 디램 같은데다 만약에 여러분들이 핑잉 을 해두면 os시간에 핑 배웠쬬 그렇게 핑잉을 해두면 그 캐시를 보면 그걸 가져다 새로 만들 필요가 없이 이미 만들어진 그것 을 가져다 내가 실제 프로세싱할떄도 마찬가지고 남들한테 줄때도 마찬가지고 굉장히 빨리 처리할수있다 
리드갖다가 디스크 리드나 다 줄일수있다. 
당연한말이다 그런용도로 쓰기위함이다 실질적으로 여러분들이 rdd를 가져다 
요 rdd는 중요하니까 여러분들이 정한다 어떤 rdd가 캐시되 고 펄시스턴시 되는건 여러분들이 정하는거다 그것을 가져다가 어떤 rdd를 갖다가 할꺼냐 할떄 쓰는 명령이 아까 말씀드렸다싶이 persistence랑 캐시라는 명령어다 
실제 함수이다 이 함수를 쓰면 그 rdd가 캐시에 핑잉이 되요 메모리에다가 핑잉이 된다. 그리고 아까 말씀드렸죠 자 폴트 타일런스가 나오고 왜 ? 내 부모에 자 리니지 정보를 다 가지고 있고 그리고 그리고 실제 컴퓨테이션에 필요한 그런 코드는 여러분들이 코드상에 다있으니까 만들어내면된다. 그쳐 그래서 얘네들은 리즐리언트 하고 
그리고 폴트 타일런트 하다 설사 rdd에 어떤 해당 파티션 이라든지 rdd가 날아가버려도 얼마든지 새로만들수있습니다.
자 이거 똑같은 얘긴데

## working with rdds
rdd를 갖다가 처음에 이제 데이터에서 어 데이터코드에서 rdd를 만들어내고 그래서 트랜스포메이션과정을 거쳐가지고 계속 트랜스포메이션을 하는 거다. 
트랜스포메이션 자체를 어렵다고 생각하지말자 여러분들이 하고자 하는일 그게 트랜스포메이션이다. 아시겟죠 내가 필터링 아웃해가지고 나중ㅇ ㅔ예제를 보여드리겠지만 
내가 무슨 로그에서 어떤 굉장한 서버에서 굉장히 많은 양의 
그런 로그 파일에서 내가 어떤 데이터를 내가 추출하고 싶어 그랬을떄 여러분들이 필터링 아웃할꺼고 아니면은 스플릿도하고 여러가지 작업을 할꺼라고 그쵸 그하는 작업 자체가 트랜스포메이션 과정이다 그리고 그 과정을 통해서 새로운 결과값이 나오잔아 
그게 새로 만들어진 트랜스포메이션 되서 새로 나온 rdd이다. 
그래서 rdd를 통해서 여러분들이 새로운 rdd가 계속 나오고 맨마지막에 되서 아 닥치고 결과를 내놔 그러면 은 열심히 열심히 작업들이 다수행되고 최종적으로 결과값을 통해서 여러분들 그 최종 데이터만 리턴되는 형태로 작동을한다.

## Example in Python : Wordcount
코드 보자
자 여러분들 파이선 얼마만큼 익숙한지 모르겠는데 여러분들한테 제가 파이선 가르쳐드리기 위한 용은 아님 실제 웃기잔아 
자 어렵지 않다.
텍스트 파일에서 그게 로컬파일이든 hdfs 상관없다 자 텍스트파일 데이터가 텍스트 파일이면 텍스트 파일이라는 함수를 통해서 우리가 만들어내요 rdd를 만들어낸다고 했다.
그리고나서 만들어낸 rdd를 가지고 트랜스포메이션 과정을 거친다. 이게 rdd를 이런식으로 만들어지고 그리고 트랜스포메이션 과정을 거칩니다 실제 여러분들 스칼라 코드를 보셔도여 플랫맵이랑 맵이랑 리듀스 바이키 3가지로 구성이 되어있다 물론 스칼라이기 때문에 묶으면 살짝 다르긴 하다 기본적으로 요 3개 에 그 트랜스포메이션 함수쓰는건 똑같다.
아시겟죠 이런식으로 트랜스포에미션 과정을 거치고 
count.collect 하게 되면은 자 output을 던져준다.
요 컬렉트는 아까 말씀드렸죠 액션이다. 
여기 컬렉트 하게 되면요 여기서 작업 한 모든 작업들이 드라이브프로그램 안으로 리턴된다.
아시겠쬬 얘는 그래서 드라이버 프로그램을 리턴해주고 그리고 
그 결과값을 그것 뿐만아니라 hdfs 에서 저장까지 해줘 
자 요거는 자 워드카운터가 그런식으로 동작하게 되는 모습이다 그런데 
아까 말씀드렸다 싶이 요단계까지는 실제 작업은 하지않는다. 
그냥 스택만 해두고
기다리고있는것이다 액션이 들어오기까지 기다리고 있다.
액션이 들어오면 그재서야 스파크가 이데이터를 다 처리하고 다작업을 하고 그다음에
이제 최종 결과값을 던져주는 그런 역할을한다. 
그래서 이거를 가져다 라인 바이 라인으로 조금더 살펴보면 
자 제일 처음에 
텍스트파일 
여러분들 알고있는 여러분들 입장에서는 680m 짜리 텍스트 파일 있잔아요 그파일에서 제일먼저 이제 요 과정을 거치게되면 
128메가 단위로 쭉쭉 쪼개서 그다음에 이런식으로 파티션 나눈것을 청크를 단위로 나눕니다 그게이제 텍스트 파일을 통해서 각각 rdd만들어지는 과정이다. 그러고 나서 rdd가 만들어지고 났으면 그다음엔 트랜스포메이션 과정을 계속 거친다 그래서 플랫 맵을 통해서 그 
플랫맵은 자 아 여러분 헷갈리실텐데 지금 설명 ㄴㄴ 플랫맵이랑 일반 맵이 뭐가 다른지는 설명해드리겠다 
뒷부분에 나온다 플랫맵도 어쩃든지 간에 맵이다. 맵인데 그걸 가져다 플랫하게 만드는것이다 
설명드린다.
자 맵과정을 거친다 물론 플랫 맵이에요
플랫 맵 과정을 거치고 그리고 보시면 알겟지만 그걸가져다 데이터를 가져다 스플릿 하죠 
람다 펑션 = 인라인 펑션
자 그래서 어쟷거나 한 라인 씩 가져와서 스플릿을 하잔아요 
공백단위로 
다 자른는거임 
그리고 이제 플랫맵 과정을 통해서 그렇게 나오면 그데이터를 가져다 맵과정을 거친다
그래서 그 각각 단어에 대해서 새로운 단어에 대해서 단어,1 단어,1 단어,1 이런식으로 작동, 기억나시죠 똑같이 이런식으로 작동을하고 그런식으로 만드어지고 나면은 
그다음에는 키별로 같은 값들 키별로 만들어지는 그 실제 그 카운트를 다 더해주는 작업을 하게되는데 그게 리듀스 작업이다 그게 바로 리듀스바이 키다.
키별로 소팅해가지고 거기다가 각각 a+b 벨리유인데 그 카운트를 다더해주면 이런 작업을 거치게 됩니다. 그러고 나서 컬렉트하게 되면 그 최종 결과값이 드라이버 로 옮겨 지게 되고 그리고 마지막에 그거를 가져다 아 난 저장할꺼야 
그결과값을 저장해줘 라고 하면 디스크에다 뭐 디스크든 뭐든 스토리지 에다가 데이터를 저장하게 된다. 이게 hdfs 나온다고 해서 헷갈리지 말자 이건 여러분들이 hdfs를 썻을때 그렇게 되는거고 그냥 여러분들이 로컬 파일 시스템이면 그냥 여러분들이 저장하실지 c: 그렇게 쓰면 로컬 파일로 시스템안으로 저장이된다.

순전 히 hdfs를 쓰는것이다.
자 요거도 꼭같다.
rdd input이 처음에 데이터가 오고요 데이터가 있고 rdd가 만들면 이런식으로 라인 바이 라인으로 단어별로 쪼개서 들어옵니다 그렇죠 근데 이게 플랫 맵 과정을 거치면 이게 플랫 맵 과정을 거치면 이 라인 바이 라인 들의 그 과정들이 하나로 묶어가지고 플랫 라이트?/ 된게 되고 그리고 이게 맵과정을 거쳐서 단어,1 단어,1 그러고 나서 리듀스바이 키를 통해서 다 더해져서 최종결과값이 나오는데 
여기서 나오는데 

## map vs flatMap
여기나온다 자 기존 데이터가 있으면요 만약에 rdd가 이런식으로 
rdd가 통상적으로 텍스트 같은 경우는 한라인씩 긁어 오거든요 긁어와서 아까처럼 그 파이선 경우는 리스트로 던져줘요 각 라인을 읽어서 리스트로 던져준다. 그래서 이것을 가져다 그냥 플랫맵이 아니라 맵 을 처리하게 되면 라인 하나를 읽어왔잔아 그쵸 라인을 읽어와가지고 그거를 아까 스플릿을할때 스페이스 단위로 슾플릿을 했거든요 각각 단어별로 슾플릿 이 나눠지고 라인별로 요게 맵이다. 
근데 플랫맵은 그런게 아니라 이 자체 맵 + 이제 그거를 가져다 플랫팅하게 만드는건데 이 각각 에 대해서 실제 파이선 면은 어 요 하나 자체가 리스트고 리스트 오브 리스트에요 
아시겟죠 
리스트가 있는데 그 각각 리스트 속 원소가 리스트 리스트 리스트 요런 데이터다 이 커다란 속에 있는 그 각각 리스트에서 그리스트 다없애버린것이다.하나의 리스트속에 전체 갔다가 정말 말그대로 평평하게 보이도록 만들어버린것이다

그게 플랫맵이다 
그래서 실질적으로 보면 각각 리스트별로 이렇게 나눠져 있던 얘뜰이 하나로 통쨰로 묶여가지고 어 그냥 플랫하게 보이잔아요 그래서 이게 플랫맵이다라고 한다

아시겟죠 그차이가 있는것이다.
그래서 아까 조금더 살펴보면 계속 반복해 서죄송한데

텍스트파일에서 읽어오는거 제일 먼저고 rdd 가 만들어지고 그다음에 트랜스포메이션 과정을 거친다 우리가 말씀드렸다 싶이 지금까지 말씀드렸던 요거 자체가 트랜스포메이션에 있는 오퍼레이션들이다. 그렇죠 그래서 rdd가 만들어지고 자 그걸 갖다가 컬렉트 해 라고 했더니 걔네들이 액션입니다. 액션쳐서 값이 값이 드라이버로 실질적으로 이제 나오게 되고 그러고 맨마지막으로 세이브 애즈 텍스트파일 같은 경우는 물론 이것만 쓰면 상관없지만 예제니까 그렇다 이거 역시도 액션이다. 그래서 나왔던 데이터를 얘는 드라이버로 던져주는것이고 애는 그거뿐만아니라 로컬 파잂시스템 이든 실제 스토리지 시스템에 데이터를 가져다 저장하게 되는 그런 과정을 보여준다.이게 콘센트??라는 그런 모습을 보여주는것이다 아시겟죠 

## Conceptual Representation
자아 
아까전에는 그 예제로 그 워드카운트 봤는데 워드 카운트 만 하니까 재미업으니까 다른거 하나더 가져왔다.
만약에 서버에 있는 그런 로그 기록을 가져다 여러분들이 바이닝을 한다 예를들어가지고 실제 여러분들이 어 하둡 제대로 돌려보면은 하둡만해도 로그 기록 엄청 납니다. 로그 파일이 굉장히 많아 어 로그를 갖다가 어떻게 분석을 하고 어떻게 처리할것인가도 사실 굉장 히 골치아프다 그래서 간단한 예제다.자로그파일이 있습니다. 예를들어서 굉장히 큰 용량의 로그파일이다 라고 가정을 했을떄 우리가 뭘하고 싶으냐면 여기서 뭔가 에러가 났어 분명히 어떤 시스템에 서 에러가 난거같은데 거기서 어 에러난 부분이 어딘지 모른지 
찾고싶어 자그런부분이 만약에 그런 처리를 한다고 가정해보죠 
그럴떄 그런 파일이 만약에 있다고 가정하면 그 로그파일 을 가져와가지고 그것을 가져다 이제 텍스트파일 이런식으로 rdd 만들고 그리고 자 여기서 보시면 필터아웃을 ?? 합니다
저 rdd 재천? 만들고나서 그 다음에 그 rdd를 가져다 기본으로 해서 자 필터링을 하겟죠 예를들어서 뭐 그 우리시스템은 에러가 나면 그속에다 대문자 에러 뭐 이런식으로 항상 그런식으로 해서 프린트 아웃한다 아니면 로그인을 한다라는 규칙이 있다라고 만약에 가정하게 되면 자 
스타트 위드죠 그쵸 
파이썬 보면 어쩃거나 자 스타트 위드, 에러라고 시작한느 그런 문장을 갖다가 가져오는것이다 찾아냅니다 그러고 나서 그런 문장을 갖고나와서 그다음에 자 탭, 스플릿트 데이터를 가져다 그 문장을 가져오고 탭 단위로 스플릿을 합니다 그러게 되면 이 워드를 ?? 하겟죠 
자그러고 나서 그데이터를 가져다 보시면 알겟지만 자 그렇게 만들어진 트랜스포메이션 형태에서 나온 그 rdd 가지고 만약에 여러분들이 이걸 가져다 내가 캐시에다가 저장을 해놓고 프로세싱을 하고싶어 왜냐하면 처리를 많이해야하니까 
그럴때 그런 rdd.cache를 주시면 그 rdd가 메모리단으로 들어갑니다 그때부터 인메모리 프로세싱을 하게된다. 그렇게 하고 나서 거기서 여러분들이 이제 필터 아웃할떄 어 뭐 보시면은 그 문자들 중에 foo 라는 그런 단어가 들어있는 것들은 다 필터링 아웃을 하고 그리고그게 몇개가 나왔는지를 점 카운트 해가지고 이런식으로 
물론 이제 카운트는 액션이죠 어쨋거나 이렇게 필터링 아웃해서 어 그카운터를 갖다가 내가 돌려줘 라고 이런식으로 여러분들이 코드를 짜실수있다. 이런식으로 형태가 흘러갑니다 일반적으로 프로세싱을 할떄 
아시겟죠 그리고 나서 중간과정에 여러분들이 찾고싶은 그거는 여러분들 로그 를 가져다 마이닝을 어떻게 하느냐에 따라서 달려있을 뿐인거고 
그런 과정을 거치고 맨 나중에 저장을 하고싶으면 세이브애즈텍스트 파일 이런식으로 저장하던지 저장결과값을 저장을 하게 되는 그런 형태가 된다.
이예제를 보시면요 위키 피디아 자체 엔진을 갖고있는데 얘네들이 풀텍스트 서치를 합니다 예제다.
그 풀택스트 설치라는게 뭐냐면 말그대로 텍스트를 갖다가 처음부터 끝까지 다읽는것이다 
인덱싱 되가지고 해싱을 해가지고 내가 원하는 데이터를 탁 뽑아오는게 아니라 실제 성능 테스트를 하기 위해가지고 그 들어있는 데이터 그런 텍스를 가져다 서치하게 되는데 풀택스트 서치를 가져다 해봤더니 스파크였더니 인메모리 했던 형태의 1초 
로끝나버린다 이거를 가져다 만약에 디스크 넣고 뺴고 그짓을 하면 일일이 20초 걸린다 
그 일들을 스파크를 통해서 인메모리 프로세싱을 했더니 한 1초안되서 끝나버린다 이거를 가져다 다시 확대를 합니다.

1테라 바이트로 대폭 한번 늘려볼까 이렇게 해서 굉장히 큰용량으로 늘려서 그거를 다시 풀텍스트 리서치 해봤더니 한 5초 7초 정도에 끝나버리더라 근데 이걸가져다 디스크에다 넣고 뺴고 그작업을 하면 보통 170초 이렇게 걸린다.
굉장히 일을 줄여주게 된다. 사실은 스파크가 굉장한 능력이 있는건 사실이다.

## RDD Fault Tolerance
왜 어떤식으로 얘가 폴트 타일런스를 갔다가 지원을 하느냐 
아까 말씀드렸다 rdd는 만들어
트랜스포메이션을 거쳐가지고 rdd가 새로만들어지면 만들어질떄마다 자기 혈통 정보를 다 가지고 있어야된다. 각각 
포인터를 가지고서 부모를 각각 가리치는 포인터를 다 킾핑 하고 있고 그러고 보시면 알겠지만 데이터가 이렇게 생겼
이거 나오잔아요 필터아웃하고 그다음 맵어떻게 하고 각각 코드에 대해서 어떤식으로 어떤 코드를 그리고 어떤 트랜스포메이션을 거쳐서 내가 rdd가 만들어졌는지 에 대한 코드는 이미 코드내 있다. 그 정보 플러스 내가 어디로 부터 이 그 프로세싱을 했는지 만 알게되면은 새로운 rdd를 만드는 저런문제가 아닙니다.
그래서 여기보시면 하둡에서 데이터를 만들어내고 여기다가 이제 필터링 하잔아요  그쵸 그러면 이 필터해ㅅ ㅓ만들어진 이 rdd는 부모를 가리키게 되고 그리고 그 맵을 통해서 나온 rdd는 다시 원래있던 얘의 그 부모인 필터rdd를 갔다가 다시 가리키게 되는 그런 형태다 근데 여기서 이제 그얘기가 나온다 여러분들 그 혹시나 아까전에 rdd 말씀드릴때 그런생각을 하셨을지도 몰라요 자 rdd가 만들어지고 나면 이뮤터블 하다 rdd는 트랜스포메이션을 거쳐서 새로운 rdd는 만들어ㅈ질지 언정 rdd 자체가 바뀌지 않는다(시험)
rdd는 이뮤터블 하다고 말씀드렸는데 그게 이것떄문에 그렇다 왜냐하면 rdd자체가 이뮤터블해서 데이터를 가서 바꿔버리면 이 기능 지원 전혀 안됩니다
rdd가 이거는 이뮤터블 하기떄문에 이게 가능한것이다 
그래서 그기능 그거랑 이거랑은 일맥상통한 내용이다
폴트 타일런스를 제공하기 위해서 rdd를 가져다 이뮤터블 하게 만든다.


## spark soft ward stack
지금까지의 전반적은 프레임워크나 스파크 플로이 에 대해 말씀드린거고 
그게 아니라 여러분들 애플리케이션 따라서 스파크 어떤 코드 쓸지는 여러분이 결정한다.
도메인 마다 다르고 애플리케이션 마다 다르다.
어떤 걸 쓰셔야하는지 
내용이 스파크 코어부분이고 밑에 리소스 매니저 하게되는 클러스터 매니저라고 하기도 하는 
걔네들이 어쨋거나 리소스 매니저가 들어있고 그리고 실제 데이터를 읽어오는 그런 부분은 아마존 카산드라 hdfs 든 이런 스토리지 시스템 을 통해서 데이터 읽어오고 리소스 매니저가 매니지를 하고 스파크 코어 에서 스파크 스파크 작업을 하는데 자 보시면 크게 자 4가지 로 나눠진다 크게 여러분들이 만약에 인메모리 프로세싱해서 빅데이터 처리를 하고 싶을떄 그 애플리케이션이 
그 rdbms 처리해되는 그런 데이터라든지 그런식에 데이터를 가져다 스파크를 이용해서 처리를 해야 될거같으면 스파크 sql api 스면됨 깔면됨
스파크 기본
그런걸 쓰면됨 
데이터프레임 즈 = 스파크sql에 서 만들어진
원래 샤크였는데 이름이 바뀜
그리고 이제 머신러닝이다 (mlib)
얘네들이 머신러닝을 하기 위해서 딥러닝 그거를 그애플리케이션이 여러분들 처리 해야한다 이 라이브러리르 쓰시면된다. 이 api를 그대로 제공 받아서쓰시면된다.

그래프 x = nosql 그래프 프로세싱 하기위해서 여러분들이 써야될 그런 api x
자체 아파치 제공
그냥 쓰시면됨
마지막으로 스트리밍 어떻게 스트리밍 을 다룰지 쉽게 말하면 리얼타임 프로세싱 해야하는데 그런 데이터를 처리해야한다 스파크 프레임 워크를 가지고 그런 빅데이터 처리해야한다 그러면 스파크 스트리밍 api를 쓰면된다.

## spark sql
실제 말씀드렸다 싶이 sql 가져다 그런 데이터 그런 struct 데이터를 갖다가 어떻게 어 스파크 프레임워크에서 돌아갈수있도록 해줄건지에대한 api제공한다
실질적으로 얘네들은 스파크 sql은 처음 만들어질때는 shart ㅇ였는데
기존에 있던 아파치 하이브가 sql인데 
하둡 위에서 돌아가게 되는
그 sql인데 그 하이브를 가져다 포팅해서 스파크에 돌아가게 한게 스파크 sql임 
아파치 하이브 그대로 이거 스파크 sql 돌리면 그대로 돌아간다 포딩해서
하이브 ok, 쿼리를 수행할때 이제 하둡 맵 리듀스 위에서 그 sql 처리를 할려고 하니 대용량이면 괜찬은데 자잘한 sql 날리다 보니까 초기 세팅 작업이 너무든다 실제 하둡 돌려보면 파일뜯어보면 이니셜라이즈하고 실제 코딩작업하면 중간 데이터 쓰고 지우고 쓰고 지우고 굉장히 많이한다. 그런 작업들이 생기게 되는데 쿼리가 크면 이런작업일들이 그 프로세싱 타임 묻히게 되지만 쿼리 가 작은데이터를 처리하게 되면 쿼리를 작은 쿼리를 하게 되면 이게 그 중간과정이라든지 이니셜라이즈 작업이 포지션? 이 너무커지는것이다
상대적으로 내가 2초일을 하기 위해가지고 예를들어서 이니셜라이즈 작업을 5초라고 그러면 누가좋아합니가 말이 안된다. 하둡 맵 리듀스는 그런문제가 생긴다
그걸 가져다 스파크 프레임 워크 위에 올려가지고 작업하기 위해서 했던것이다 
왜냐하면 하이브가 기존에 위에서 돌아가는거거 든요 스파크를 돌려고 하니까 포팅을 한것이다 그게 스파크 sql이다 
스피드 업투 40, 업투 이해 , 함정이다
그런일은 잘벌어지지 않는다.
빨라졌다 칼럼 베이스다.

## 스파크 스트리밍 
스트리밍 데이터르 배웠다. 스트리밍 데이터를 처리하게 되는데 기본 키컨셉자체가 리얼타임 프로세싱을 하기위함이다.우리가 그 많은 데이터를 갖다가 이미 다가지고 있고 그걸 덤프해가지고 스토리지에 이미 들어있으면 스트리밍 이딴 데이터 처리가 왜필요해요 
필요가 없잔아요 이미들어있는데 그게아니라 들어오게 되면 그런 엄청난 데이터를 순식간에 리얼타임 프로세싱을 해야되는데 그걸 가져다 빨리처리하자 실질적으로 이 리얼타임 프로세싱 모델자체는 하둡의 맵 리듀스도 제공을 합니다 근데 기본적으로 성능이 떨어진다
그런데 얘네들이 인메모리 프로세싱을 하다보니까 그게 가능한데 
얘네 스파크 그 스트리밍 모델자체도 그림 자세히 보시면 잘나와있는데 
그런 스트림 데이터 가 쫙 들어와요 순식간에 들어오게 되면 얘네들은 어떻게되냐면 그데이털르 가져다 잘게 쪼갭니다. 잘게 쪼개서
태스크 별로 쪼개서 
조개서 그래서 인메모리 프로세싱을 하는데 컨커런트하게 인메모리 프로세싱을 막 해버립니다 
그래고 나온 데이터를 갖다가 잘게 잘게 쪼갠 사실 이게 이렇게 보니까 뭐 시퀀셜한 처리같지만요 시퀀셜한 처리가 아니다 이 들어온 데이터를 갔다가 어느정도 보푸링해가지고? 잘게 쪼개서 얘네들 각각은 동시처리 해버린다 그렇기 떄문에 순식간에 들어오는 그런 데이터 가 스트링이 리얼타임 프로세싱이 거의 리얼 타임 프로세싱 데이터 가 처리가능하다.

그래서 그런 실질적인 배치작업이 마이크로 배치라고 하는데 마이크로 배치에요 사실은 이자체 하나하나 자체가 배치작업이다 
리얼타임프로세싱 잘한거 아니에요?? 사실은 그런데 잘게 쪼개서 자잘한 마이크로 배치작업을 동시에 실행시켜서 나중에 그 데이터를 가져다 합쳐버린다 그런식으로 해서 스트림 데이터를 처리를 한다.

## 스파므 mlib & graphx
제공을 하고 api를 제공하는데 실질적으로 이게 스파크같은경우는 단거보다도 실제 머신러닝을 하게되면 성능향상 굉장하다. 실질적으로 제일 많이 쓰는게 아닐까
하둡의 맵 리듀스 같은 경우는 언털액티브 한 그런 작업 스테이지를 계속해서 도는 작업은 안맞음 얘네들은 인메모리 프로세싱을 하기떄문에 몇바퀴 돌고 자시고도 필요없을 뿐더러 얘들은 맵 리듀스 무조건 정해서 너는 맵도 하고 리듀스도 해야되지만 얘네들은 맵 리듀스 라는게 없다 따라도 되지만 안따른다고 해서 상관없다.
아까전에 트랜스포메이션이나 그런 실제 데이터 액션ㅇ을 보면 맵리듀스가 나눠져 있지않다 필터링하면 필터링하는거고 세이브 하면 세이브하는거고 컬렉트하면 컬렉트하는거고 하나의 그런 데이터 그 트랜스포메이션에 오퍼레이션이 나눠져있다. 그렇기 떄문에 얘네들은 인터랙티브 한 작업 각각 여러개의 스테이지 나눠가지고 몇번이고 계속 도는 그런 머신러닝 흔히 얘기하는 딥러닝에 잘맞는데 왜냐하면 계속 반복되는 작업을 수행 그런 반복적인 데이터를 갖다가 캐시를 넣놓고서 얘네들이 rdd를 께속해서 만들어 다 쓰다 싶이 보내면된다.
그래서 얘네들은 실질적으로 그런모델이 잘맞느다. 자랑하듯이 up to 100
당당하게 100 써놓은 이유가 여기에 괴장히 잘맞는다.

바꿔 얘기하면 하둡의 맵 리듀스를 많이 깝니다.

그래프x는 페이지 랭커 라든지 nosql 잠시말씀드렸던 그런 그래 프  데이터를 처리하기위한 그런 api를 이런식으로 그래프x 라이브러리 통해서 api 제공 그걸 이용해서 코딩한다.

## 아오..

최소한 저기에 있는 애끼를 이번학기에 들어보셨다.
다뤄드렸다.