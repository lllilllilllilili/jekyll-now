---
post : layout
title : 컴퓨터구조(기)8
---
## Review : Major Components of a Computer
메모리 시스템을 살펴본다.
메모리 시스템 보기전에 기본적으로 우리 현재상황하고있는 환경을 돌아봐야 한다.
반도체 집적도에 기술발전으로 인해서 뒤에 보면 잠깐 나왔지만, 전에도 나왔지만 거의 18개월 마다 집적도가 2배로 향상됬다.
무어의 법칙이라고한다.
그집적도 향상을 프로세서 쪽은 어떻게 활용했냐면, cpu 클락스피드를 높이고 
cpu 안에 기능을 많이 집어넣는쪽으로 그렇게 활용함
메모리쪽은 용량을 높히는 쪽으로 활용함
용량을 높히는 대신 메모리 accesstime, 접근시간을 그렇게 크게 향상되지 않았다.
20년 전에 비해서라도
결과적으로 프로세스는 굉장히 빨라지고 메모리는 굉장히 대용량으로감
어떤일이 발생?
다 각각을 놓고보면 좋은 선택일 수있는데
두개의 같이 결합해놓고 봤떠니 약간의 미스매치가 일어남

프로세스는 엄청나게 빠른데 메모리는 프로세스의 성능에 비해서 속도가 잘 못따라가니까 무슨일이 일어나나면
용량은 크지만, cpu에서 메모리한번 왔다갔다 시간이 굉장히 오래걸림 매번 메모리 access를 해야됨
메모리에서 명령어 가지고 와야함, 명령어에서 load store는 항상 메모리에 읽어오고 메모리 써야하는식으로 메모리에 access 하는 시간이 굉장히 많은데
그 gap이 너무 커서 결론적으로 이 프로세서에 속도를 제대로 활용하지 못한다.
그래서 그것을 어떻게하면 조금 완화 시킬 수있을까?
사람이 고안해낸게 메모리가 있으면 프로세스가 있으면 그 사이에 메모리보다 조금더 빠른 메모리를 설계해넣을수없을까 그러나 용량은 작고 메모리보다 훨씬 빠른 그것을 설치하면, 메모리에서 데이터를 가지고오면 그것을 한번쓰고 버리지 않고 그 데이터를 거기다 보관한다. 가만히 프로그램을보면 한번 갖다 쓴 데이터를 재활용하는 경우가 많다. 대표적으로 우리 c 프로그램으로 for loop을 쓴다. 그것을 생각해보면 i=0 ~ i<=1000 i++ 시키면서 그다음에 주로 그안에서 배열의 데이터를 하나씩 읽어다가 총합을 구한다그러면 sum에다ai를 갖다 더하는 구조를 생각해보자 
계속 for 룹이 반복될텐데 반복될때마다 i라는 변수를 읽어옴 또 sum이라는 변수를 계속읽어옴 메모리에서 한번 읽어온것을 바로 버리기에는 아까우니까 중간 계층에다가 잠깐 카피를 해둔다. 또 어떤 용도냐?? ai 를 읽어 배열인듯? 변수, for 룹에서 a0 a1 a2 읽어간다 그런데 a0를 딹읽어갈때 생각이 어디에 미치냐면 조금 있으면 a1 a2 도 읽어갈거야 프로그램들이 한번읽기시작하면 거기서 얼마만큼은 계속해서 읽는 경향을 보인다
그러면 아예 a0을 올려보내면서 뒤따라서 a1 a2 a3을 계속 퍼올린다 위로 방금애기했던 그 프로세스 가까운 쪽에 메모리에다가 미리 가져다 둔다. 그러면 어떻게 되? 그다음에 정말로 a2를 cpu가 원하면 그러면, 메모리에서 그것을 가지고오지 않고 메모리에서 미리 가져다준 메모리에서 읽어갈 수있다. 그런 경우에 그 프로세스와 메인 메모리 사이에 위치하는 그런 소규모 아주 빠른 소용량 메모리를 뭐라하냐면 캐시라고한다.
캐시메모리라고도 한다.
그런데 캐시메모리가 하이어리커

## A Typical Memory Hierarchy
계층이란 말이다. 몇단계 계층, 그 캐시메모리가 컴퓨터시스템 전체를 보면 캐시의 역할이 한곳에 존재하는것도 아니고 전체 프로세스로부터 저말단에 이르는 큰 시스템을 보면 각각의 계층들이 있고 계층사이 에서 사이에서 그 아래에있는 데이터를 위에다 올려놓고 또 그 아래에있는ㄷ ㅔ이터를 위에다 올려놓고 이런일들이 계속해서 반복적으로 활용되고 있다. 그것을 우리가 그것을 메모리 계층을 활용한다 라고 말한다.

배경은 그렇고
프로세스 상당한 시간을 들였고 싱글 사이클 멀티사이클 파이플라이닝 그렇다.
그다음에 메모리 장치에 대해서 해볼려고 하는데 메모리 
사실 메인 메모리가 주인데, 메인 메모리를 조금 개선하기 위해서 캐시라고 두었고 또 메인메모리를 뒤에서 메인메로리는 우리가 보존 하기위해서는 비휘발성 메모리가 필요하다.
디스크라든지, 요즘에 ssd 라든지 플래시 메모리 기반이 메인메모리 뒤에서 떠받이고 있는다.
이게 보면계층이잔아 우리가 이것을 secondary memory 라고 하는데 secondary 라는건 두번째 라는 의미임
이런 계층 구조 얘기하고있음

우리가 조금더 보면 방금얘기했던 세컨더리, 메인 여기에 여기서부터 캐시인데 (어디?) 지난번에도 말했다싶이 여기서부터 하나의 마이크로프로세스 칩이면 칩에 집적도 , 집적도 술이 굉장히 발달하면서 여기안에다가 집어넣을 수있는 그 회로 회로의 복잡도, 양이 많아짐 바꿔말하면, 예전에는 프로세스 하나를 간단한 프로세스 하나를 설계해두면 이만한 공간이 다필요했다. 뭐에 비유했지,? 쌀에다가 붓으로 새겨넣는 그예를 들었는데 기술이 덜 발달했을때는 그 가늘기가 굉장히 굵어서 쌀알에다가 4글자 쓰면 끝이엇음
최근에는 그 가늘기가 어느정도냐 여기다가 책을 심어 넣을 수 있을정도에 선폭으로 반도체가 늘어났음. 예전에는 요만큼 필요했던 로직이 지금은 이정도만 필요하면 그 로직들을 다 설계해서 넣을 수있다. 그러니까 나머지 공간이 남는다. 거기에 대부분 공간이 남음 사람이 별걸 다 집어넣는다. 프로세스 넣자 2개 더 넣자 16개 더 넣자. 메모리도 넣자
여기에서도 캐시를 만들어내는 기술, 칩안에서도 
칩안에도 캐시라는게 존재하는데
명령어 만 따로 들어갈 수있는 캐시 또 데이터만 따로 들어갈 수있는 캐시 캐시 구분하기도 하고 어쨋든 이와같은 캐시를 칩안에 캐시를 온-칩 케시라고 하고 그리고 마이크로 프로세스 칩밖에 있는 칩을 우리가 오프칩 캐시 라고 한다.

오프 칩 캐시라고 하고 메모리를 레벨을 매기는데 프로세스 가까운 쪽부터 레벨 1 L1 캐시 그다음에 L2 캐시 
이사이에 캐시 하나 더 넣을수있어 L3 캐시 그리고 메인 메모리
이렇게 레벨을 매기기도 한다.

스피드, 데이터를 읽고쓰고 하는데 걸리는 시간 사실은 메모리에 정점에 있는것은 뭐냐 캐시보다 더 빠르고 소용량 인것은 레지스터임 레지스터가 메모리에 정점에 있고 여기서 대부분 의 읽고쓰고 연산이 일어난다. 그래서 속도를 보면은 나노세크로 보면 레지스터에 읽고쓰는것은 1나노 
그다음에 어 온칩 캐시는 똑같은 1나노 라고 되어있지만 2~3나노 레지스터보다는 조금더 걸림 
그다음에 여기 칩 밖에 있는 오프칩 캐시는 10나노 정도
1나노가 10의 -9승 초임
그다음에 메인메모리로 가면 바뀐다. 100나노 정도된다.
그다음에 디스크로 가면 또 10배임
그래서 가만보면 우리가 1기가 Hz로 동작하는 마이크로 프로세스다 그러면 똑딱할때 명령어 하나 처리하는 1기가 Hz
1기가 Hz이 똑딱 한 사이클이 1ns 임 
그런데 명령어, 캐시가 없다고 생각해보자
자, 매번 항상 명령어를 패치하지 명령어 패치는 어디서 읽어오는거야, 메모리에 읽어온다. 얼마걸리냐? 100나노 걸린다. 주소보내고 여기서 데이터 읽어내서 데이터 여기까지 돌아오고 사실은 더 걸림 이 100 나노라는건 얘한테 주소 전달되고 그 주소를 받아서 이안에서 밖으로 꺼내주는데 걸리는 시간이어서 사실은 100나노 플러스 알파야 그런데 이거 그냥 우리가 일단 무시하고 이시간만 봤을때 100나노 이것만 보면
그건 무슨말이냐면, 명령어 패치 보내고 나서 여기서 똑딱똑딱똑딱 해서 100개가 지나가야 그재서야 저쪽에서 온다. 이거 아무리 빨리 만들어도 뭐해 한번씩 오는데 100개의 사이클이 지나가야 하는데 
그래서 이렇게 읽어오면 여기다가 둔다. 여기다가 읽어온것을 아까 얘기하면 i, sum 에다가 복사본을 둔다. 
이 캐시에다가 
그래서 처음에는 i를 여기에서 가지고 오지만 그다음에 i는 어디서 가지고오냐? 여기서 가지고 온다. 그다음에 여기서 어 10 ns 면 가지고 온다. 더 적극적으로 캐싱을 하면 i를 어디다 가져다 놔?
여기다가 가져다 둔다 온칩에다가 그러면은 3나노면 가지고 온다. 100나노 걸려서 가지고왔던것을
그런데 문제는 뭐냐면 이 쪽으로 올수록 메모리 한 비트를 만들어넣는데 차지하는 집적 공간 말하자면 회로 사이즈가 커다. 이쪽으로 올수록 그리고 한 비트의 소요되는 비용이 비싸다. 그러니까 여기는 용량이 작을수밖에 없다. 프로세스 가까이 올수록 용량을 작게만들수밖에 없다 그대신에 빠르지만 용량은 작아.
그리고 비싸다.
그게 이제 우리 엔지니어링 할때 어떻게 타협할껏인지 용량을 어느정도로 타협을 할것인가 그거에 디자인 포인트가 된다.
그래서 우리가 용량을 보면 기껏해야 레지스터의 개수는 32개에서 많아봐야 100 개 이내 그다음에 여기는 킬로바이트 수 
여기는 뭐 수십 내지 여기는 오프칩 캐시도 메가바이트 수준으로 굉장히 많이 늘었다 용량이 그다음에 여기서 메인 메모리도 메가가 아니라 뭐야, 기가 바이트 수준으로 늘어났다. 거기에 거의 테라로 가고
이 뒤에 잠깐 나온다. 메인 메모리를 구성하는 소자는 뭐냐면 디램이다.

## Memory Hierarchy Technologies
DRAM : 랜덤 엑세스 메모리이다. 디램 
캐시를 구성하는 소자는 뭐냐면 SRAM 임 
SRAM : Static Random Access Memory

스태틱은 상태를 안정적으로 유지한다 에 있고
다이나믹은 실질적으로 상태가 우리가 전기전자적인 상태가 조금씩 변한다. 변하는 이유는 잇다 보겠지만 그 상태를 항상 회로에서 보상을 해줘야한다. 그게 바로 디램의 특징임
잠깐 한번 읽어보자.

랜덤엑세스 메모리가 뭐인거같냐 전체적인 것에서 내가 읽고 싶은 위치를 바로 가서 읽어오는게 랜덤 엑세스임 임의의 위치를 바로 엑세스 할 수있는것
메모리 랜덤엑세스임
어 하드 디스크 랜덤 엑세스 의 준말이다.
사실은
근데 완전한 랜덤 엑세스는 아니다.
왜 완전한 랜덤 엑세스 가 아닌 예로 뭐를 들 수있냐면 
요즘은 잘 안쓰는데 비디오 태이프 봤어? 비디오 테이프, 비디오 테이프 녹화를 해뒀는데 어디에 생일 파티한것을 찾아아해
그 어떻게 찾지? 그 위치 바로 못가
쭉 읽으면서 어느 위치에서 아 여기에서 여기 구간 여기 구간 그때그때 데이터를 확인하면서 끝까지 가야한다.
이런 매치 이런것은 랜덤 액세스 가 아님
이런것은 순차적으로 접근하는 것임 태이프 대표적으로 태이프가 순차적으로함
어떤곳으로 갈려면 꼭 중간 거쳐서 가야된다.
랜덤 액세스 는 중간에 거치지 않고 자기가 원하는 곳을 바로 접근할 수있는 매체임 이게 랜덤액세스임

dram : 굉장히 고용량이고 파워를 적게 소모하고 비교적인 싼 가격에 비해서 느리다. 어느정도냐 어 약 100ns 정도 빠른건 정도는 50ns도있지만 100ns 정도 

sram : 어 집적도 측면에서 좋지 않다. 디램에 비해서 왜냐하면디램은 트랜지스터 한개로 한 비트를 만들수있다. 트랜지스터 배웠지 전자에서 사실은 트랜지스터 한 셋  + 뭐가 필요하냐면 
그 커페스터=축전지 
전하를 담아놓을수있는 커페스터가 필요하다 셀 하나 하고 근데 sram은 한 비트를 받을려면 트랜지스터 6개가 필요하다.
그대신에 얘는 6개로 안정적인 상태를 유지하는데 반해서 얘는 한 트랜지스터 + 커페스터 가지고 한 비트구성하는데 커페스터 담겨있는 전하의 양이 정보다 이게 풀 charge 되어있으면 1이고 charge가 안되어있으면 0임 근데 생각을 해보면은 이거 완전 쉴드가 없잔아 그러니까 이게 충전을 해뒀어도 시간이 지나면 전하가 새나간다. 옆으로 이렇게 조금씩 조금씩 지나면 처음에는 1을 만들어놨는데 시간이 지나면 어떤 비트가 0이 되어버린다.
그래서 상태가 변한다. 그래서 그거를 보상해주는 방법이 있어야 한다. 그래서 주기적으로 그안에 상태를 읽어내서 다시 써줘야 한다. 1이면 1로 0이면 0으로 다시써주는 작업을 뭐라고 하냐면 어 refreshed 라고 한다. 
대력 얼마에 한번씩 4ms 한번씩 정기적으로 그 내용을 다시 써준다.  그러니까 디램이 왜 느릴수밖에 없느냐 두가지 요소가 있는데 뒤에서 이제 보겠지만 sense 하는데 오래걸린다. 
cell을 어떻게 sense 하냐, 여기 축전지에 들어있는 값을 아주 미세한 전하값을 읽어내야 그래서 이제 그 1이냐 0이냐 판단하는데 그게 어느정도로 민감하느냐 
그냥 우리가 복도가 있으면 저끝에 내가 서있고 이쪽끝에서 어떤 사람이 커피를 마시고 있다고 하고 있고 저쪽에서 저사람이 무슨 커피를 마시고 있나 그게 향이 나한테 무슨 헤이즐럿이구나 알수있는 정도로 그정도로 아주 미세하게 전달되고 정보가 
그리고 그정도로 오래걸림 
sense하는데 그러니까 sense 하는데 오래걸리고 일단 탐지하는데 오래걸리고 뭐가또 상위 나간걸 refresh 해야 하기 때문에 refresh 타임이 있고 access 타임이 들어간다. 
그러기 때문에 느릴수밖에 없다.
그래서 뭐와 뭐 사이에서 디자인들이 선택한거냐면 용량을 아주 혁신적으로 그 고용량을 만들기 위해서 트랜지스터와 커페스터 방법을 썻다. 근데 그게 속도의 한계를 가지고옴 결국은 뭘 버렸어 속도를 버렸어 이미 
sram, 전 원이 들어와있는동안은 안정적으로 값을 조절한다 다만 집적도는 6배임 디램에 비해서 같은 식 안에 얘가 6비트 심어넣을공간에 얘는 // 정정
한비트 심어 넣을 공간에 얘는 6비트 심어넣을수있다.
거의 뭐 6:1 보다는 조금더 완화 되는데 여기는 사이즈 퍼스트
여기가 이제 volatile이고 
nonvolatile은 fresh 메모리 같은것들 
우리가 eeprom 했는데 
electrocally 전기적으로 e는 erasable 지울수있는 그다음에 p는 programmeble rom임 rom은 read only memory 임 
programming rom 임 사실
결국은 우리가 이제 그냥rom은 그냥 rom은 시스템이 처음에 동작해서 생성할때 어떤 값이 거기에 기록이 되고 그거는 바꿀수가 없다 일반적으로 
이 eeprom은 중간중간에 갱신할수있다. 프로그래밍에 의해서 완전히 소거하고 새로운 데이터로
물론 이제 시간은 훨씬 오래걸린다 dram이나 sram에 비한

그다음에 여기에는 이제 ramdom에 가까운 완전한 ramdom이라 보기 어렵고 random에 가까운 그런 기술들 
disk 가 왜 random이 아니냐면 여러분들 디스크 전에 그림본적있을텐데 디스크는 기본적으로 무엇으로 구성되어있어?
원판으로 구성되어있다. 원판안에 수많은 동심원들이 있고 거기에 데이터가 기록되어있다 그러니까 어떻게 되어있냐면 
원판을 잇는 어떤 우리가 보통그것을 arm이라고 하는데 arm 끝에 데이터를 읽는 패드가 이렇게 달려있다.그래서 
데이터를 읽을때 이 arm을 움직여 가지고 내가 원하는 동심원 위로 가져다 두고 원판은 돌아가고 거기서 데이터를 읽는다. 그러니까 완전한 랜덤은 아니다. 어느정도 순차성이 있다.
그래서 이것은 순차성이 있다는 말은 어떤 특징이 있냐, 읽는 로케이션에 따라서 access time이 달라진다 아주 운좋을 경우에는 걔가 있는 위치에 데이터를 읽으면 
아주 재수없는 경우에는 그 제일멀리 움직인 다음에 데이터를 일겅야한다. 그래서 location 마다 access time이 다르다.

캐시는 멀 써여? sram을 쓴다. 
메인 메모리는 dram을 쓴다.
그뒤에 얘기했지만 dram 을 access 하는 과정을 보면 우리가 그 보면 address 가 한번에 32bit가 갔었다 
cpu에서 32bit address가 가면 데이터 32bit가 나왔는데 사실은 내부적으로는 이 address를 받으면 address를 해석해야 할거아니야 그렇다. address 해석해서 거기에 해당되는 데이터를 꺼내야하는데 그 일종에 뭐냐면 일종에 mux임 그게 
mux가 뭔지 알지 input을 받아가지고 그 INPUT에 해당되는 값 하나를 선택하는 것이 mux인데 dram도일종에 mux임
이거를 address를 디코딩할떄 2단계로 나눠서 32bit 면 상위 16비트 가지고 먼저 한 줄을 선택을 하고 그다음에 하위 16비트 가지고 그중에 일부를 선택한다. 그렇게 해서 한 워드 를 선택하도록 한다 그렇게 설계되어있다. 
그 왜그랬을까 32비트를 그냥 한번에 해석해서 데이터를 선택하지 않고 왜 둘둘로 나눴을까 그전에 그와 유사한 얘기를 한적있었는데 mux가 input이 n개라고 하면 그러면 그 n개의 input을 받는 mux 회로의 복잡도는 input에 몇배? 제곱 배에 해당된다. 
input의 제곱배야 그래서 그것을 어떻게 표기를 하냐면 어차피 하나를 선택하면되니까 n개의 인풋이 들어오면 상위의 n/2 개 가지고 일부를 선택한다음에 그다음에 하위에 n/2 가지고 그중에서 일부를 선택하도록 그렇게 바꾸면 회로가 반으로 준다. 
이게 n개의 인풋을 갖는 mux야 이걸 회로 복잡도 얼마라고 n^2 이걸 어떻게? 처음에 상위에 있는 n/2개 가지고 그다음에 일부를 선택해 그다음에 하위의 에있는 n/2개 가지고 그중에서 나온 데이터의 일부를 선택해 똑같아 반가지고 먼저 선택하고 나머지 반가지고 선택하고 결과는 그런데 여기는 n^2이고 여기는 (n/2)^2 = n^2/4
n^2/4 + n^2/4 더하면 n^2/2 이다. 그렇다. 그래서 우리 그 앞에 싱글 사이클 데이터 패스를 보면 이 원리를 이용해서 둘로 분리된 부분이 있었는데 뭐였지?
컨트롤 이었다. 컨트롤이 전체 다 거기서 컨트롤 해도 되는데 뭐를 분리했어? op code를 따로 분리해서 alu op를 따로 만들었다. 그 alu op를 구지 따로 만들이유가 없어. 한 컨트롤 안에서 다 해도되  이렇게 하면 회로복잡도가 커지니까 그래서 function code를 처리하는 control logic을 alu contol이라고 해서 아래쪽에 따로 만들었다. 기억나지
마찬가지다. 첫 단계를 뭐라고 하냐면 row access strobe ras라고 하고 행을 선택하는 부분임 그 선택된 행중에서 일부를 선택하는것을 column access strobe 라고 하고 cas 라고 한다
dram은 access할때 ras cas 두단계로 이루어진다.
우리가 메모리 access를 메모리 퍼포먼스, 성능을 측정할때 주요한 그 metric , 측정기준이 있는데 
latency야 latency는 그 칩에서 한워드를 읽고쓰는데 걸리는 시간이다. 
그래서 latency는 크게 두 요소로 latency, 지연시간 부를수있는데 두요소로 구분되는데 하나는 access time  
처음에 요청이 들어간 시간부터 해당되는 word가 읽혀지거나 쓰여질떄까지 사이 시간 그게 access time 
그런데 문제는 그러면 request가 들어가고 뭐가 나오고 그다음에 바로 request가 들어갈 수 있느냐? 그렇지 않다. 왜 안그렇냐면 아까도 말했듯이 dram 같은 경우는 그 사이사이에 뭐가 refresh도 발생해야 되고 부대적인 처리가 일어나기때문에 바로 모든 request를 연속해서 받을 수가 없다.
그래서 우리가 사이클 타임이라는 개념이라는것을 두는데 연속적으로 리퀘스트들이 들어갈 수있는 그 인터벌, 한 리퀘스트와 다음 리퀘스트 간에 간격 그것을 우리가 한 사이클이라고 한다. 사이클이 훨씬더크다. 엑세스타임보다 
엑세스타임은 사이클 타임의 일부이다.
자 이거는 읽어내는데 걸리는 시간이고 그다음에칩에서 이렇게 읽어나오면 그다음에 뭐를 타고 cpu로 가? 버스를 타고 간다. 
버스를 타고 갈때 버스가 몇비트냐? 버스가 얼마나 빨리 동작하느냐 가 또 주요한 성능요소다 우리가 그것을 뭐라 그러냐면 밴드위쓰 
우리말로는 대역폭, 또는 트랜스포레이트=전송률 
밴드위쓰 또는 데이터 트랜스포 레이트? 
단위 시간당 여기 어떤 단위시간당 1초동안 얼마나 많은 데이터가 그 버스에서 전송될수있는가? 주로 우리가 이제 레이턴시는 뭐에 중요한 요소가되냐? 실시간성 , 예를들어서 우리가 인터넷으로 서로 전화 화상통화 이런것도 하는데 그떄 레이턴시가 너무 느리면 서로 상호작용하는 실시간성이 떨어진다. 여기서 아 했는데 1초뒤에 저기서 아 
여러분들 옛날에는 국제전화 한번걸려오면 20년전만 하더라도 미국선 전화할려면 내가 물으면 1초 그뒤에 상대방이 대화를 해가지고 굉장히 서로 어색했다. 그런거에 영향을 미친다. 서로 실시간성 상호작용 밴드위쓰는 뭐에 영향을 미쳐? 그 데이터량 
예를들면 어 아주 대역폭이 작아, 그런데 레이턴시는 짧아 그러면 음성은 서비스를 할수있어 그런데 
대역폭이 작으면 화상통화는 서비스 할 수없다. 데이터량이 많으니까

## Static RAM(SRAM)
여러분 이런거 봣죠? 이게 이제 트랜지스터 여기 인버터 인데 트랜지스터 2개로 구성됬어 이 인버터가 전체로 한 
한 메슬?? 에 한 비트가 트랜지스터 6개로 구성되어있다. 
자 어떤 여기가 가로축이 워드 라인이라고 그러고 세로축이 있는 요 한 비트로 들어오는 요 것은 비트라인이라고 하는데 우리가 여기다 어떤 정보를 읽을떄 어떻게하냐 이 워드라인을 인에이블 시켜서 
워드라인에 스위치를 이렇게 닫아준다. 그러면 여기에있던 값이 여기에 비트라인으로 나오는거다. 그게 읽을때야

쓸때는 반대다. 쓸때는 워드라인 을 선택하는건 똑같고 쓰는거는 밖에서 값이 들어오는것이다. 밖에서 값이 간학게 드라이브 되면??? 여기에 있는 상태를 바꾼다. 
만약에 1이 들어왔다 그러면 1이 들어와서 1 
1 그다음에 여기 0 그다음에 1 
그래서 여기가 1 상태가 유지가 된다. 이렇게해서 

## Classical SRAM Organiztion

자 sram은 두단계를 거치지않고 원 패스로 
여기에 address가 나오고 
얘도 뭐 두단계임 

row address 일부가 들어가서 어 워드를 선택하고 그럼 워드가 선택되면 거기에 해당 되는 값이 쭈욱 선택되는 값이 밖으로 나옴 
그러면 그 밖으로 나온걸 여기에 buffer에다가 담는다. 

버퍼에 담은 다음에 하위에 있는 column address 
아까 얘기한 32bit 중에서 상위의 16비트는 이 행은 선택하는데 쓰이고 하위의 16비트는 여기에 준비되어있다가 여기서 쭉 나오면 하위 16비트에 의해서 나오는 비트 중에서 일부를 선택하면된다.
그렇게 쓰인다. 여기 여기 두단계인데 

지금 어 짧은거 같은데
지금 여기 같은 경우는 자 row가 몇이에요? row가 8줄이다.
8줄 중에서 하나를 선택해야 하니까 여기 rwo 에는 몇개의 line이 들어갈까? 3개의 line 이 들어간다 0~7까지 구분할 수있는 수면된다. 
현재 요 그림상으로 볼때는 
그다음에 여기에 나온게 8비트인데 8비트 중에서 왼쪽에 있는 4비트 오른쪽 4비트 둘중 하나를 선택한다. 
그러면 여기 column 을 선택하는 정도는 몇 비트면 될까? 
왼쪽 선택 할꺼냐 오른쪽 선택할꺼냐 ? 1비트 이면 된다. 
그래서 지금 4비트 어드레스 중에서 3비트는 rwo 를 선택하는데 쓰였고 한 비트는 이 예를 보면 한 비트는 column을 선택하는데 쓰였다. 
이거는 뭐 지금 결국은 4비트가 한 워드라고 하면 4비트 가 한워드라고 하면 전체 워드 가 몇개있어? 이 안에
한 줄에 2워드 있는 셈이잔아 
그게 8줄 있으니까 전체 16 워드가 있는 셈이다.
16 워드 중에 한 워드를 선택을 할려면 
우리가 어드레스 라인은 4라인이 있어야됨 
2 의 4승이 16이니까 
4 라인을 가지고 서 쓰는것이다.

만약에 워드가 2비트 워드다. 극단적으로
한 워드가 두비트로 구성되어있어 그러면 어떻게 구성되야 할까? 여기에서 2비트를 선택해서 내려보내야 하니까 어떻게?
한 row에 두비트 짜리가 몇개 나오냐? 4개 나온다 
4개중에 하나를 선택해야 하니까 여기에 2라인이 들어가야 된다.
4개중에서 하나를 선택해야 하니까 
//워드의 개수가 4니까 어드레스 라인이 2비트 여야 한다. (생각)


그리고 여기엔 아깐 똑같이 8줄중에서 한줄이니까 3줄이 들어가야 된다. 그러면은 이 어드레스 라인의 수하고 뭐 하고 일치해야 하냐? 안에 들어가있는 워드의 개수하고 일치해야한다. 워드의개수가 32개면 어드레스 라인이 5비트여야 하고 그 5비트가 row에 어떻게 쓰일지 column에 어떻게 쓰일지 그때 그떄 선택하는 워드 사이즈에 따라서 결정이 된다. 


//정리 한 워드가 예를 들어서 2비트로 구성되면 한 줄은 8개로 구성되는 거니까 2비트짜리가 4개 있는 셈이 된다. 4워드로 구성이 되고 4워드가 구성이되면 하나를 뽑는데 2라인만 있으면 된다. 
//궁금한것 : 8줄 중에서 하나를 선택해야 하니까 여기 row에는 몇개의 line이 들어갈까? 3개의 라인이 들어간다. 0~7까지 구분되면 된다. 그리고 
4비트가 한 워드라고 하면 이 안에 한줄에 2워드가 있는셈 (그리고 이후 *8 8줄이 있으니까 전체 16워드가 되는것)
이것이 시뮬레이션 그림상에 어떤 부분을 의미하는건지 잘 이해가 되지 않는다.(내생각)

자 이게 dram인데

## Dynamic RAM(DRAM)
DRAM은 아주 단순하다. 트랜지스터가 그다음 이게 뭐야 컴페스티(충전지) 여기에 워드라인이 드라이브 되어가지고 여기가 선택이 되면 여기있는 값이 읽혀져 나오거나 또는 반대로 여기서 write할때는 들어와서 여기에 전하를 채우도록 그렇게 되어있다.

## Classical DRAM Organiztion(~Square Planes)
이것은 어떻게 구성되어있는지 함봐라, 훨씬더 적극적으로 지금 어 어드레스 쓰고 있는데 여기서는 지금 이런 plane이 여러 plane 이 있고 지금 여기에 row address가 들어오면 이 row가 모든 plane에 다 적용되 그래서 모든 plane에 해당되는 row가 일단 다 선택이 된다. 그래서 쭉 나온다.
여기까지 
여기에 보통 column Selector에 이 나온값을 담는 buffer가 있다. 우리가 그것을 센싱 버퍼 라고 하는데 
일단 버퍼가 있어서 센싱이 되서 들어가면 이 시간이 걸린다. 내가 아까 저끝에 있는 커피향을 여기서 맡아야 되는 그 시간이 라고 했다. 여기서 이렇게 아주 미세하게 흘러나오는것을 센싱해서 여기다가 쓰는것이다. 이시간이 꽤 많이 걸린다. 그다음에 어떻게
여기에 컬럼 어드레스가 쫙 들어가가지고 모든 plane에 동시에 들어가서 들어온 bit 중에서 몇번 bit 그렇게 선택을 함 
그러면 한 plane에서는 한 bit가 선택되지만 이 plane을 만약에 32개로 만들어 넣었으면 몇 비트가 선택되는거야? 32bit가 선택되는것이다. 이렇게 해서 우리가 이 dram에 집적도를 효율적으로, 최적화하는 그런형태로 dram이 만들어지고 있다.

## Classical DRAM Operation
그래서 dram을 읽을때 방금 얘기한것 처럼 그러면 저 n개의 row 중에서 어떤 row를 읽을 것인가? row address를 띄어 사실은 32 bit address가 cpu에서 한꺼번에 오지만 그중에서 일부를 row address로 일부를 column address로 내부적으로 집어넣는다 그래서 row address를 집어넣는데 그때 아 지금부터 row address가 들어간다. 라는걸 어딘가 알려줘야 된다. 그걸 우리가 row address, row access strob ras라는 신호가 있는데 여기에 여러분들 위에다가 바를 하나 그어줄래
어 ras도 바를 하나 그어주고 cas도 바를 하나 그어주자
이 bar를 그어주는 이유는 뭔거같아? bar를 그어주는 이유
bar를 그어주는 이유는, 이 값이 활성화됬을때는 row 상태가 활성화 이라는것임 0일때가 
무슨 의미냐면, ras 가 0일떄 아 지금 부터 ras가 시작된다는것을 알리는것이다. 
cas가 이렇게 있다가 0일때 지금부터 cas가 시작된다. cas 단계가 시작된다는것을 알리는것이다.
그걸 우리가 이제 위에다가 바를 그려져서 표시를 한다 또는 뭐 경우에 따라서 어떤 경우에는 #을 쓰기도하는데 
회로마다
자그래서 row address를 넣고 나서 ras를 enable 시켜 그럼 아 지금부터 ras 단계가 시작됬다. address는 그 단계가 시작되기전부터 미리 들어가 있어야 되겠지? 그렇지? 어느정도 setup time이 필요하고 그다음에 어 데이터가 row 가 선택되서 나왔을거아니야 
그러면 cas를 다시 선택해서 column을 선택을해 그러면 요 정도 지나면 데이터가 나왔겠지 그렇지 그래서 나와서 이때 데이터를 읽어낸다. 
요만큼이 실제 데이터가 access 된 access time 임. 그런데 바로 그다음에 사이클을 시작할 수있으면 access time을 갖고 cycle time을 갖지만 일반적으로 이 사이에 다른 일들을 하게 되어있다. 특히 refresh를 하거나 뭐 다른 회로 조정을 하거나 그래서 바로 next request가 바로 시작되지 못한다. 
조금 있다가 다시 ras를 시작한다. 그래서 그다음 request 가 시작할때까지의 시간을 뭐라 그런다고? cycle time이라고 한다. 그렇지 그래서 이 시간이 거의 없다면 기술적으로 
cycle time와 access time이 거의 같지만 현실적으로 거의 불가능하다. cycle time이 길다. 여기에는 뭐가 대표적으로 포함되어있다? dram같은 경우 refresh 타임, 읽어내서 다시 쓰는 refresh 타임이 대표적으로 포함되어 있다.

## Synchronous RAMs
우리가 보통 어 싱그러너스 dram ?? 해봤는데 ? 
이걸 줄여서 sram이라고는 안한다
synchrouous ram이라 하고
이거 페이지 모드 디램 
어 싱크로너스 디램 
뭐 얘기하고 있는데 이거 자유 학습
각자 읽어보고 
어쨋든 

싱크로너스 램은 전송 능력을 갖는다. burst 데이터를 보낼 
같은 열안에 포함된 순차적인 주소의 연속으로부터 

스피드에서 이점이 있다. 완성된 주소를 제공할 필요가 없기 때문에 (row and column이)
같은 burst안에서 word를 위해서
1. page mode DRAMs - 명시해라 출발 (row) address 와 그리고 연속적인 column address
2. SDRAMs - 명시해라 출발 (row+column) address 그리고 burst length (number of words in the row= 열안에 있는 워드의수). burst 안에 있는 데이터 는 옮겨질것이다. 
clock signal의 컨트롤 아래에
DDR SDRAMs(Double Data Rate SDRAMs)
이동해라 burst data를 rising 그리고 clock의 falling edge 둘 다에다 (밴드위쓰랑 동일하거나 두배이상)

## (Fast) Page Mode DRAM Operation
열은 N*M SRAM buffer 안으로 읽는다.
1. 오직 cas 는 필요로 한다. 접근하기 위해서 다른 M-bit blocks row위에서 (row = burst size)
2. RAS는 계속 확고히 하고 있다. CAS가 변하는 동안 (변하지 않는다는 뜻인거 같은데.. (내생각))

## Synchronous DRAM(SDRAM) Operation
열 이후에 읽는다. SRAM 레지스터 안에서 
1. 넣어라 CAS는 출발 "burst"주소로서 
burst length를 따라서 
2. 이동해라 a burst of data를 순차적인 주소에 연속으로부터 열안에서 
2-1. clock controls를 이동해라 burst안에 연속적인 word의

## Technology Trends
우리가 지금 이제 특히 dram 같은 경우 
ras cas 이루어져서 access time이 이루어지는데 
row를 읽어내는 시간을 우리가 뭐라고 하냐면 row access time 또는 row access cycle 
그다음에 
cac 는 calumn access cycle 이건 카스 시간이다. 
이건 라스시간이고
뭐가 더 그 시간이 많이 걸리고 줄이기 힘든 시간일까? cas 와 ras 중에서 어? 뭐가 더 줄인시간일까? 
row access 하면 시간이 훨씬 오래걸리고 그것을 줄이기가 힘들다. 일단 와서 버퍼에 들어가면 버퍼에서 뭔가 잘라내는거 선택하는건 어려운일이 아니야 그래서 시간을 보면은 우리가 메모리가 이렇게 쭉 발전해오면서 카스 시간은 굉장히 급속하게 해서 거의 무시할정도의 시간 수준까지 떨어졌는데 ras 시간은 여전히 많이 안떨어지고 있음 ras 시간이 그만큼 메모리 기술에서 지금 허들,장애의 한 부분을 차지하고 있다는 것을 지금 보여주고 있고
여기에 그 어 시대별로, 시기별로 그 메모리 용량 단가 예전에는 말도 안됬다. 
80년에 64kb가 얼마였어요? 어 상상이 가냐 
물론 이게 64kb 가 64kbit가 150만불 이라는건 아니지만 더 단가로 1 gbyte 구성하면 150만불 이라는 의미임 15억 정도임
여러분이 지금 수십억 짜리 기계를 쓰고 있는것이다.  수십억 짜리임 예전에 같았으면 
아까도 얘기했지만 프로세서 에 그 clock과 dram에 access time의 간격이 점점 갈수록 크게 벌어지고 있는것이다. 시간 측면에서 
이걸 어떻게 매꿀 것인가 하는 문제인데 
잠깐 보충 자료로 넘어가자!
(보충 자료를 줄때부터 이건 쪽지 시험이 있다 라고 판단했어야 했는데 흑흑)

비어있는 부분을 보충자료로 보완해서 중복되는것도 있지만 보충자료로 보자.


# Computer Architecture (보충자료)
# Large and Fast : Exploiting(이용하다) Memory Hierarchy

## Datapath
메모리에 access할 부분이 이렇게 많이 나타난다라는거임
명령어 패치, 그다음에 데이터 엑세스 스토어 로드 
sram, dram 
sram과 dram의 조합으로 우리가 메모리 시스템을 구성해야 하는데 결국은 우리가 이것을 적절하게 계층적으로 잘 엮어가지고 어떤 효과를 발휘할려고 하냐면 용량으로 따지면 밑에 있는 dram이 가지고 있는 용량을 충분히 활용하면서 access time으로 따지면 상위에 있는 sram에 access time에 준하는 그런 토탈 시스템을 구현해볼려고 하는것이다.
욕심히 과하다. 용량은 dram의 용량을 확보하고 access time은 sram에 access time에 준하는 그런 기술을 만들어 볼려고 한다. 

그 무어의 법칙 

## Comparisons of Memory Technologies
x
## Processor Memory Latency Gap
다시한번 말하지만 1.5년 마다 성능이 더블업 된다는거 거의 
그런데 프로세스는 거의 이와 같은 형태로 퍼포먼스가 신장했고 
어, dram은 사실은 여기서 말하는 퍼포먼스는 access time loading이다. 용량이 아니고 access time 임 


요그림 잘 기억해두고,

## Soluition : Memory Hierarchy
그래서 그렇게 우리가 
계층화 해서 메모리를 여러 계층으로 나눠가지고 밑에는 느리지만 대용량
프로세스에 가까울수록 작지만 빠른 소용량이지만 빠른 그런 메모리로 계층을 둬서 cpu 입장에서는 저기 뭐야 일루젼이 뭐야! 
이게 마치 하나의 시스템인것 같은 그런 현상을 갖고 동작을 한다 
그런데 어 여기에서 용량은 아까 얘기 한대로 얘의 용량을 갖고 있으면서 스피드는 여기에 있는 얘의 스피드를 충분히 활용하는 그런 메모리 시스템을 추구하는 방향으로 기술이 진보하고 있다. 

그러면 어떻게 하느냐? 이게 굉장히 중요한 얘긴대(아아.. 중요하다니까 나와버렸어..하)
방금 얘기한대로 여러 계층을 둔다. 일단 여러 계층으 둔다.
그다음에, 계층간에 서로 캐싱을 활용한다. 우리가 캐싱이라고 하는게 아까 얘기했듯이 메인 메모리라고 해봐 여기에 지금 구분을 안하고 다 메모리라고 했는데 이게 다 메모리라고 생각할 수 있기때문에 다 메모리 라고 한거임 근데 하나 하나 따지면 얘 메인 메모리 소자는 dram 
얘는 뭐야, 세컨더리 메모리 소자는 뭐야 디스크 
얘는 뭐야 캐시 소자는 sram 그렇다. 앞에 장 보면 나와있음
얘도 캐시 역시 sram 에 준하는 집적 회로 
얘는 레지스터 그런데 이게 마치 토탈 솔루션으로 하나의 메모리인것처럼 동작하게 만들려고 하는거야 하나의 메모리 처럼 그런데 이 캐시는 누구와 누구 사이를 중재해주는 역할을 하냐? 메인 메모리와 이안에 있는 빠른 메모리 티스크 ep? 라는? 그래서 얘를 얘의 일부를 여기로 가져다 놓는다 그렇지 얘는 얘의 일부를 또 여기다 가져다 놓는다. 얘는 얘의 일부를 또 가져다 놓는다. 극단적으로 얘기하면 디스크의 데이터가 있잔아 디스크 데이터 중에서 많이 쓰는거는 어디다 가져다 놓냐? 시스템 프로그래밍에서 커널단에 버퍼 캐시라는게 있다라는 얘기 들었냐? 버퍼캐시가 뭐냐, 디스크에 있는 데이터를 다른 데이터의 일부를 여기 커널 메모리에다가 복사해놓는것이다 그게 버퍼캐시이다. 그래서 캐시라고 한다. 

메모리인데 캐시라고 부르는 이름을 그렇게 하위 레벨 에 있는 데이터의 일부를 상위 레벨로 복제하는것 그것을 우리가 다 캐싱이라고 한다. 다 캐싱이야

자 그런데 그것을 우리가 어떻게 더 적극적으로 활용하는가? 원리는 우선 어떤 한 순간에 보면 데이터가 두개의 어제이스트(adjacent) 레벨? 두개 인접한 레벨들 사이에서 특히 아래에 있는 lower 레벨에서 upper level로 데이터가 복제된다.
복제되는것을 적극적으로 활용하는 것이다.

버퍼 레벨 이라는것은 프로세스 에 가까운 쪽을 우리가 버퍼 레벨이라고 하고 얘의 특징은 용량은 작지만 acces time은 굉장히 빠른 비교적 간단하고 비싼 
lower level은 프로세스로부터 하나 멀리 떨어져있는건데 용량은 엄청 크지만 access time은 느리고 단가는 비교적 싼 그런 메모리 구성

그런데 어떻게 옮기느냐 ? 기본적으로 우리가 cpu에서 메모리 access 하는 기본 데이터 단위는 이제 까지 보면 보통 word 였음 한 word 
그런데 이제는 조금 다른 의미로 lower level에서 upper level로 upper level에서 더 upper level로 움직이는 단위가 word 가 아니고 word 보다 보통 더 큰 용량으로 움직인다. 기본단위로 그걸 뭐라고 하냐면 블락이라고 한다. block 

block이 뭐야, 두 레벨 들 사이에 전송되는 기본단위 이다. 
한 워드일 수 있지만 일반적으로 멀티풀 워드로 구성이된다. 
그래서 뭐 4워드 2의 지수승 또는 8워드 더 확대하면 16워드 
64바이트 잔아 
그렇게 대용량으로 벌크로 움직이게 된다. 
쉽게 얘기하면 이렇게 메모리 이렇게 제로 1 2 3 쭉 있잔아 그전에는 그냥 한워드라고 해 
프로세스가 한 워드 달라고 하면 저 워드만 읽어서 보냈잔아 그렇지 않고 이렇게 해서 옮기는 거야 위로 블락을 
이 블락을 뒤에도 얘기했지만 또는 블락 이라고 부르기도 하고 라인이라고 부르기도 한다.

라인이라고 부르기도 한다. 
그래서 이렇게 보면은 일단 내가 어떤 워드를 찾을때 upper level에서 먼저 찾아 그 워드가 있는지 사실은 그 워드가 있는지를 찾는게 아니라 그 워드가 소속된 block이 있는지를 찾는다.
그러면 block 이 있으면 lucky한거임 
재수가 좋은거임 그러면 거기서 내가 원하는 워드를 읽어간다.

없으면 block 이 없는거지 그 워드만 없는건 아니다
워드는 한 블락 단위로 움직이기 떄문에 
만약에 여기서 없으면 내가 찾는 블락이 없고 없으면 어디 
하나의 밑에 레이어 에서 그 블락을 찾아서 블락을 읽어다 여기다 가져다 물론 내가 궁극적으로 원하는건 그 블락안에 들어있는 어느 한 워드이다. 그렇다 기본적으로 연산은 워드 단위로 이루어지니까 하지만 레벨과 레벨 사이 에서는 블락 단위로 움직이다는 것이다.
(핵심)

3분 줄테니까 읽어보셈
## Why Hierarchy Works?
그러면 이와 같은 레벨과 레벨 사이에 블락으로 이렇게 복제본을 갖다놓고 하는 그와 같은 원리 그게 바로 합리적인 원리냐 ?
합리적이다 왜냐하면
우리가 사용하는 많은 프로그램이 뭐를 가지고 있냐면
로켈러티 우리말로는 지역성이라는 가지고 있는데
아까 우리가 처음에 배경설명할때 마찬가지다.
우리가 지역성이 두 타입의 지역성이 있는데 
하나는 temporal locality 시간적 지역성이 있고
어떤 아이템 어떤 데이터 라고 봐도 되고 어떤 베리어블 이라고 봐도 되고 어떤 데이터가 지금 사용됬으면 지금 참조됬으면 머지 않아서 곧 정말로 베리 순 곧 이어서 그 데이터 다시 쓸 가능성이 무지무지하게 높다. 대표로 내가 예를 든게 어떤거야? loop지 아까 여기보면 for i=어쩌구 저쩌구 sum은 어쩌구 저쩌구 이런것이다.
i는 변수 sum이라는 변수가 
내가 지금 한번 읽으면 조금 있으면 또 읽는거야 계속
이게 템포럴 로켈러티다.(시험문제였음)

spatial locality는 뭐냐 우리말로는 공간적인 지역성이라고 부른다. 어떤 데이터가 지금 참조됬으면 그러면 그 데이터 가까이에 있는놈 예를들면 지금 
A[0] 를 지금 참조했어? 그러면 조금 있으면 뭘 참조한단 얘기야? A[1] A[2] 이런것들을 곧이어서 참조한다는 거임
우리 프로그램 그렇게 짜는 경우가 많다. 그렇지?
그래서 어떻게 한단 얘기야 
어, 그래서 A[0]를 프로그램에서 access 하면 A[0]를 가지고 가는게 아니고 A[0]로부터 시작되는 일련의 이 덩어리를 블락 , 블락을 보내는것이다. 블락을 위로 보낸다. 
그리고 그렇게 따지면 데이터 뿐만아니라 명령어도 마찬가지다. 명령어도 우리가 명령어를 패치하면 사실은 한 명령어를 가지고 오는거임 그렇지 한 명령어를 가지고 오는건데 메모리에서 사실은 한 명령어 읽어서 프로세스 올릴때 걔로부터 시작된 한 블락을 읽어서 캐시에다 가져다 둔다 그러면 그뒤에 일부는 굉장히 빠르게 패칭을 하겠지 

인스터럭션 패치가 
그리고 그 특히 우리 프로그램은 자주 쓰는 놈에게 집중적으로 쓰는 그런 패턴을 보이고 있다. 그래서 전체 우리가 사용하는 주소 공간을 봤을때 일부 영역을 아주 집중적으로 사용한다. 그래서 저기 90% 라는게 전체 코드 나 전체데이터 중에 10퍼센트에 해당하는 여기 10%에 해당되는 정도를 전체 시간중에서 90%에 시간동안 얘들만 쓴다.
자 그래서 로켈리티 가 있기때문에 이것을 활용하기 위해서 메모리 계층적으로 만들고 기본적으로 기초적인 모든 데이터가 저장되어있고 그다음에 어떻게? 디스크에서 일단 메모리 DRAM으로 일부를 카피해 일부라는건 가장 최근에 access한 데이터 또는 지금 access하고 있는 놈의 근처에 있는 데이터 그래서 여러분들 우리가 물론 이게 음 아이오 장치 에 특징이기도 하지만 우리가 디스크를 무슨 디바이스라고하지? 블락 디바이스 라고한다. 블락 장치라고 한다. 키보드를 캐릭터 디바이스 라고 한다. 
블락 디바이스는 뭐야? 바이트 단위로 움직이는게아니고, 블락 블락으로 움직인다. 걔가 속해있는 한 블락 
한 블락의 크기가 뭐 2kbyte 또는 4kbyte로 블락 덩어리로 
그다음에 또 뭐야 dram에서 그 상위에 있는 sram으로 역시 마찬가지로 중요한건 뭐야, 카피가 존재해
그래서 카피로 얻어지면 이것을 우리가 이제 피라미드 형태로 밑에는 용량이 크고 위로 갈수록 용량은 작고 스피드는 빠르고 이런 피라미드를 보인다 이게 메모리의 하이어리커 이다. 
자 그래서 일단 극단적으로

## Levels of Memory Hierarchy 
극단적으로 생각하면 어떤것을 생각할 수있느냐
우리가 여기에 a라는 데이터가 있어 원래는 a라는 데이터가 최하위에 있었어
근데 읽으면 어디로가 이 a가 
상위로 간다. 상위에 
상위의 디스크로 가있다가 또읽으면 메모리로 가있다가 그다음에 또 읽으면 캐시로 간다. 
이렇게 원본은 어디에 있어? 원본은 아래에 있다. 원본은 아래에 있고 위에 있는 것들은 뭐야? 다 얘의 복사본들이다. 
중요한건 어느 복사본이 존재하면 그 로부터 위로는 복사본이 없을수도있지만 경우에 따라서 걔로부터 아래쪽에는 그 복사본의 해당되는 원본들이 다 존재해야 한다.
그게 아주 중요한 특징중의 하나다.

얘와 얘들 사이에 옮기는 거는 누가 컨트롤 하느냐? 주로 os가 컨트롤한다. 주로 피 드라이브나 디스크나 메모리 까지 ??? 하면 os 
그다음에 메모리에서 하드 디스크 저기 캐시로 옮기는건 주로 캐시 컨트롤러 과거는 하드웨어
여기는 프로그래머가 개입하지 않고 그리고 어떤 데이터를 레지스터에 가져다 놓는것은 누가 결정하느냐 주로 프로그래머 나 컴파일러가 결정한다. 우리가 예를 들어서 어떤 데이터를 r0 , r1 에다가 어사인하잔아 그렇지?

중요한건 요 cache에다가 데이터를 두는 동작은 캐시 컨트롤러, 하드웨어 에서 우리가 이걸 이제 트랜스 페어렌 오퍼레이션(Instr operands)이건가..? 해가지고 사용자가 여기다가 캐싱이 되는지 안되는지 알 수없음. 알 필요가 없다. 완전히 하드웨어에 의해서 동작한다. 그래서 예를들면 데이터가 이렇게 어떤 데이터가 이렇게 지나가잔아 그러면 여기서 보고 있다가 어! 이런 데이터가 지나가네 잡아가지고 여기다가 저장을 해둔다. 지나다니는것을 계속 보면서 

## Memory Hierarchy : Terminology
다시 한번 말하는데 그 level 과 level 사이에 카핑되는단위를 뭐라고 한다? 블락이라고 한다. 또는 여기 아카라고 써있는건 뭐에오? 
다른 말로 라인이라고 한다. 

싱글 모드 일수도 있지만 현대 컴퓨터 시스템에서는 멀티플 워드다. 2의 지수승 배수로 자 그래서 프로세스에서 어떤 워드를 엑세스 할려고 하면 잘봐바 어떤 워드를 엑세스 할려고 하면 일단은 자기 가까운 레벨에 메모리에 그 워드가 들어있는 뭐가 있는지 본다고? 블락이 있는지 본다. 그 워드를 포함하고 있는 블락이 있는가?
그래서 그 블락이 있으면 그것을 우리가 히트라고 한다. 
블락이 없으면 미스라고 한다.
여기서 히트가 되면 lucky임 그래서 거기서 해당되는 워드를 읽어가 만약에 찾아갔는데 블락이 없어 그러면 어떻게해? 내려가야대 
그다음에서 그 해당되는 워드를 포함하고 있는 블락을 찾아서 그거를 위로 가지고 와야해 가지고 와서 여기다가 놓고 블락을 카피해놓고 그중에서 프로세스가 원하는건 또 한 워드일꺼임 그 워드를 가지고 온다.
그래서 우리가 토탈 전체 엑세스 중에 예를들어서 cpu가 10만번 엑세스를 했는데 그중에서 9만번 히트했다. 그러면 얼마야 hit ratio가 0.9다. 그렇다. 그래서 hit ratio는 0과 1 사이의 값이다. 
퍼펙트하면 1이고 하지만 퍼펙트 할 수없다.
우리 그래서 우리 현대 컴퓨터 시스템에서 이 프로세스에 가까이 에 있는 이 레벨을 1캐시에서 one cache 에서 얼마만큼의 데이터 hit ratio 가 일어날까? 얼마만큼의 hit ratio 가 있을까? 가능할까? 현대 컴퓨터 시스템에서 
얼마 만큼 될거같아? 가까운 있는 캐시에서 히트할 확률이? 0.8? 0.9? 조금 더쓰면 0.95 무슨얙기야?
95 퍼 센트 정도는 거의 여기서 찾아낸다. 그러니까 아까 무슨얘기를 했냐면 우리가 메모리 계층 구조를 여러 단계로 관리하면서 용량은 누구의 용량을 활용해? 밑에있는 놈들이 제공하는 대용량을 활용하고 스피든느 누구의 스피드를 활욜하냐면 가까이에 있는 놈들을 활용한다고 했다. 여기에서 거의 95% 이상이 hit 되기때문에 실질적인 체감속도가 얘의 속도가 나는것이다. 얘의 가까이에 있는 놈들에 이해되죠? 무슨말인지? 
hit time 이라는건 이 upper level에서 해당되는 것을 찾는시간임 그래서 여기에 sram 을 access 하는시간 그다음에 그 데이터가 내가 찾는 데이터인지 아닌지 확인하는 시간 이게 hit time이다. 
miss는 데이터가 upper level에 없고 없으면 그걸 끝나는 게 아니라 lower 레벨에서 데이터를 가지고 와야 된다. 그렇죠? 
그래서 miss ratio는 당연히 1-hit ratio 고 요 사건 만큼 밑에서 가져와야 되는데 그 가져올때 드는 비용을 우리가 miss penalty 라고 한다. 미스 때 들어가면 어떤 비용이다. 
미스 패널티는 밑에서 그 프로세스로 업퍼레벨에 있는 데이터를 밑에서 읽어와서 블락을 업펄레벨에다가 리플레이스 어딘가에 위치시키는건데 여기다가 리플레이스 라는 말 밑줄. 

이게 왜 replace 냐 이 업퍼레벨의 용량은 lower 레벨의 용량에 비해서 훨씬 작다. 무슨얘기냐면, 여기에 작은 욜량을 이 밑에있는 대용량이 어떻게 share하는것임 공유하는것이다. 
그렇치, 또 어떤 예를 들수있을까 어, 그러다 보니까 여기는 항상 붐빈다. 왜냐하면 여기에서 많은 데이터들이 오고 가는데 걔들중에 일부들이 여기에 이렇게 막 카피가 되어있으니까 여기는 늘 붐비고 여기는 늘 꽉차 있다. 
여기는 뭔가는 꽉차있다. 그러니까 새로운 데이터가 와가지고 여기에 들어갈려면 빈자리가 없으니까 거의 없고 , 그러다 보니까 지금 있는것중에 누군가를 쫓아내고 그자리에다가 들어가야 된다. 
그래서 replace라는 말 교체한다. 이전에 있는놈을 쫓아내고 그자리에 들어간다. 우리가 replace, 교체한다라는 말을 쓴다.

그러니까 여기서 replace 해야되고 여기서 데이터를 쭉 읽어오는데 읽어오는 양은 블락이다. 블락이 크면 클수록 트랜스퍼 타임 transmit time은 블락이 길이에 비례해서 길어진다. 

그래서 보면은 hit time 하고 miss penalty하고 비교해보면 비교할 수 없을정도로 time이 작다.  
## How is the hierarchy managed?
그래서 어떻게 계층이 유지되느냐? 레지스터와 메모리 사이에는 컴파일러나 프로그래머에 의해서 캐시나 메모리 사이에는 하드웨어 에 의해서 메모리 와 디스크사이에서는 일부는 하드웨어서 동작하지만 사실은 대부분 operating system에 의해서 여러분들이 2학기때 배울텐데 
일부는 프로그래머가 거기에 개입하기도 하지만 대부분 os 에 의해서 대표적으로 이게 뭐야..? ㄷ여기 들어있는게?
버퍼 캐시 또는 페이지 캐시 이런것들이 os에 의해서 디스크 데이터를 캐싱하고 있는 값들 이다.

## Questions for Hierarchy Design
lower lever에서 한 블락을 가지고 오면은 어 일단 
upper level에 어디에 둘것인가를 결정해야 하는데 그것을 우리가 블락 플레이스 먼트 블락 배치 블락 배정 원리 라고 하고 
이거는 뭐하고 연결이 되냐면 Q3. 에 만약에 워드가 프리이면 문제가 없지만 아까도 얘기 했듯이 위에 있는 레벨이 소용량이기때문에 대부분 차겠죠. 그러면 누구를 쫓아내야되는데 그떄 쫓아내고 새롭게 교체하는 부분을 replace 한다고 했다. 그래서 어느 블락을 어느 곳에 위치할것인가를 placement는 기존에 어떤것들을 replace 할것인가 하고도 아주 밀접하게 연결되어있다. 
block placement와 block replacement 는 서로 상호 연결관계에 있다. 
그다음에 upper level 에 무언가 block 들이 있는데 그중에서 내가 찾는 block이 있는가 없는가 그거를 확인하는 과정을 block identification 이라고 한다. 블락 식별이라고 한다. 블락 식별도 우리가 어떤 그 기법 원리가 필요하다.

그다음에 대부분의 데이터를 읽는건데 데이터 읽어낼때는 문제가없어. 그런데 문제가 뭐냐면 아까 그림으로 돌아가면 자 이그림을 보자 원래 원본은 메모리에 있었어 

## Levels of Memory Hierearchy
그래서 cpu가 그 a를 읽어갈때 어 a를 지금 cpu가 읽으니까 a를 또 읽겠지 하고 여기다가 카피를 둔다. 그리고 또 읽어
어그래 맞아 내가 거기다 가져다 두길 잘했네 하고 서비스를 해 그리고 read는 문제가 없어 그런데 어떤 일이 발생하냐면 프로그램의 read만하는게 아니잔아 원래 a의 들어있는 값이 100이었는데 여기 100이란 값이 있고 여기 100이라는 값이 갔는데
계산해가지고 이걸 101 로 만들었네 어.
그럼 그순간에 a는 a프라임으로 값이 바뀐다. 100 이 아니고 101로 

자 어떤 문제가 생겨 같은 변수 고 같은 데이터인데 지금 여기게 있는 복사본하고 여기도 바껴야되 복사본하고 원본하고 값이 다르면 이게 모순된 상황이다. 일관성이 없는 상황임 그러면 여기도 바꿔줘야 겠다 a프라임으로 그렇지? 그러면 여기만 바뀌면되나? (아래로 내려가는걸 의미하는듯) 밑에도 또 바껴야 겠네
그렇지?
여기만 바뀌면되? 밑에 또 있는데 ... 이렇게 그치
무슨 문제야? read는 문제가 없어 거의 복사본만 가져다 놓으면되 근데 문제는 그 데이터를 위에서 write 했을때 그 아래에 있는 원본하고 상위에서 바뀐 카피본하고의 서로 불일치 
inconsistency 불일치 문제를 해결해줘야 된다.
그래서 그 해결하는 방법이 뭐야? 방금 얘기한대로 위에서 쓰면 어그래 여기도 바꾸고 밑에 또있지 그래 여기도 바꾸고 또 있지? 여기도 바꾸고 쭉 write를 한번할때 끝까지 쭈욱 해서 끝까지 가주는 방법 끝까지 쭈욱 간다고 해서 write throw 라고한다. throw 가 끝까지 쭈욱 간다는 얘기다 
write throw 끝까지 쭈욱
어디까지? 이 데이터의 원본이 있는건 다 찾아가지고 고치는것이다. 
쭈욱 
근데 이자식이 또 101 방금 고치더니 또 
우리가 보통 카운트 하나씩 증가하면 그런 프로그램이라든지 금방 또 102 로 바꿔버리네 그러면 또 write throw 한다. 계속해서 
이게 무슨 문제지? 어. cache의 효과를 이렇게되면 하나도 못보는것이다. caching은 우리가 가까운 레벨에다가 데이터를 둔다음에 왠만하면 거기서 서비스를 받는것을 적극적으로 활용할려고 캐시를 둔건데 그런데 지금 write 할때마다 그게 항상 어디까지 가? 
끝까지 내려가게끔 되어있다 무엇때문에? 데이터의 일관성을 유지하기 위해서 
그렇지 write throw 
그러니까 캐시가 있으나 마나다
오히려 캐시가 더 부담이 된다. 캐시가 없었으면 그냥 쭉 한번만 저기가서 쓰면되는데 바로 아래 써버리고 또 바로 아래 써버리고 오히려 더 걸림돌이 된다. 
이거는
write throw가 
자 그래서 이거를 조금더 뒤에 내가 지금 미리 배경을 얘기하는건데 write throw가 효과적인 방법은 아니다 그렇지
일단은 어떻게 하냐면 이렇게 
cache의 값이 101로 바뀌면 일단은 그냥 밑에 값하고 다른거는 알지만 일단은 거기까지 내려가기가 지금 귀찮고 바쁘니까 일단 캐시에서만 처리하자 그래서 여기서 만약에 됐다 그러면 
그래서 101을 그다음에 금방또 102로 금방 또 103으로 
이렇게 바뀌면 일단은 아래까지 내려가지않고 캐시에서 많은 write가 서비스 된다. 그렇지
그런데 한가지 불안한건 있다. 불안한건 있다. 지금 원본하고는 아직 받는상태가 계속 유지가 된다. 그렇지?
원본하고는 문제는 이로가면 이제 전기가 갑자기 정전이 된다. 그러면 이제 아주 운이 나쁜것이다
열심히 계산해뒀는데 계산결과가 하나도 반영이 안되고 다 날라가버린다. 그런경우는 어쩔수없는데
자, 그러면 언젠가는 이 103이 여기 103에 103에 103에 반영이 되어야 하는데 언제 반영이 되도록 하느냐 나중에 언제? 
이 블락이 언젠가 누군가에 의해서 여기서 쫓겨나는 일이 생기겠지?
왜? 여기 용량이 작으니까 누군가가 새로운 데이터가 와가지고 내가 어디로 들어가야 되는데 뭐 이렇게 찾다가 내가 
니가 제일 만만하니까(페이지 캐시??아마도..) 그자리좀 비켜줘 라고 해서 거기에 이렇게 차지할때 그걸 뭐라고 했어 블락리플레이스 라고했다.
블락이 리플레스될때, 블락이 리플레이스될때 이 데이터가 리플레이스되서 쫓겨날때 그때는 이 데이터를 어디다가 메모리에다가 써줘야한다. 그래서 이와같은 방법을 뭐라그러냐면 아까는 write를 끝까지 쓰는것을 write throw라고했는데 지금 어떤 블락을 교체할때 그때 갱신하는 방법을 우리가 write back 라고 한다. 나중에 한다고 그래서 

write back 언제? 블락이 교체될때 ! (중요)

## Direct Mapped Cache
자 그리고 지나가고 자 그래서 자 지금부터 이제는 
모를 기준으로 생각을 하냐면 항상 블락을 기준으로 생각한다 이제 까지는 워드 기준으로 생각했잔아 그렇지? 메모리 생각할때는 워드가 아니고 워드보다 더 큰 단위 블락으로 생각한다.
자, 여기가 지금 워드0 1,2,3,4,5 이렇게 가잔아 4워드가 한 블락이야 그럼 얘들이 같은 블락이다. 블락0 블락1 블락2 
그냥 상식적으로 메모리 워드를 알고있어 그리고 블락 사이즈를 알고있어 그러면 내가 속해있는 블락은 몇번일까 어떻게 알까? 
내 워드에 주소 나누기 블락 의 크기 그럼 몫이 나오잔아 그러면 그게 내가 속해있는 블락 넘버다. 내가 내 워드 주소 바이트 주소 가 아니고 바이 트 주소 할때는 블락의 크기를 바이트로 환산하면 되는거니까 (시험문제 나올거같은데)
그냥 내 워드주소가 123 이야 그리고 주소가 123 이야 그리고 한 블락이 지금 4워드가 한 블락이야 
4워드가 그러면 블락 넘버로 볼때 나는 몇 번 블락에 속해있을까 그러면 어떻게 123/4 하면 몫이 얼마야 30지 내가 속해있는 블락은 30번 블락이다. 그래서 모든 워드마다 자기가 속해있는 블락이 존재한다. 그렇지 
그리고 그 블락들로 왔다갔다 한다. 
그래서 지금 여기에 블락이야. 자 이거는 메모리에 있기떄문에 메모리 블락이라고 하고 똑같은 크기로 캐싱했을때 이걸 캐시블락이라고 한다. 
그래서 아래에서 올라온 한 블락이 soemwhere 여기에 있는거다 어딘가에 그런데 아래에서 올라왔을때 어디에 이떄이제 그 
밑에 있는 번호들을 지금부터 우리들은 블락주소로 지금 여기에 가리키고 있는데 00001 1번 블락이야 00101은 이게 뭐지 5번 블락이고 블락
이안에 그냥 뭐 워드가 4개정도 들어있다 정도로 가정하자 
8개 들어있을떄도 상관없고 그러면 자, 프로세스에서 어떤 어드레스가 떠요 그러면 사실은 그 워드가 져오라는 얘기지 하지만 그 워드만 가져오는게아니고 걔가 속해있는 블락을 알아가지고 그 블락을 쭉 올려보내는것이다. 위로  그런데 문제는 그런데 밑에이렇게 많은 블락들이 있고 캐시에는 블락이 몇개없어 
캐시는 용량이 작고 워낙 비싸서 캐시에 담을 수있는것은 하나 ~ 8개 블락밖에 없다 예를들면
그럼 저 8개 블락들은 얘네들이 SHARE하는것이다. 얘를 access 할때 어디간에 위치 시켜야 할거아니야 
얘 access할때 어딘가에 위치 시켜야 한다 그렇지
그 위치 시키는 방법, 블락을 위치시키는 방법을 블락 플레이스먼트, 블락 배치법이라고 한다 그랬지
그렇지 블락 배치법 중에서 제일 심플한 방법이 뭐냐 
걔가 들어갈 위치를 딱 고정해주는거야 
어떻 게 고정 하면되겠어? 걔 블락번호가 있잔아 
그렇지 , 이 블락번호를 가지고 아 1번 블락은 1번에 2번 블락은 2번에 3번블락은 3번에 이렇게 배치시키는것이다.
그러면 0번부터 7번까지는 자기 블락이 바로 나오는것이고 그다음에 8번은 어떻게 다시 0번으로 돌아가게 이렇게
0~7번 8~다시 0번~7번 이렇게 다시 15번 0~7번 이렇게
결국 내가 말을 한것을 다시 근사하게 바꾸면 자기의 블락 주소를 저기에 들어 얘가 캐시가 제공하고있는 블락의 개수로 어떻게해서 module 을 취해서 나머지를 취해서 그 나머지에 해당되는 위치 로 블락을 대체시킨다. 자 1 나누, 모듈 8 하면 1이지 
그러면 1번 블락으로 간다. 요거는 01101 은 얼마지? 이게 13이지 그러면 13 모듈 8 하면 얼마냐 5잔아 
5번 블락으로 간다. 그렇지 
여기에 11101 이면 잘모르지만 얘 모듈 8하면 위치가 여기로 간다. 이렇게 그래서 각자 자기 블락넘버에 의해서 가야될 캐시 블락의 위치가 결정되는 방법 
이것을 우리가 다이렉트 맵드 캐시 우리말로는 직접 사상캐시라고 한다. 이해되냐? 무슨말인지? 그렇죠 이해되죠!

여기까지 잘 정리 해두자!!
ㅠㅠㅠ


## Why Hierarchy Works?


